<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="pdoc 15.0.3"/>
    <title>cloai API documentation</title>

    <style>/*! * Bootstrap Reboot v5.0.0 (https://getbootstrap.com/) * Copyright 2011-2021 The Bootstrap Authors * Copyright 2011-2021 Twitter, Inc. * Licensed under MIT (https://github.com/twbs/bootstrap/blob/main/LICENSE) * Forked from Normalize.css, licensed MIT (https://github.com/necolas/normalize.css/blob/master/LICENSE.md) */*,::after,::before{box-sizing:border-box}@media (prefers-reduced-motion:no-preference){:root{scroll-behavior:smooth}}body{margin:0;font-family:system-ui,-apple-system,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans","Liberation Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";font-size:1rem;font-weight:400;line-height:1.5;color:#212529;background-color:#fff;-webkit-text-size-adjust:100%;-webkit-tap-highlight-color:transparent}hr{margin:1rem 0;color:inherit;background-color:currentColor;border:0;opacity:.25}hr:not([size]){height:1px}h1,h2,h3,h4,h5,h6{margin-top:0;margin-bottom:.5rem;font-weight:500;line-height:1.2}h1{font-size:calc(1.375rem + 1.5vw)}@media (min-width:1200px){h1{font-size:2.5rem}}h2{font-size:calc(1.325rem + .9vw)}@media (min-width:1200px){h2{font-size:2rem}}h3{font-size:calc(1.3rem + .6vw)}@media (min-width:1200px){h3{font-size:1.75rem}}h4{font-size:calc(1.275rem + .3vw)}@media (min-width:1200px){h4{font-size:1.5rem}}h5{font-size:1.25rem}h6{font-size:1rem}p{margin-top:0;margin-bottom:1rem}abbr[data-bs-original-title],abbr[title]{-webkit-text-decoration:underline dotted;text-decoration:underline dotted;cursor:help;-webkit-text-decoration-skip-ink:none;text-decoration-skip-ink:none}address{margin-bottom:1rem;font-style:normal;line-height:inherit}ol,ul{padding-left:2rem}dl,ol,ul{margin-top:0;margin-bottom:1rem}ol ol,ol ul,ul ol,ul ul{margin-bottom:0}dt{font-weight:700}dd{margin-bottom:.5rem;margin-left:0}blockquote{margin:0 0 1rem}b,strong{font-weight:bolder}small{font-size:.875em}mark{padding:.2em;background-color:#fcf8e3}sub,sup{position:relative;font-size:.75em;line-height:0;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}a{color:#0d6efd;text-decoration:underline}a:hover{color:#0a58ca}a:not([href]):not([class]),a:not([href]):not([class]):hover{color:inherit;text-decoration:none}code,kbd,pre,samp{font-family:SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;font-size:1em;direction:ltr;unicode-bidi:bidi-override}pre{display:block;margin-top:0;margin-bottom:1rem;overflow:auto;font-size:.875em}pre code{font-size:inherit;color:inherit;word-break:normal}code{font-size:.875em;color:#d63384;word-wrap:break-word}a>code{color:inherit}kbd{padding:.2rem .4rem;font-size:.875em;color:#fff;background-color:#212529;border-radius:.2rem}kbd kbd{padding:0;font-size:1em;font-weight:700}figure{margin:0 0 1rem}img,svg{vertical-align:middle}table{caption-side:bottom;border-collapse:collapse}caption{padding-top:.5rem;padding-bottom:.5rem;color:#6c757d;text-align:left}th{text-align:inherit;text-align:-webkit-match-parent}tbody,td,tfoot,th,thead,tr{border-color:inherit;border-style:solid;border-width:0}label{display:inline-block}button{border-radius:0}button:focus:not(:focus-visible){outline:0}button,input,optgroup,select,textarea{margin:0;font-family:inherit;font-size:inherit;line-height:inherit}button,select{text-transform:none}[role=button]{cursor:pointer}select{word-wrap:normal}select:disabled{opacity:1}[list]::-webkit-calendar-picker-indicator{display:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]:not(:disabled),[type=reset]:not(:disabled),[type=submit]:not(:disabled),button:not(:disabled){cursor:pointer}::-moz-focus-inner{padding:0;border-style:none}textarea{resize:vertical}fieldset{min-width:0;padding:0;margin:0;border:0}legend{float:left;width:100%;padding:0;margin-bottom:.5rem;font-size:calc(1.275rem + .3vw);line-height:inherit}@media (min-width:1200px){legend{font-size:1.5rem}}legend+*{clear:left}::-webkit-datetime-edit-day-field,::-webkit-datetime-edit-fields-wrapper,::-webkit-datetime-edit-hour-field,::-webkit-datetime-edit-minute,::-webkit-datetime-edit-month-field,::-webkit-datetime-edit-text,::-webkit-datetime-edit-year-field{padding:0}::-webkit-inner-spin-button{height:auto}[type=search]{outline-offset:-2px;-webkit-appearance:textfield}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-color-swatch-wrapper{padding:0}::file-selector-button{font:inherit}::-webkit-file-upload-button{font:inherit;-webkit-appearance:button}output{display:inline-block}iframe{border:0}summary{display:list-item;cursor:pointer}progress{vertical-align:baseline}[hidden]{display:none!important}</style>
    <style>/*! syntax-highlighting.css */pre{line-height:125%;}span.linenos{color:inherit; background-color:transparent; padding-left:5px; padding-right:20px;}.pdoc-code .hll{background-color:#ffffcc}.pdoc-code{background:#f8f8f8;}.pdoc-code .c{color:#3D7B7B; font-style:italic}.pdoc-code .err{border:1px solid #FF0000}.pdoc-code .k{color:#008000; font-weight:bold}.pdoc-code .o{color:#666666}.pdoc-code .ch{color:#3D7B7B; font-style:italic}.pdoc-code .cm{color:#3D7B7B; font-style:italic}.pdoc-code .cp{color:#9C6500}.pdoc-code .cpf{color:#3D7B7B; font-style:italic}.pdoc-code .c1{color:#3D7B7B; font-style:italic}.pdoc-code .cs{color:#3D7B7B; font-style:italic}.pdoc-code .gd{color:#A00000}.pdoc-code .ge{font-style:italic}.pdoc-code .gr{color:#E40000}.pdoc-code .gh{color:#000080; font-weight:bold}.pdoc-code .gi{color:#008400}.pdoc-code .go{color:#717171}.pdoc-code .gp{color:#000080; font-weight:bold}.pdoc-code .gs{font-weight:bold}.pdoc-code .gu{color:#800080; font-weight:bold}.pdoc-code .gt{color:#0044DD}.pdoc-code .kc{color:#008000; font-weight:bold}.pdoc-code .kd{color:#008000; font-weight:bold}.pdoc-code .kn{color:#008000; font-weight:bold}.pdoc-code .kp{color:#008000}.pdoc-code .kr{color:#008000; font-weight:bold}.pdoc-code .kt{color:#B00040}.pdoc-code .m{color:#666666}.pdoc-code .s{color:#BA2121}.pdoc-code .na{color:#687822}.pdoc-code .nb{color:#008000}.pdoc-code .nc{color:#0000FF; font-weight:bold}.pdoc-code .no{color:#880000}.pdoc-code .nd{color:#AA22FF}.pdoc-code .ni{color:#717171; font-weight:bold}.pdoc-code .ne{color:#CB3F38; font-weight:bold}.pdoc-code .nf{color:#0000FF}.pdoc-code .nl{color:#767600}.pdoc-code .nn{color:#0000FF; font-weight:bold}.pdoc-code .nt{color:#008000; font-weight:bold}.pdoc-code .nv{color:#19177C}.pdoc-code .ow{color:#AA22FF; font-weight:bold}.pdoc-code .w{color:#bbbbbb}.pdoc-code .mb{color:#666666}.pdoc-code .mf{color:#666666}.pdoc-code .mh{color:#666666}.pdoc-code .mi{color:#666666}.pdoc-code .mo{color:#666666}.pdoc-code .sa{color:#BA2121}.pdoc-code .sb{color:#BA2121}.pdoc-code .sc{color:#BA2121}.pdoc-code .dl{color:#BA2121}.pdoc-code .sd{color:#BA2121; font-style:italic}.pdoc-code .s2{color:#BA2121}.pdoc-code .se{color:#AA5D1F; font-weight:bold}.pdoc-code .sh{color:#BA2121}.pdoc-code .si{color:#A45A77; font-weight:bold}.pdoc-code .sx{color:#008000}.pdoc-code .sr{color:#A45A77}.pdoc-code .s1{color:#BA2121}.pdoc-code .ss{color:#19177C}.pdoc-code .bp{color:#008000}.pdoc-code .fm{color:#0000FF}.pdoc-code .vc{color:#19177C}.pdoc-code .vg{color:#19177C}.pdoc-code .vi{color:#19177C}.pdoc-code .vm{color:#19177C}.pdoc-code .il{color:#666666}@media (prefers-color-scheme:dark){pre{line-height:125%;}span.linenos{color:inherit; background-color:transparent; padding-left:5px; padding-right:20px;}.pdoc-code .hll{background-color:#49483e}.pdoc-code{background:#272822; color:#f8f8f2}.pdoc-code .c{color:#75715e}.pdoc-code .err{color:#960050; background-color:#1e0010}.pdoc-code .esc{color:#f8f8f2}.pdoc-code .g{color:#f8f8f2}.pdoc-code .k{color:#66d9ef}.pdoc-code .l{color:#ae81ff}.pdoc-code .n{color:#f8f8f2}.pdoc-code .o{color:#f92672}.pdoc-code .x{color:#f8f8f2}.pdoc-code .p{color:#f8f8f2}.pdoc-code .ch{color:#75715e}.pdoc-code .cm{color:#75715e}.pdoc-code .cp{color:#75715e}.pdoc-code .cpf{color:#75715e}.pdoc-code .c1{color:#75715e}.pdoc-code .cs{color:#75715e}.pdoc-code .gd{color:#f92672}.pdoc-code .ge{color:#f8f8f2; font-style:italic}.pdoc-code .gr{color:#f8f8f2}.pdoc-code .gh{color:#f8f8f2}.pdoc-code .gi{color:#a6e22e}.pdoc-code .go{color:#66d9ef}.pdoc-code .gp{color:#f92672; font-weight:bold}.pdoc-code .gs{color:#f8f8f2; font-weight:bold}.pdoc-code .gu{color:#75715e}.pdoc-code .gt{color:#f8f8f2}.pdoc-code .kc{color:#66d9ef}.pdoc-code .kd{color:#66d9ef}.pdoc-code .kn{color:#f92672}.pdoc-code .kp{color:#66d9ef}.pdoc-code .kr{color:#66d9ef}.pdoc-code .kt{color:#66d9ef}.pdoc-code .ld{color:#e6db74}.pdoc-code .m{color:#ae81ff}.pdoc-code .s{color:#e6db74}.pdoc-code .na{color:#a6e22e}.pdoc-code .nb{color:#f8f8f2}.pdoc-code .nc{color:#a6e22e}.pdoc-code .no{color:#66d9ef}.pdoc-code .nd{color:#a6e22e}.pdoc-code .ni{color:#f8f8f2}.pdoc-code .ne{color:#a6e22e}.pdoc-code .nf{color:#a6e22e}.pdoc-code .nl{color:#f8f8f2}.pdoc-code .nn{color:#f8f8f2}.pdoc-code .nx{color:#a6e22e}.pdoc-code .py{color:#f8f8f2}.pdoc-code .nt{color:#f92672}.pdoc-code .nv{color:#f8f8f2}.pdoc-code .ow{color:#f92672}.pdoc-code .w{color:#f8f8f2}.pdoc-code .mb{color:#ae81ff}.pdoc-code .mf{color:#ae81ff}.pdoc-code .mh{color:#ae81ff}.pdoc-code .mi{color:#ae81ff}.pdoc-code .mo{color:#ae81ff}.pdoc-code .sa{color:#e6db74}.pdoc-code .sb{color:#e6db74}.pdoc-code .sc{color:#e6db74}.pdoc-code .dl{color:#e6db74}.pdoc-code .sd{color:#e6db74}.pdoc-code .s2{color:#e6db74}.pdoc-code .se{color:#ae81ff}.pdoc-code .sh{color:#e6db74}.pdoc-code .si{color:#e6db74}.pdoc-code .sx{color:#e6db74}.pdoc-code .sr{color:#e6db74}.pdoc-code .s1{color:#e6db74}.pdoc-code .ss{color:#e6db74}.pdoc-code .bp{color:#f8f8f2}.pdoc-code .fm{color:#a6e22e}.pdoc-code .vc{color:#f8f8f2}.pdoc-code .vg{color:#f8f8f2}.pdoc-code .vi{color:#f8f8f2}.pdoc-code .vm{color:#f8f8f2}}</style>
    <style>/*! theme.css */:root{--pdoc-background:#fff;}.pdoc{--text:#212529;--muted:#6c757d;--link:#3660a5;--link-hover:#1659c5;--code:#f8f8f8;--active:#fff598;--accent:#eee;--accent2:#c1c1c1;--nav-hover:rgba(255, 255, 255, 0.5);--name:#0066BB;--def:#008800;--annotation:#007020;}@media (prefers-color-scheme:dark){:root{--pdoc-background:#212529;}.pdoc{--text:#f7f7f7;--muted:#9d9d9d;--link:#58a6ff;--link-hover:#3989ff;--code:#333;--active:#555;--accent:#343434;--accent2:#555;--nav-hover:rgba(0, 0, 0, 0.1);--name:#77C1FF;--def:#0cdd0c;--annotation:#00c037;}}</style>
    <style>/*! layout.css */html, body{width:100%;height:100%;}html, main{scroll-behavior:smooth;}body{background-color:var(--pdoc-background);}@media (max-width:769px){#navtoggle{cursor:pointer;position:absolute;width:50px;height:40px;top:1rem;right:1rem;border-color:var(--text);color:var(--text);display:flex;opacity:0.8;z-index:999;}#navtoggle:hover{opacity:1;}#togglestate + div{display:none;}#togglestate:checked + div{display:inherit;}main, header{padding:2rem 3vw;}header + main{margin-top:-3rem;}.git-button{display:none !important;}nav input[type="search"]{max-width:77%;}nav input[type="search"]:first-child{margin-top:-6px;}nav input[type="search"]:valid ~ *{display:none !important;}}@media (min-width:770px){:root{--sidebar-width:clamp(12.5rem, 28vw, 22rem);}nav{position:fixed;overflow:auto;height:100vh;width:var(--sidebar-width);}main, header{padding:3rem 2rem 3rem calc(var(--sidebar-width) + 3rem);width:calc(54rem + var(--sidebar-width));max-width:100%;}header + main{margin-top:-4rem;}#navtoggle{display:none;}}#togglestate{position:absolute;height:0;opacity:0;}nav.pdoc{--pad:clamp(0.5rem, 2vw, 1.75rem);--indent:1.5rem;background-color:var(--accent);border-right:1px solid var(--accent2);box-shadow:0 0 20px rgba(50, 50, 50, .2) inset;padding:0 0 0 var(--pad);overflow-wrap:anywhere;scrollbar-width:thin; scrollbar-color:var(--accent2) transparent; z-index:1}nav.pdoc::-webkit-scrollbar{width:.4rem; }nav.pdoc::-webkit-scrollbar-thumb{background-color:var(--accent2); }nav.pdoc > div{padding:var(--pad) 0;}nav.pdoc .module-list-button{display:inline-flex;align-items:center;color:var(--text);border-color:var(--muted);margin-bottom:1rem;}nav.pdoc .module-list-button:hover{border-color:var(--text);}nav.pdoc input[type=search]{display:block;outline-offset:0;width:calc(100% - var(--pad));}nav.pdoc .logo{max-width:calc(100% - var(--pad));max-height:35vh;display:block;margin:0 auto 1rem;transform:translate(calc(-.5 * var(--pad)), 0);}nav.pdoc ul{list-style:none;padding-left:0;}nav.pdoc > div > ul{margin-left:calc(0px - var(--pad));}nav.pdoc li a{padding:.2rem 0 .2rem calc(var(--pad) + var(--indent));}nav.pdoc > div > ul > li > a{padding-left:var(--pad);}nav.pdoc li{transition:all 100ms;}nav.pdoc li:hover{background-color:var(--nav-hover);}nav.pdoc a, nav.pdoc a:hover{color:var(--text);}nav.pdoc a{display:block;}nav.pdoc > h2:first-of-type{margin-top:1.5rem;}nav.pdoc .class:before{content:"class ";color:var(--muted);}nav.pdoc .function:after{content:"()";color:var(--muted);}nav.pdoc footer:before{content:"";display:block;width:calc(100% - var(--pad));border-top:solid var(--accent2) 1px;margin-top:1.5rem;padding-top:.5rem;}nav.pdoc footer{font-size:small;}</style>
    <style>/*! content.css */.pdoc{color:var(--text);box-sizing:border-box;line-height:1.5;background:none;}.pdoc .pdoc-button{cursor:pointer;display:inline-block;border:solid black 1px;border-radius:2px;font-size:.75rem;padding:calc(0.5em - 1px) 1em;transition:100ms all;}.pdoc .alert{padding:1rem 1rem 1rem calc(1.5rem + 24px);border:1px solid transparent;border-radius:.25rem;background-repeat:no-repeat;background-position:.75rem center;margin-bottom:1rem;}.pdoc .alert > em{display:none;}.pdoc .alert > *:last-child{margin-bottom:0;}.pdoc .alert.note{color:#084298;background-color:#cfe2ff;border-color:#b6d4fe;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23084298%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8%2016A8%208%200%201%200%208%200a8%208%200%200%200%200%2016zm.93-9.412-1%204.705c-.07.34.029.533.304.533.194%200%20.487-.07.686-.246l-.088.416c-.287.346-.92.598-1.465.598-.703%200-1.002-.422-.808-1.319l.738-3.468c.064-.293.006-.399-.287-.47l-.451-.081.082-.381%202.29-.287zM8%205.5a1%201%200%201%201%200-2%201%201%200%200%201%200%202z%22/%3E%3C/svg%3E");}.pdoc .alert.tip{color:#0a3622;background-color:#d1e7dd;border-color:#a3cfbb;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%230a3622%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M2%206a6%206%200%201%201%2010.174%204.31c-.203.196-.359.4-.453.619l-.762%201.769A.5.5%200%200%201%2010.5%2013a.5.5%200%200%201%200%201%20.5.5%200%200%201%200%201l-.224.447a1%201%200%200%201-.894.553H6.618a1%201%200%200%201-.894-.553L5.5%2015a.5.5%200%200%201%200-1%20.5.5%200%200%201%200-1%20.5.5%200%200%201-.46-.302l-.761-1.77a2%202%200%200%200-.453-.618A5.98%205.98%200%200%201%202%206m6-5a5%205%200%200%200-3.479%208.592c.263.254.514.564.676.941L5.83%2012h4.342l.632-1.467c.162-.377.413-.687.676-.941A5%205%200%200%200%208%201%22/%3E%3C/svg%3E");}.pdoc .alert.important{color:#055160;background-color:#cff4fc;border-color:#9eeaf9;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23055160%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M2%200a2%202%200%200%200-2%202v12a2%202%200%200%200%202%202h12a2%202%200%200%200%202-2V2a2%202%200%200%200-2-2zm6%204c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%204.995A.905.905%200%200%201%208%204m.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2%22/%3E%3C/svg%3E");}.pdoc .alert.warning{color:#664d03;background-color:#fff3cd;border-color:#ffecb5;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23664d03%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8.982%201.566a1.13%201.13%200%200%200-1.96%200L.165%2013.233c-.457.778.091%201.767.98%201.767h13.713c.889%200%201.438-.99.98-1.767L8.982%201.566zM8%205c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%205.995A.905.905%200%200%201%208%205zm.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2z%22/%3E%3C/svg%3E");}.pdoc .alert.caution{color:#842029;background-color:#f8d7da;border-color:#f5c2c7;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23842029%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M11.46.146A.5.5%200%200%200%2011.107%200H4.893a.5.5%200%200%200-.353.146L.146%204.54A.5.5%200%200%200%200%204.893v6.214a.5.5%200%200%200%20.146.353l4.394%204.394a.5.5%200%200%200%20.353.146h6.214a.5.5%200%200%200%20.353-.146l4.394-4.394a.5.5%200%200%200%20.146-.353V4.893a.5.5%200%200%200-.146-.353zM8%204c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%204.995A.905.905%200%200%201%208%204m.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2%22/%3E%3C/svg%3E");}.pdoc .alert.danger{color:#842029;background-color:#f8d7da;border-color:#f5c2c7;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23842029%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M5.52.359A.5.5%200%200%201%206%200h4a.5.5%200%200%201%20.474.658L8.694%206H12.5a.5.5%200%200%201%20.395.807l-7%209a.5.5%200%200%201-.873-.454L6.823%209.5H3.5a.5.5%200%200%201-.48-.641l2.5-8.5z%22/%3E%3C/svg%3E");}.pdoc .visually-hidden{position:absolute !important;width:1px !important;height:1px !important;padding:0 !important;margin:-1px !important;overflow:hidden !important;clip:rect(0, 0, 0, 0) !important;white-space:nowrap !important;border:0 !important;}.pdoc h1, .pdoc h2, .pdoc h3{font-weight:300;margin:.3em 0;padding:.2em 0;}.pdoc > section:not(.module-info) h1{font-size:1.5rem;font-weight:500;}.pdoc > section:not(.module-info) h2{font-size:1.4rem;font-weight:500;}.pdoc > section:not(.module-info) h3{font-size:1.3rem;font-weight:500;}.pdoc > section:not(.module-info) h4{font-size:1.2rem;}.pdoc > section:not(.module-info) h5{font-size:1.1rem;}.pdoc a{text-decoration:none;color:var(--link);}.pdoc a:hover{color:var(--link-hover);}.pdoc blockquote{margin-left:2rem;}.pdoc pre{border-top:1px solid var(--accent2);border-bottom:1px solid var(--accent2);margin-top:0;margin-bottom:1em;padding:.5rem 0 .5rem .5rem;overflow-x:auto;background-color:var(--code);}.pdoc code{color:var(--text);padding:.2em .4em;margin:0;font-size:85%;background-color:var(--accent);border-radius:6px;}.pdoc a > code{color:inherit;}.pdoc pre > code{display:inline-block;font-size:inherit;background:none;border:none;padding:0;}.pdoc > section:not(.module-info){margin-bottom:1.5rem;}.pdoc .modulename{margin-top:0;font-weight:bold;}.pdoc .modulename a{color:var(--link);transition:100ms all;}.pdoc .git-button{float:right;border:solid var(--link) 1px;}.pdoc .git-button:hover{background-color:var(--link);color:var(--pdoc-background);}.view-source-toggle-state,.view-source-toggle-state ~ .pdoc-code{display:none;}.view-source-toggle-state:checked ~ .pdoc-code{display:block;}.view-source-button{display:inline-block;float:right;font-size:.75rem;line-height:1.5rem;color:var(--muted);padding:0 .4rem 0 1.3rem;cursor:pointer;text-indent:-2px;}.view-source-button > span{visibility:hidden;}.module-info .view-source-button{float:none;display:flex;justify-content:flex-end;margin:-1.2rem .4rem -.2rem 0;}.view-source-button::before{position:absolute;content:"View Source";display:list-item;list-style-type:disclosure-closed;}.view-source-toggle-state:checked ~ .attr .view-source-button::before,.view-source-toggle-state:checked ~ .view-source-button::before{list-style-type:disclosure-open;}.pdoc .docstring{margin-bottom:1.5rem;}.pdoc section:not(.module-info) .docstring{margin-left:clamp(0rem, 5vw - 2rem, 1rem);}.pdoc .docstring .pdoc-code{margin-left:1em;margin-right:1em;}.pdoc h1:target,.pdoc h2:target,.pdoc h3:target,.pdoc h4:target,.pdoc h5:target,.pdoc h6:target,.pdoc .pdoc-code > pre > span:target{background-color:var(--active);box-shadow:-1rem 0 0 0 var(--active);}.pdoc .pdoc-code > pre > span:target{display:block;}.pdoc div:target > .attr,.pdoc section:target > .attr,.pdoc dd:target > a{background-color:var(--active);}.pdoc *{scroll-margin:2rem;}.pdoc .pdoc-code .linenos{user-select:none;}.pdoc .attr:hover{filter:contrast(0.95);}.pdoc section, .pdoc .classattr{position:relative;}.pdoc .headerlink{--width:clamp(1rem, 3vw, 2rem);position:absolute;top:0;left:calc(0rem - var(--width));transition:all 100ms ease-in-out;opacity:0;}.pdoc .headerlink::before{content:"#";display:block;text-align:center;width:var(--width);height:2.3rem;line-height:2.3rem;font-size:1.5rem;}.pdoc .attr:hover ~ .headerlink,.pdoc *:target > .headerlink,.pdoc .headerlink:hover{opacity:1;}.pdoc .attr{display:block;margin:.5rem 0 .5rem;padding:.4rem .4rem .4rem 1rem;background-color:var(--accent);overflow-x:auto;}.pdoc .classattr{margin-left:2rem;}.pdoc .decorator-deprecated{color:#842029;}.pdoc .decorator-deprecated ~ span{filter:grayscale(1) opacity(0.8);}.pdoc .name{color:var(--name);font-weight:bold;}.pdoc .def{color:var(--def);font-weight:bold;}.pdoc .signature{background-color:transparent;}.pdoc .param, .pdoc .return-annotation{white-space:pre;}.pdoc .signature.multiline .param{display:block;}.pdoc .signature.condensed .param{display:inline-block;}.pdoc .annotation{color:var(--annotation);}.pdoc .view-value-toggle-state,.pdoc .view-value-toggle-state ~ .default_value{display:none;}.pdoc .view-value-toggle-state:checked ~ .default_value{display:inherit;}.pdoc .view-value-button{font-size:.5rem;vertical-align:middle;border-style:dashed;margin-top:-0.1rem;}.pdoc .view-value-button:hover{background:white;}.pdoc .view-value-button::before{content:"show";text-align:center;width:2.2em;display:inline-block;}.pdoc .view-value-toggle-state:checked ~ .view-value-button::before{content:"hide";}.pdoc .inherited{margin-left:2rem;}.pdoc .inherited dt{font-weight:700;}.pdoc .inherited dt, .pdoc .inherited dd{display:inline;margin-left:0;margin-bottom:.5rem;}.pdoc .inherited dd:not(:last-child):after{content:", ";}.pdoc .inherited .class:before{content:"class ";}.pdoc .inherited .function a:after{content:"()";}.pdoc .search-result .docstring{overflow:auto;max-height:25vh;}.pdoc .search-result.focused > .attr{background-color:var(--active);}.pdoc .attribution{margin-top:2rem;display:block;opacity:0.5;transition:all 200ms;filter:grayscale(100%);}.pdoc .attribution:hover{opacity:1;filter:grayscale(0%);}.pdoc .attribution img{margin-left:5px;height:35px;vertical-align:middle;width:70px;transition:all 200ms;}.pdoc table{display:block;width:max-content;max-width:100%;overflow:auto;margin-bottom:1rem;}.pdoc table th{font-weight:600;}.pdoc table th, .pdoc table td{padding:6px 13px;border:1px solid var(--accent2);}</style>
    <style>/*! custom.css */</style></head>
<body>
    <nav class="pdoc">
        <label id="navtoggle" for="togglestate" class="pdoc-button"><svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 30 30'><path stroke-linecap='round' stroke="currentColor" stroke-miterlimit='10' stroke-width='2' d='M4 7h22M4 15h22M4 23h22'/></svg></label>
        <input id="togglestate" type="checkbox" aria-hidden="true" tabindex="-1">
        <div>


            <h2>Contents</h2>
            <ul>
  <li><a href="#cloai">Cloai</a>
  <ul>
    <li><a href="#installation">Installation</a></li>
    <li><a href="#usage">Usage</a></li>
    <li><a href="#contributing">Contributing</a></li>
    <li><a href="#license">License</a></li>
    <li><a href="#support">Support</a></li>
  </ul></li>
</ul>



            <h2>API Documentation</h2>
                <ul class="memberlist">
            <li>
                    <a class="class" href="#AnthropicBedrockLlm">AnthropicBedrockLlm</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#AnthropicBedrockLlm.__init__">AnthropicBedrockLlm</a>
                        </li>
                        <li>
                                <a class="variable" href="#AnthropicBedrockLlm.client">client</a>
                        </li>
                        <li>
                                <a class="variable" href="#AnthropicBedrockLlm.model">model</a>
                        </li>
                        <li>
                                <a class="function" href="#AnthropicBedrockLlm.run">run</a>
                        </li>
                        <li>
                                <a class="function" href="#AnthropicBedrockLlm.call_instructor">call_instructor</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#AzureLlm">AzureLlm</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#AzureLlm.__init__">AzureLlm</a>
                        </li>
                        <li>
                                <a class="variable" href="#AzureLlm.client">client</a>
                        </li>
                        <li>
                                <a class="variable" href="#AzureLlm.model">model</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#LargeLanguageModel">LargeLanguageModel</a>
                            <ul class="memberlist">
                        <li>
                                <a class="variable" href="#LargeLanguageModel.model_config">model_config</a>
                        </li>
                        <li>
                                <a class="variable" href="#LargeLanguageModel.client">client</a>
                        </li>
                        <li>
                                <a class="function" href="#LargeLanguageModel.run">run</a>
                        </li>
                        <li>
                                <a class="function" href="#LargeLanguageModel.call_instructor">call_instructor</a>
                        </li>
                        <li>
                                <a class="function" href="#LargeLanguageModel.chain_of_verification">chain_of_verification</a>
                        </li>
                        <li>
                                <a class="function" href="#LargeLanguageModel.chain_of_density">chain_of_density</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#OllamaLlm">OllamaLlm</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#OllamaLlm.__init__">OllamaLlm</a>
                        </li>
                        <li>
                                <a class="variable" href="#OllamaLlm.model">model</a>
                        </li>
                        <li>
                                <a class="variable" href="#OllamaLlm.client">client</a>
                        </li>
                        <li>
                                <a class="function" href="#OllamaLlm.run">run</a>
                        </li>
                        <li>
                                <a class="function" href="#OllamaLlm.call_instructor">call_instructor</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#OpenAiLlm">OpenAiLlm</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#OpenAiLlm.__init__">OpenAiLlm</a>
                        </li>
                        <li>
                                <a class="variable" href="#OpenAiLlm.client">client</a>
                        </li>
                        <li>
                                <a class="variable" href="#OpenAiLlm.model">model</a>
                        </li>
                </ul>

            </li>
    </ul>



        <a class="attribution" title="pdoc: Python API documentation generator" href="https://pdoc.dev" target="_blank">
            built with <span class="visually-hidden">pdoc</span><img
                alt="pdoc logo"
                src="data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20role%3D%22img%22%20aria-label%3D%22pdoc%20logo%22%20width%3D%22300%22%20height%3D%22150%22%20viewBox%3D%22-1%200%2060%2030%22%3E%3Ctitle%3Epdoc%3C/title%3E%3Cpath%20d%3D%22M29.621%2021.293c-.011-.273-.214-.475-.511-.481a.5.5%200%200%200-.489.503l-.044%201.393c-.097.551-.695%201.215-1.566%201.704-.577.428-1.306.486-2.193.182-1.426-.617-2.467-1.654-3.304-2.487l-.173-.172a3.43%203.43%200%200%200-.365-.306.49.49%200%200%200-.286-.196c-1.718-1.06-4.931-1.47-7.353.191l-.219.15c-1.707%201.187-3.413%202.131-4.328%201.03-.02-.027-.49-.685-.141-1.763.233-.721.546-2.408.772-4.076.042-.09.067-.187.046-.288.166-1.347.277-2.625.241-3.351%201.378-1.008%202.271-2.586%202.271-4.362%200-.976-.272-1.935-.788-2.774-.057-.094-.122-.18-.184-.268.033-.167.052-.339.052-.516%200-1.477-1.202-2.679-2.679-2.679-.791%200-1.496.352-1.987.9a6.3%206.3%200%200%200-1.001.029c-.492-.564-1.207-.929-2.012-.929-1.477%200-2.679%201.202-2.679%202.679A2.65%202.65%200%200%200%20.97%206.554c-.383.747-.595%201.572-.595%202.41%200%202.311%201.507%204.29%203.635%205.107-.037.699-.147%202.27-.423%203.294l-.137.461c-.622%202.042-2.515%208.257%201.727%2010.643%201.614.908%203.06%201.248%204.317%201.248%202.665%200%204.492-1.524%205.322-2.401%201.476-1.559%202.886-1.854%206.491.82%201.877%201.393%203.514%201.753%204.861%201.068%202.223-1.713%202.811-3.867%203.399-6.374.077-.846.056-1.469.054-1.537zm-4.835%204.313c-.054.305-.156.586-.242.629-.034-.007-.131-.022-.307-.157-.145-.111-.314-.478-.456-.908.221.121.432.25.675.355.115.039.219.051.33.081zm-2.251-1.238c-.05.33-.158.648-.252.694-.022.001-.125-.018-.307-.157-.217-.166-.488-.906-.639-1.573.358.344.754.693%201.198%201.036zm-3.887-2.337c-.006-.116-.018-.231-.041-.342.635.145%201.189.368%201.599.625.097.231.166.481.174.642-.03.049-.055.101-.067.158-.046.013-.128.026-.298.004-.278-.037-.901-.57-1.367-1.087zm-1.127-.497c.116.306.176.625.12.71-.019.014-.117.045-.345.016-.206-.027-.604-.332-.986-.695.41-.051.816-.056%201.211-.031zm-4.535%201.535c.209.22.379.47.358.598-.006.041-.088.138-.351.234-.144.055-.539-.063-.979-.259a11.66%2011.66%200%200%200%20.972-.573zm.983-.664c.359-.237.738-.418%201.126-.554.25.237.479.548.457.694-.006.042-.087.138-.351.235-.174.064-.694-.105-1.232-.375zm-3.381%201.794c-.022.145-.061.29-.149.401-.133.166-.358.248-.69.251h-.002c-.133%200-.306-.26-.45-.621.417.091.854.07%201.291-.031zm-2.066-8.077a4.78%204.78%200%200%201-.775-.584c.172-.115.505-.254.88-.378l-.105.962zm-.331%202.302a10.32%2010.32%200%200%201-.828-.502c.202-.143.576-.328.984-.49l-.156.992zm-.45%202.157l-.701-.403c.214-.115.536-.249.891-.376a11.57%2011.57%200%200%201-.19.779zm-.181%201.716c.064.398.194.702.298.893-.194-.051-.435-.162-.736-.398.061-.119.224-.3.438-.495zM8.87%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zm-.735-.389a1.15%201.15%200%200%200-.314.783%201.16%201.16%200%200%200%201.162%201.162c.457%200%20.842-.27%201.032-.653.026.117.042.238.042.362a1.68%201.68%200%200%201-1.679%201.679%201.68%201.68%200%200%201-1.679-1.679c0-.843.626-1.535%201.436-1.654zM5.059%205.406A1.68%201.68%200%200%201%203.38%207.085a1.68%201.68%200%200%201-1.679-1.679c0-.037.009-.072.011-.109.21.3.541.508.935.508a1.16%201.16%200%200%200%201.162-1.162%201.14%201.14%200%200%200-.474-.912c.015%200%20.03-.005.045-.005.926.001%201.679.754%201.679%201.68zM3.198%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zM1.375%208.964c0-.52.103-1.035.288-1.52.466.394%201.06.64%201.717.64%201.144%200%202.116-.725%202.499-1.738.383%201.012%201.355%201.738%202.499%201.738.867%200%201.631-.421%202.121-1.062.307.605.478%201.267.478%201.942%200%202.486-2.153%204.51-4.801%204.51s-4.801-2.023-4.801-4.51zm24.342%2019.349c-.985.498-2.267.168-3.813-.979-3.073-2.281-5.453-3.199-7.813-.705-1.315%201.391-4.163%203.365-8.423.97-3.174-1.786-2.239-6.266-1.261-9.479l.146-.492c.276-1.02.395-2.457.444-3.268a6.11%206.11%200%200%200%201.18.115%206.01%206.01%200%200%200%202.536-.562l-.006.175c-.802.215-1.848.612-2.021%201.25-.079.295.021.601.274.837.219.203.415.364.598.501-.667.304-1.243.698-1.311%201.179-.02.144-.022.507.393.787.213.144.395.26.564.365-1.285.521-1.361.96-1.381%201.126-.018.142-.011.496.427.746l.854.489c-.473.389-.971.914-.999%201.429-.018.278.095.532.316.713.675.556%201.231.721%201.653.721.059%200%20.104-.014.158-.02.207.707.641%201.64%201.513%201.64h.013c.8-.008%201.236-.345%201.462-.626.173-.216.268-.457.325-.692.424.195.93.374%201.372.374.151%200%20.294-.021.423-.068.732-.27.944-.704.993-1.021.009-.061.003-.119.002-.179.266.086.538.147.789.147.15%200%20.294-.021.423-.069.542-.2.797-.489.914-.754.237.147.478.258.704.288.106.014.205.021.296.021.356%200%20.595-.101.767-.229.438.435%201.094.992%201.656%201.067.106.014.205.021.296.021a1.56%201.56%200%200%200%20.323-.035c.17.575.453%201.289.866%201.605.358.273.665.362.914.362a.99.99%200%200%200%20.421-.093%201.03%201.03%200%200%200%20.245-.164c.168.428.39.846.68%201.068.358.273.665.362.913.362a.99.99%200%200%200%20.421-.093c.317-.148.512-.448.639-.762.251.157.495.257.726.257.127%200%20.25-.024.37-.071.427-.17.706-.617.841-1.314.022-.015.047-.022.068-.038.067-.051.133-.104.196-.159-.443%201.486-1.107%202.761-2.086%203.257zM8.66%209.925a.5.5%200%201%200-1%200c0%20.653-.818%201.205-1.787%201.205s-1.787-.552-1.787-1.205a.5.5%200%201%200-1%200c0%201.216%201.25%202.205%202.787%202.205s2.787-.989%202.787-2.205zm4.4%2015.965l-.208.097c-2.661%201.258-4.708%201.436-6.086.527-1.542-1.017-1.88-3.19-1.844-4.198a.4.4%200%200%200-.385-.414c-.242-.029-.406.164-.414.385-.046%201.249.367%203.686%202.202%204.896.708.467%201.547.7%202.51.7%201.248%200%202.706-.392%204.362-1.174l.185-.086a.4.4%200%200%200%20.205-.527c-.089-.204-.326-.291-.527-.206zM9.547%202.292c.093.077.205.114.317.114a.5.5%200%200%200%20.318-.886L8.817.397a.5.5%200%200%200-.703.068.5.5%200%200%200%20.069.703l1.364%201.124zm-7.661-.065c.086%200%20.173-.022.253-.068l1.523-.893a.5.5%200%200%200-.506-.863l-1.523.892a.5.5%200%200%200-.179.685c.094.158.261.247.432.247z%22%20transform%3D%22matrix%28-1%200%200%201%2058%200%29%22%20fill%3D%22%233bb300%22/%3E%3Cpath%20d%3D%22M.3%2021.86V10.18q0-.46.02-.68.04-.22.18-.5.28-.54%201.34-.54%201.06%200%201.42.28.38.26.44.78.76-1.04%202.38-1.04%201.64%200%203.1%201.54%201.46%201.54%201.46%203.58%200%202.04-1.46%203.58-1.44%201.54-3.08%201.54-1.64%200-2.38-.92v4.04q0%20.46-.04.68-.02.22-.18.5-.14.3-.5.42-.36.12-.98.12-.62%200-1-.12-.36-.12-.52-.4-.14-.28-.18-.5-.02-.22-.02-.68zm3.96-9.42q-.46.54-.46%201.18%200%20.64.46%201.18.48.52%201.2.52.74%200%201.24-.52.52-.52.52-1.18%200-.66-.48-1.18-.48-.54-1.26-.54-.76%200-1.22.54zm14.741-8.36q.16-.3.54-.42.38-.12%201-.12.64%200%201.02.12.38.12.52.42.16.3.18.54.04.22.04.68v11.94q0%20.46-.04.7-.02.22-.18.5-.3.54-1.7.54-1.38%200-1.54-.98-.84.96-2.34.96-1.8%200-3.28-1.56-1.48-1.58-1.48-3.66%200-2.1%201.48-3.68%201.5-1.58%203.28-1.58%201.48%200%202.3%201v-4.2q0-.46.02-.68.04-.24.18-.52zm-3.24%2010.86q.52.54%201.26.54.74%200%201.22-.54.5-.54.5-1.18%200-.66-.48-1.22-.46-.56-1.26-.56-.8%200-1.28.56-.48.54-.48%201.2%200%20.66.52%201.2zm7.833-1.2q0-2.4%201.68-3.96%201.68-1.56%203.84-1.56%202.16%200%203.82%201.56%201.66%201.54%201.66%203.94%200%201.66-.86%202.96-.86%201.28-2.1%201.9-1.22.6-2.54.6-1.32%200-2.56-.64-1.24-.66-2.1-1.92-.84-1.28-.84-2.88zm4.18%201.44q.64.48%201.3.48.66%200%201.32-.5.66-.5.66-1.48%200-.98-.62-1.46-.62-.48-1.34-.48-.72%200-1.34.5-.62.5-.62%201.48%200%20.96.64%201.46zm11.412-1.44q0%20.84.56%201.32.56.46%201.18.46.64%200%201.18-.36.56-.38.9-.38.6%200%201.46%201.06.46.58.46%201.04%200%20.76-1.1%201.42-1.14.8-2.8.8-1.86%200-3.58-1.34-.82-.64-1.34-1.7-.52-1.08-.52-2.36%200-1.3.52-2.34.52-1.06%201.34-1.7%201.66-1.32%203.54-1.32.76%200%201.48.22.72.2%201.06.4l.32.2q.36.24.56.38.52.4.52.92%200%20.5-.42%201.14-.72%201.1-1.38%201.1-.38%200-1.08-.44-.36-.34-1.04-.34-.66%200-1.24.48-.58.48-.58%201.34z%22%20fill%3D%22green%22/%3E%3C/svg%3E"/>
        </a>
</div>
    </nav>
    <main class="pdoc">
            <section class="module-info">
                    <h1 class="modulename">
cloai    </h1>

                        <div class="docstring"><h1 id="cloai">Cloai</h1>

<p>Cloai is a generic interface to large language models. It enables the usage of
various prompting techniques (currently: chain of verification, chain of density,
instructor) across a wide variety of models, whilst using an identical interface.</p>

<h2 id="installation">Installation</h2>

<p>To install cloai, you can use the following command:</p>

<div class="pdoc-code codehilite">
<pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>cloai
</code></pre>
</div>

<h2 id="usage">Usage</h2>

<p>First, instantiate a client with a large language model provider. Cloai currently
supports OpenAI, Azure OpenAI, AWS Bedrock (Anthropic only), and Ollama:</p>

<h4 id="openai-client">OpenAI Client</h4>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">cloai</span>

<span class="n">client</span> <span class="o">=</span> <span class="n"><a href="#OpenAiLlm">cloai.OpenAiLlm</a></span><span class="p">(</span><span class="n">api_key</span><span class="o">=</span><span class="s2">&quot;your_key&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-4o&quot;</span><span class="p">)</span>
</code></pre>
</div>

<h4 id="ollama-client">Ollama Client</h4>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">cloai</span>

<span class="n">client</span> <span class="o">=</span> <span class="n"><a href="#OllamaLlm">cloai.OllamaLlm</a></span><span class="p">(</span>
  <span class="n">model</span><span class="o">=</span><span class="s2">&quot;llama3.2&quot;</span><span class="p">,</span>
  <span class="n">base_url</span><span class="o">=</span><span class="s2">&quot;http://localhost:11434/v1&quot;</span><span class="p">,</span>
<span class="p">)</span>
</code></pre>
</div>

<h4 id="azure-openai-client">Azure OpenAI Client</h4>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">cloai</span>

<span class="n">client</span> <span class="o">=</span> <span class="n"><a href="#AzureLlm">cloai.AzureLlm</a></span><span class="p">(</span>
  <span class="n">api_key</span><span class="o">=</span><span class="s2">&quot;your_key&quot;</span><span class="p">,</span>
  <span class="n">endpoint</span><span class="o">=</span><span class="s2">&quot;your_endpoint&quot;</span><span class="p">,</span>
  <span class="n">api_version</span><span class="o">=</span><span class="s2">&quot;version_number&quot;</span><span class="p">,</span>
  <span class="n">deployment</span><span class="o">=</span><span class="s2">&quot;your_deployment&quot;</span>
<span class="p">)</span>
</code></pre>
</div>

<h4 id="aws-bedrock-anthropic">AWS Bedrock (Anthropic)</h4>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">cloai</span>

<span class="n">client</span> <span class="o">=</span> <span class="n"><a href="#AnthropicBedrockLlm">cloai.AnthropicBedrockLlm</a></span><span class="p">(</span>
  <span class="n">model</span><span class="o">=</span><span class="s2">&quot;anthropic.claude-3-5-sonnet-20241022-v2:0&quot;</span><span class="p">,</span>
  <span class="n">aws_access_key</span><span class="o">=</span><span class="s2">&quot;YOUR_ACCESS_KEY&quot;</span><span class="p">,</span>
  <span class="n">aws_secret_key</span><span class="o">=</span><span class="s2">&quot;YOUR_SECRET_KEY&quot;</span><span class="p">,</span>
  <span class="n">region</span><span class="o">=</span><span class="s2">&quot;REGION&quot;</span><span class="p">,</span>
<span class="p">)</span>
</code></pre>
</div>

<p>Once your client is created, you can construct the generic interface and make use of
all the methods, regardless of which LLM you are using. Please be aware that cloai
uses asynchronous clients so you will have to await the promises. If you are in a
synchronous environment, see <code>asyncio.run()</code>.</p>

<div class="pdoc-code codehilite">
<pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">cloai</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pydantic</span>

<span class="n">model</span> <span class="o">=</span> <span class="n"><a href="#LargeLanguageModel">cloai.LargeLanguageModel</a></span><span class="p">(</span><span class="n">client</span><span class="o">=</span><span class="n">client</span><span class="p">)</span>

<span class="c1"># Standard prompt</span>
<span class="n">result</span> <span class="o">=</span> <span class="k">await</span> <span class="n">model</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">system_prompt</span><span class="p">,</span> <span class="n">user_prompt</span><span class="p">)</span>

<span class="c1"># Instructor</span>
<span class="k">class</span><span class="w"> </span><span class="nc">Response</span><span class="p">(</span><span class="n">pydantic</span><span class="o">.</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">is_scary</span><span class="p">:</span> <span class="nb">bool</span>

<span class="n">result</span> <span class="o">=</span> <span class="k">await</span> <span class="n">model</span><span class="o">.</span><span class="n">call_instructor</span><span class="p">(</span>
  <span class="n">response_model</span><span class="o">=</span><span class="n">Response</span><span class="p">,</span>
  <span class="n">system_prompt</span><span class="o">=</span><span class="s2">&quot;Tell the user if a movie is scary.&quot;</span><span class="p">,</span>
  <span class="n">user_prompt</span><span class="o">=</span><span class="s2">&quot;Scary movie 3.&quot;</span>
<span class="p">)</span>

<span class="c1"># Chain of verification</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">chain_of_verification</span><span class="p">(</span><span class="n">system_prompt</span><span class="p">,</span> <span class="n">user_prompt</span><span class="p">)</span>

<span class="c1"># Chain of density</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">chain_of_density</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</code></pre>
</div>

<h2 id="contributing">Contributing</h2>

<p>Contributions are welcome! Please see the <a href="CONTRIBUTING.md">contributing guidelines</a> for more information.</p>

<h2 id="license">License</h2>

<p>cloai is licensed under the terms of the <a href="LICENSE">L-GPLv2.1 license</a>.</p>

<h2 id="support">Support</h2>

<p>If you encounter any issues or have any questions, please report them on our <a href="https://github.com/childmindresearch/cloai/issues">issues page</a>.</p>
</div>

                        <input id="mod-cloai-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">

                        <label class="view-source-button" for="mod-cloai-view-source"><span>View Source</span></label>

                        <div class="pdoc-code codehilite"><pre><span></span><span id="L-1"><a href="#L-1"><span class="linenos"> 1</span></a><span class="sd">&quot;&quot;&quot;.. include:: ../../README.md&quot;&quot;&quot;</span>  <span class="c1"># noqa: D415</span>
</span><span id="L-2"><a href="#L-2"><span class="linenos"> 2</span></a>
</span><span id="L-3"><a href="#L-3"><span class="linenos"> 3</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">cloai.llm.bedrock</span><span class="w"> </span><span class="kn">import</span> <span class="n">AnthropicBedrockLlm</span>
</span><span id="L-4"><a href="#L-4"><span class="linenos"> 4</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">cloai.llm.llm</span><span class="w"> </span><span class="kn">import</span> <span class="n">LargeLanguageModel</span>
</span><span id="L-5"><a href="#L-5"><span class="linenos"> 5</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">cloai.llm.ollama</span><span class="w"> </span><span class="kn">import</span> <span class="n">OllamaLlm</span>
</span><span id="L-6"><a href="#L-6"><span class="linenos"> 6</span></a><span class="kn">from</span><span class="w"> </span><span class="nn">cloai.llm.openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">AzureLlm</span><span class="p">,</span> <span class="n">OpenAiLlm</span>
</span><span id="L-7"><a href="#L-7"><span class="linenos"> 7</span></a>
</span><span id="L-8"><a href="#L-8"><span class="linenos"> 8</span></a><span class="n">__all__</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="L-9"><a href="#L-9"><span class="linenos"> 9</span></a>    <span class="s2">&quot;AnthropicBedrockLlm&quot;</span><span class="p">,</span>
</span><span id="L-10"><a href="#L-10"><span class="linenos">10</span></a>    <span class="s2">&quot;AzureLlm&quot;</span><span class="p">,</span>
</span><span id="L-11"><a href="#L-11"><span class="linenos">11</span></a>    <span class="s2">&quot;LargeLanguageModel&quot;</span><span class="p">,</span>
</span><span id="L-12"><a href="#L-12"><span class="linenos">12</span></a>    <span class="s2">&quot;OllamaLlm&quot;</span><span class="p">,</span>
</span><span id="L-13"><a href="#L-13"><span class="linenos">13</span></a>    <span class="s2">&quot;OpenAiLlm&quot;</span><span class="p">,</span>
</span><span id="L-14"><a href="#L-14"><span class="linenos">14</span></a><span class="p">)</span>
</span></pre></div>


            </section>
                <section id="AnthropicBedrockLlm">
                            <input id="AnthropicBedrockLlm-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">AnthropicBedrockLlm</span><wbr>(<span class="base">cloai.llm.utils.LlmBaseClass</span>):

                <label class="view-source-button" for="AnthropicBedrockLlm-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#AnthropicBedrockLlm"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="AnthropicBedrockLlm-26"><a href="#AnthropicBedrockLlm-26"><span class="linenos">26</span></a><span class="k">class</span><span class="w"> </span><span class="nc">AnthropicBedrockLlm</span><span class="p">(</span><span class="n">utils</span><span class="o">.</span><span class="n">LlmBaseClass</span><span class="p">):</span>
</span><span id="AnthropicBedrockLlm-27"><a href="#AnthropicBedrockLlm-27"><span class="linenos">27</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Class for Anthropic Large Language models on Bedrock.</span>
</span><span id="AnthropicBedrockLlm-28"><a href="#AnthropicBedrockLlm-28"><span class="linenos">28</span></a>
</span><span id="AnthropicBedrockLlm-29"><a href="#AnthropicBedrockLlm-29"><span class="linenos">29</span></a><span class="sd">    Attributes:</span>
</span><span id="AnthropicBedrockLlm-30"><a href="#AnthropicBedrockLlm-30"><span class="linenos">30</span></a><span class="sd">        client: The BedRock client.</span>
</span><span id="AnthropicBedrockLlm-31"><a href="#AnthropicBedrockLlm-31"><span class="linenos">31</span></a><span class="sd">        model: The model that is invoked.</span>
</span><span id="AnthropicBedrockLlm-32"><a href="#AnthropicBedrockLlm-32"><span class="linenos">32</span></a>
</span><span id="AnthropicBedrockLlm-33"><a href="#AnthropicBedrockLlm-33"><span class="linenos">33</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="AnthropicBedrockLlm-34"><a href="#AnthropicBedrockLlm-34"><span class="linenos">34</span></a>
</span><span id="AnthropicBedrockLlm-35"><a href="#AnthropicBedrockLlm-35"><span class="linenos">35</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="AnthropicBedrockLlm-36"><a href="#AnthropicBedrockLlm-36"><span class="linenos">36</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm-37"><a href="#AnthropicBedrockLlm-37"><span class="linenos">37</span></a>        <span class="n">model</span><span class="p">:</span> <span class="n">ANTHROPIC_BEDROCK_MODELS</span> <span class="o">|</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm-38"><a href="#AnthropicBedrockLlm-38"><span class="linenos">38</span></a>        <span class="o">*</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm-39"><a href="#AnthropicBedrockLlm-39"><span class="linenos">39</span></a>        <span class="n">aws_access_key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm-40"><a href="#AnthropicBedrockLlm-40"><span class="linenos">40</span></a>        <span class="n">aws_secret_key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm-41"><a href="#AnthropicBedrockLlm-41"><span class="linenos">41</span></a>        <span class="n">region</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm-42"><a href="#AnthropicBedrockLlm-42"><span class="linenos">42</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="AnthropicBedrockLlm-43"><a href="#AnthropicBedrockLlm-43"><span class="linenos">43</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initializes the BedRock client.&quot;&quot;&quot;</span>
</span><span id="AnthropicBedrockLlm-44"><a href="#AnthropicBedrockLlm-44"><span class="linenos">44</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">client</span> <span class="o">=</span> <span class="n">anthropic</span><span class="o">.</span><span class="n">AsyncAnthropicBedrock</span><span class="p">(</span>
</span><span id="AnthropicBedrockLlm-45"><a href="#AnthropicBedrockLlm-45"><span class="linenos">45</span></a>            <span class="n">aws_access_key</span><span class="o">=</span><span class="n">aws_access_key</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm-46"><a href="#AnthropicBedrockLlm-46"><span class="linenos">46</span></a>            <span class="n">aws_secret_key</span><span class="o">=</span><span class="n">aws_secret_key</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm-47"><a href="#AnthropicBedrockLlm-47"><span class="linenos">47</span></a>            <span class="n">aws_region</span><span class="o">=</span><span class="n">region</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm-48"><a href="#AnthropicBedrockLlm-48"><span class="linenos">48</span></a>        <span class="p">)</span>
</span><span id="AnthropicBedrockLlm-49"><a href="#AnthropicBedrockLlm-49"><span class="linenos">49</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
</span><span id="AnthropicBedrockLlm-50"><a href="#AnthropicBedrockLlm-50"><span class="linenos">50</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_instructor</span> <span class="o">=</span> <span class="n">instructor</span><span class="o">.</span><span class="n">from_anthropic</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">client</span><span class="p">)</span>
</span><span id="AnthropicBedrockLlm-51"><a href="#AnthropicBedrockLlm-51"><span class="linenos">51</span></a>
</span><span id="AnthropicBedrockLlm-52"><a href="#AnthropicBedrockLlm-52"><span class="linenos">52</span></a>    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">system_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">user_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
</span><span id="AnthropicBedrockLlm-53"><a href="#AnthropicBedrockLlm-53"><span class="linenos">53</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Runs the model with the given prompts.</span>
</span><span id="AnthropicBedrockLlm-54"><a href="#AnthropicBedrockLlm-54"><span class="linenos">54</span></a>
</span><span id="AnthropicBedrockLlm-55"><a href="#AnthropicBedrockLlm-55"><span class="linenos">55</span></a><span class="sd">        Args:</span>
</span><span id="AnthropicBedrockLlm-56"><a href="#AnthropicBedrockLlm-56"><span class="linenos">56</span></a><span class="sd">            system_prompt: The system prompt.</span>
</span><span id="AnthropicBedrockLlm-57"><a href="#AnthropicBedrockLlm-57"><span class="linenos">57</span></a><span class="sd">            user_prompt: The user prompt.</span>
</span><span id="AnthropicBedrockLlm-58"><a href="#AnthropicBedrockLlm-58"><span class="linenos">58</span></a>
</span><span id="AnthropicBedrockLlm-59"><a href="#AnthropicBedrockLlm-59"><span class="linenos">59</span></a><span class="sd">        Returns:</span>
</span><span id="AnthropicBedrockLlm-60"><a href="#AnthropicBedrockLlm-60"><span class="linenos">60</span></a><span class="sd">            The output text.</span>
</span><span id="AnthropicBedrockLlm-61"><a href="#AnthropicBedrockLlm-61"><span class="linenos">61</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="AnthropicBedrockLlm-62"><a href="#AnthropicBedrockLlm-62"><span class="linenos">62</span></a>        <span class="n">message</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">client</span><span class="o">.</span><span class="n">messages</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
</span><span id="AnthropicBedrockLlm-63"><a href="#AnthropicBedrockLlm-63"><span class="linenos">63</span></a>            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm-64"><a href="#AnthropicBedrockLlm-64"><span class="linenos">64</span></a>            <span class="n">max_tokens</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm-65"><a href="#AnthropicBedrockLlm-65"><span class="linenos">65</span></a>            <span class="n">system</span><span class="o">=</span><span class="n">system_prompt</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm-66"><a href="#AnthropicBedrockLlm-66"><span class="linenos">66</span></a>            <span class="n">messages</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">user_prompt</span><span class="p">}],</span>
</span><span id="AnthropicBedrockLlm-67"><a href="#AnthropicBedrockLlm-67"><span class="linenos">67</span></a>        <span class="p">)</span>
</span><span id="AnthropicBedrockLlm-68"><a href="#AnthropicBedrockLlm-68"><span class="linenos">68</span></a>        <span class="k">return</span> <span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span>  <span class="c1"># type: ignore[union-attr]</span>
</span><span id="AnthropicBedrockLlm-69"><a href="#AnthropicBedrockLlm-69"><span class="linenos">69</span></a>
</span><span id="AnthropicBedrockLlm-70"><a href="#AnthropicBedrockLlm-70"><span class="linenos">70</span></a>    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">call_instructor</span><span class="p">(</span>
</span><span id="AnthropicBedrockLlm-71"><a href="#AnthropicBedrockLlm-71"><span class="linenos">71</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm-72"><a href="#AnthropicBedrockLlm-72"><span class="linenos">72</span></a>        <span class="n">response_model</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="n">T</span><span class="p">],</span>
</span><span id="AnthropicBedrockLlm-73"><a href="#AnthropicBedrockLlm-73"><span class="linenos">73</span></a>        <span class="n">system_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm-74"><a href="#AnthropicBedrockLlm-74"><span class="linenos">74</span></a>        <span class="n">user_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm-75"><a href="#AnthropicBedrockLlm-75"><span class="linenos">75</span></a>        <span class="n">max_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4096</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm-76"><a href="#AnthropicBedrockLlm-76"><span class="linenos">76</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
</span><span id="AnthropicBedrockLlm-77"><a href="#AnthropicBedrockLlm-77"><span class="linenos">77</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Run a type-safe large language model query.</span>
</span><span id="AnthropicBedrockLlm-78"><a href="#AnthropicBedrockLlm-78"><span class="linenos">78</span></a>
</span><span id="AnthropicBedrockLlm-79"><a href="#AnthropicBedrockLlm-79"><span class="linenos">79</span></a><span class="sd">        Args:</span>
</span><span id="AnthropicBedrockLlm-80"><a href="#AnthropicBedrockLlm-80"><span class="linenos">80</span></a><span class="sd">            response_model: The Pydantic response model.</span>
</span><span id="AnthropicBedrockLlm-81"><a href="#AnthropicBedrockLlm-81"><span class="linenos">81</span></a><span class="sd">            system_prompt: The system prompt.</span>
</span><span id="AnthropicBedrockLlm-82"><a href="#AnthropicBedrockLlm-82"><span class="linenos">82</span></a><span class="sd">            user_prompt: The user prompt.</span>
</span><span id="AnthropicBedrockLlm-83"><a href="#AnthropicBedrockLlm-83"><span class="linenos">83</span></a><span class="sd">            max_tokens: The maximum number of tokens to allow.</span>
</span><span id="AnthropicBedrockLlm-84"><a href="#AnthropicBedrockLlm-84"><span class="linenos">84</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="AnthropicBedrockLlm-85"><a href="#AnthropicBedrockLlm-85"><span class="linenos">85</span></a>        <span class="k">return</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">_instructor</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>  <span class="c1"># type: ignore[type-var]</span>
</span><span id="AnthropicBedrockLlm-86"><a href="#AnthropicBedrockLlm-86"><span class="linenos">86</span></a>            <span class="n">response_model</span><span class="o">=</span><span class="n">response_model</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm-87"><a href="#AnthropicBedrockLlm-87"><span class="linenos">87</span></a>            <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
</span><span id="AnthropicBedrockLlm-88"><a href="#AnthropicBedrockLlm-88"><span class="linenos">88</span></a>                <span class="p">{</span>
</span><span id="AnthropicBedrockLlm-89"><a href="#AnthropicBedrockLlm-89"><span class="linenos">89</span></a>                    <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm-90"><a href="#AnthropicBedrockLlm-90"><span class="linenos">90</span></a>                    <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">user_prompt</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm-91"><a href="#AnthropicBedrockLlm-91"><span class="linenos">91</span></a>                <span class="p">},</span>
</span><span id="AnthropicBedrockLlm-92"><a href="#AnthropicBedrockLlm-92"><span class="linenos">92</span></a>            <span class="p">],</span>
</span><span id="AnthropicBedrockLlm-93"><a href="#AnthropicBedrockLlm-93"><span class="linenos">93</span></a>            <span class="n">system</span><span class="o">=</span><span class="n">system_prompt</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm-94"><a href="#AnthropicBedrockLlm-94"><span class="linenos">94</span></a>            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm-95"><a href="#AnthropicBedrockLlm-95"><span class="linenos">95</span></a>            <span class="n">max_tokens</span><span class="o">=</span><span class="n">max_tokens</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm-96"><a href="#AnthropicBedrockLlm-96"><span class="linenos">96</span></a>        <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Class for Anthropic Large Language models on Bedrock.</p>

<h6 id="attributes">Attributes:</h6>

<ul>
<li><strong>client:</strong>  The BedRock client.</li>
<li><strong>model:</strong>  The model that is invoked.</li>
</ul>
</div>


                            <div id="AnthropicBedrockLlm.__init__" class="classattr">
                                        <input id="AnthropicBedrockLlm.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">AnthropicBedrockLlm</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">model</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Literal</span><span class="p">[</span><span class="s1">&#39;anthropic.claude-3-5-sonnet-20241022-v2:0&#39;</span><span class="p">,</span> <span class="s1">&#39;anthropic.claude-3-5-sonnet-20240620-v1:0&#39;</span><span class="p">,</span> <span class="s1">&#39;anthropic.claude-3-opus-20240229-v1:0&#39;</span><span class="p">,</span> <span class="s1">&#39;anthropic.claude-3-5-haiku-20241022-v1:0&#39;</span><span class="p">,</span> <span class="s1">&#39;anthropic.claude-3-haiku-20240307-v1:0&#39;</span><span class="p">,</span> <span class="s1">&#39;anthropic.claude-sonnet-4-20250514-v1:0&#39;</span><span class="p">,</span> <span class="s1">&#39;anthropic.claude-opus-4-20250514-v1:0&#39;</span><span class="p">],</span> <span class="nb">str</span><span class="p">]</span>,</span><span class="param">	<span class="o">*</span>,</span><span class="param">	<span class="n">aws_access_key</span><span class="p">:</span> <span class="nb">str</span>,</span><span class="param">	<span class="n">aws_secret_key</span><span class="p">:</span> <span class="nb">str</span>,</span><span class="param">	<span class="n">region</span><span class="p">:</span> <span class="nb">str</span></span>)</span>

                <label class="view-source-button" for="AnthropicBedrockLlm.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#AnthropicBedrockLlm.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="AnthropicBedrockLlm.__init__-35"><a href="#AnthropicBedrockLlm.__init__-35"><span class="linenos">35</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="AnthropicBedrockLlm.__init__-36"><a href="#AnthropicBedrockLlm.__init__-36"><span class="linenos">36</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm.__init__-37"><a href="#AnthropicBedrockLlm.__init__-37"><span class="linenos">37</span></a>        <span class="n">model</span><span class="p">:</span> <span class="n">ANTHROPIC_BEDROCK_MODELS</span> <span class="o">|</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm.__init__-38"><a href="#AnthropicBedrockLlm.__init__-38"><span class="linenos">38</span></a>        <span class="o">*</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm.__init__-39"><a href="#AnthropicBedrockLlm.__init__-39"><span class="linenos">39</span></a>        <span class="n">aws_access_key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm.__init__-40"><a href="#AnthropicBedrockLlm.__init__-40"><span class="linenos">40</span></a>        <span class="n">aws_secret_key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm.__init__-41"><a href="#AnthropicBedrockLlm.__init__-41"><span class="linenos">41</span></a>        <span class="n">region</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm.__init__-42"><a href="#AnthropicBedrockLlm.__init__-42"><span class="linenos">42</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="AnthropicBedrockLlm.__init__-43"><a href="#AnthropicBedrockLlm.__init__-43"><span class="linenos">43</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initializes the BedRock client.&quot;&quot;&quot;</span>
</span><span id="AnthropicBedrockLlm.__init__-44"><a href="#AnthropicBedrockLlm.__init__-44"><span class="linenos">44</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">client</span> <span class="o">=</span> <span class="n">anthropic</span><span class="o">.</span><span class="n">AsyncAnthropicBedrock</span><span class="p">(</span>
</span><span id="AnthropicBedrockLlm.__init__-45"><a href="#AnthropicBedrockLlm.__init__-45"><span class="linenos">45</span></a>            <span class="n">aws_access_key</span><span class="o">=</span><span class="n">aws_access_key</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm.__init__-46"><a href="#AnthropicBedrockLlm.__init__-46"><span class="linenos">46</span></a>            <span class="n">aws_secret_key</span><span class="o">=</span><span class="n">aws_secret_key</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm.__init__-47"><a href="#AnthropicBedrockLlm.__init__-47"><span class="linenos">47</span></a>            <span class="n">aws_region</span><span class="o">=</span><span class="n">region</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm.__init__-48"><a href="#AnthropicBedrockLlm.__init__-48"><span class="linenos">48</span></a>        <span class="p">)</span>
</span><span id="AnthropicBedrockLlm.__init__-49"><a href="#AnthropicBedrockLlm.__init__-49"><span class="linenos">49</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
</span><span id="AnthropicBedrockLlm.__init__-50"><a href="#AnthropicBedrockLlm.__init__-50"><span class="linenos">50</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_instructor</span> <span class="o">=</span> <span class="n">instructor</span><span class="o">.</span><span class="n">from_anthropic</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">client</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Initializes the BedRock client.</p>
</div>


                            </div>
                            <div id="AnthropicBedrockLlm.client" class="classattr">
                                <div class="attr variable">
            <span class="name">client</span>

        
    </div>
    <a class="headerlink" href="#AnthropicBedrockLlm.client"></a>
    
    

                            </div>
                            <div id="AnthropicBedrockLlm.model" class="classattr">
                                <div class="attr variable">
            <span class="name">model</span>

        
    </div>
    <a class="headerlink" href="#AnthropicBedrockLlm.model"></a>
    
    

                            </div>
                            <div id="AnthropicBedrockLlm.run" class="classattr">
                                        <input id="AnthropicBedrockLlm.run-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">async def</span>
        <span class="name">run</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">system_prompt</span><span class="p">:</span> <span class="nb">str</span>, </span><span class="param"><span class="n">user_prompt</span><span class="p">:</span> <span class="nb">str</span></span><span class="return-annotation">) -> <span class="nb">str</span>:</span></span>

                <label class="view-source-button" for="AnthropicBedrockLlm.run-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#AnthropicBedrockLlm.run"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="AnthropicBedrockLlm.run-52"><a href="#AnthropicBedrockLlm.run-52"><span class="linenos">52</span></a>    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">system_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">user_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
</span><span id="AnthropicBedrockLlm.run-53"><a href="#AnthropicBedrockLlm.run-53"><span class="linenos">53</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Runs the model with the given prompts.</span>
</span><span id="AnthropicBedrockLlm.run-54"><a href="#AnthropicBedrockLlm.run-54"><span class="linenos">54</span></a>
</span><span id="AnthropicBedrockLlm.run-55"><a href="#AnthropicBedrockLlm.run-55"><span class="linenos">55</span></a><span class="sd">        Args:</span>
</span><span id="AnthropicBedrockLlm.run-56"><a href="#AnthropicBedrockLlm.run-56"><span class="linenos">56</span></a><span class="sd">            system_prompt: The system prompt.</span>
</span><span id="AnthropicBedrockLlm.run-57"><a href="#AnthropicBedrockLlm.run-57"><span class="linenos">57</span></a><span class="sd">            user_prompt: The user prompt.</span>
</span><span id="AnthropicBedrockLlm.run-58"><a href="#AnthropicBedrockLlm.run-58"><span class="linenos">58</span></a>
</span><span id="AnthropicBedrockLlm.run-59"><a href="#AnthropicBedrockLlm.run-59"><span class="linenos">59</span></a><span class="sd">        Returns:</span>
</span><span id="AnthropicBedrockLlm.run-60"><a href="#AnthropicBedrockLlm.run-60"><span class="linenos">60</span></a><span class="sd">            The output text.</span>
</span><span id="AnthropicBedrockLlm.run-61"><a href="#AnthropicBedrockLlm.run-61"><span class="linenos">61</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="AnthropicBedrockLlm.run-62"><a href="#AnthropicBedrockLlm.run-62"><span class="linenos">62</span></a>        <span class="n">message</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">client</span><span class="o">.</span><span class="n">messages</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
</span><span id="AnthropicBedrockLlm.run-63"><a href="#AnthropicBedrockLlm.run-63"><span class="linenos">63</span></a>            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm.run-64"><a href="#AnthropicBedrockLlm.run-64"><span class="linenos">64</span></a>            <span class="n">max_tokens</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm.run-65"><a href="#AnthropicBedrockLlm.run-65"><span class="linenos">65</span></a>            <span class="n">system</span><span class="o">=</span><span class="n">system_prompt</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm.run-66"><a href="#AnthropicBedrockLlm.run-66"><span class="linenos">66</span></a>            <span class="n">messages</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">user_prompt</span><span class="p">}],</span>
</span><span id="AnthropicBedrockLlm.run-67"><a href="#AnthropicBedrockLlm.run-67"><span class="linenos">67</span></a>        <span class="p">)</span>
</span><span id="AnthropicBedrockLlm.run-68"><a href="#AnthropicBedrockLlm.run-68"><span class="linenos">68</span></a>        <span class="k">return</span> <span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span>  <span class="c1"># type: ignore[union-attr]</span>
</span></pre></div>


            <div class="docstring"><p>Runs the model with the given prompts.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>system_prompt:</strong>  The system prompt.</li>
<li><strong>user_prompt:</strong>  The user prompt.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>The output text.</p>
</blockquote>
</div>


                            </div>
                            <div id="AnthropicBedrockLlm.call_instructor" class="classattr">
                                        <input id="AnthropicBedrockLlm.call_instructor-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">async def</span>
        <span class="name">call_instructor</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">response_model</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="o">~</span><span class="n">T</span><span class="p">]</span>,</span><span class="param">	<span class="n">system_prompt</span><span class="p">:</span> <span class="nb">str</span>,</span><span class="param">	<span class="n">user_prompt</span><span class="p">:</span> <span class="nb">str</span>,</span><span class="param">	<span class="n">max_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4096</span></span><span class="return-annotation">) -> <span class="o">~</span><span class="n">T</span>:</span></span>

                <label class="view-source-button" for="AnthropicBedrockLlm.call_instructor-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#AnthropicBedrockLlm.call_instructor"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="AnthropicBedrockLlm.call_instructor-70"><a href="#AnthropicBedrockLlm.call_instructor-70"><span class="linenos">70</span></a>    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">call_instructor</span><span class="p">(</span>
</span><span id="AnthropicBedrockLlm.call_instructor-71"><a href="#AnthropicBedrockLlm.call_instructor-71"><span class="linenos">71</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm.call_instructor-72"><a href="#AnthropicBedrockLlm.call_instructor-72"><span class="linenos">72</span></a>        <span class="n">response_model</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="n">T</span><span class="p">],</span>
</span><span id="AnthropicBedrockLlm.call_instructor-73"><a href="#AnthropicBedrockLlm.call_instructor-73"><span class="linenos">73</span></a>        <span class="n">system_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm.call_instructor-74"><a href="#AnthropicBedrockLlm.call_instructor-74"><span class="linenos">74</span></a>        <span class="n">user_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm.call_instructor-75"><a href="#AnthropicBedrockLlm.call_instructor-75"><span class="linenos">75</span></a>        <span class="n">max_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4096</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm.call_instructor-76"><a href="#AnthropicBedrockLlm.call_instructor-76"><span class="linenos">76</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
</span><span id="AnthropicBedrockLlm.call_instructor-77"><a href="#AnthropicBedrockLlm.call_instructor-77"><span class="linenos">77</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Run a type-safe large language model query.</span>
</span><span id="AnthropicBedrockLlm.call_instructor-78"><a href="#AnthropicBedrockLlm.call_instructor-78"><span class="linenos">78</span></a>
</span><span id="AnthropicBedrockLlm.call_instructor-79"><a href="#AnthropicBedrockLlm.call_instructor-79"><span class="linenos">79</span></a><span class="sd">        Args:</span>
</span><span id="AnthropicBedrockLlm.call_instructor-80"><a href="#AnthropicBedrockLlm.call_instructor-80"><span class="linenos">80</span></a><span class="sd">            response_model: The Pydantic response model.</span>
</span><span id="AnthropicBedrockLlm.call_instructor-81"><a href="#AnthropicBedrockLlm.call_instructor-81"><span class="linenos">81</span></a><span class="sd">            system_prompt: The system prompt.</span>
</span><span id="AnthropicBedrockLlm.call_instructor-82"><a href="#AnthropicBedrockLlm.call_instructor-82"><span class="linenos">82</span></a><span class="sd">            user_prompt: The user prompt.</span>
</span><span id="AnthropicBedrockLlm.call_instructor-83"><a href="#AnthropicBedrockLlm.call_instructor-83"><span class="linenos">83</span></a><span class="sd">            max_tokens: The maximum number of tokens to allow.</span>
</span><span id="AnthropicBedrockLlm.call_instructor-84"><a href="#AnthropicBedrockLlm.call_instructor-84"><span class="linenos">84</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="AnthropicBedrockLlm.call_instructor-85"><a href="#AnthropicBedrockLlm.call_instructor-85"><span class="linenos">85</span></a>        <span class="k">return</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">_instructor</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>  <span class="c1"># type: ignore[type-var]</span>
</span><span id="AnthropicBedrockLlm.call_instructor-86"><a href="#AnthropicBedrockLlm.call_instructor-86"><span class="linenos">86</span></a>            <span class="n">response_model</span><span class="o">=</span><span class="n">response_model</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm.call_instructor-87"><a href="#AnthropicBedrockLlm.call_instructor-87"><span class="linenos">87</span></a>            <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
</span><span id="AnthropicBedrockLlm.call_instructor-88"><a href="#AnthropicBedrockLlm.call_instructor-88"><span class="linenos">88</span></a>                <span class="p">{</span>
</span><span id="AnthropicBedrockLlm.call_instructor-89"><a href="#AnthropicBedrockLlm.call_instructor-89"><span class="linenos">89</span></a>                    <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm.call_instructor-90"><a href="#AnthropicBedrockLlm.call_instructor-90"><span class="linenos">90</span></a>                    <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">user_prompt</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm.call_instructor-91"><a href="#AnthropicBedrockLlm.call_instructor-91"><span class="linenos">91</span></a>                <span class="p">},</span>
</span><span id="AnthropicBedrockLlm.call_instructor-92"><a href="#AnthropicBedrockLlm.call_instructor-92"><span class="linenos">92</span></a>            <span class="p">],</span>
</span><span id="AnthropicBedrockLlm.call_instructor-93"><a href="#AnthropicBedrockLlm.call_instructor-93"><span class="linenos">93</span></a>            <span class="n">system</span><span class="o">=</span><span class="n">system_prompt</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm.call_instructor-94"><a href="#AnthropicBedrockLlm.call_instructor-94"><span class="linenos">94</span></a>            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm.call_instructor-95"><a href="#AnthropicBedrockLlm.call_instructor-95"><span class="linenos">95</span></a>            <span class="n">max_tokens</span><span class="o">=</span><span class="n">max_tokens</span><span class="p">,</span>
</span><span id="AnthropicBedrockLlm.call_instructor-96"><a href="#AnthropicBedrockLlm.call_instructor-96"><span class="linenos">96</span></a>        <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Run a type-safe large language model query.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>response_model:</strong>  The Pydantic response model.</li>
<li><strong>system_prompt:</strong>  The system prompt.</li>
<li><strong>user_prompt:</strong>  The user prompt.</li>
<li><strong>max_tokens:</strong>  The maximum number of tokens to allow.</li>
</ul>
</div>


                            </div>
                </section>
                <section id="AzureLlm">
                            <input id="AzureLlm-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">AzureLlm</span><wbr>(<span class="base">cloai.llm.openai._OpenAiBase</span>):

                <label class="view-source-button" for="AzureLlm-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#AzureLlm"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="AzureLlm-85"><a href="#AzureLlm-85"><span class="linenos"> 85</span></a><span class="k">class</span><span class="w"> </span><span class="nc">AzureLlm</span><span class="p">(</span><span class="n">_OpenAiBase</span><span class="p">):</span>
</span><span id="AzureLlm-86"><a href="#AzureLlm-86"><span class="linenos"> 86</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Azure OpenAI Large Language Models.</span>
</span><span id="AzureLlm-87"><a href="#AzureLlm-87"><span class="linenos"> 87</span></a>
</span><span id="AzureLlm-88"><a href="#AzureLlm-88"><span class="linenos"> 88</span></a><span class="sd">    This class serves as an interface for Azure Large Language Models.</span>
</span><span id="AzureLlm-89"><a href="#AzureLlm-89"><span class="linenos"> 89</span></a><span class="sd">    Both this class and OpenAiLlm inherit from the same base class as,</span>
</span><span id="AzureLlm-90"><a href="#AzureLlm-90"><span class="linenos"> 90</span></a><span class="sd">    apart from initialization, the LLM clients behave the same.</span>
</span><span id="AzureLlm-91"><a href="#AzureLlm-91"><span class="linenos"> 91</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="AzureLlm-92"><a href="#AzureLlm-92"><span class="linenos"> 92</span></a>
</span><span id="AzureLlm-93"><a href="#AzureLlm-93"><span class="linenos"> 93</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="AzureLlm-94"><a href="#AzureLlm-94"><span class="linenos"> 94</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="AzureLlm-95"><a href="#AzureLlm-95"><span class="linenos"> 95</span></a>        <span class="n">api_key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="AzureLlm-96"><a href="#AzureLlm-96"><span class="linenos"> 96</span></a>        <span class="n">endpoint</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="AzureLlm-97"><a href="#AzureLlm-97"><span class="linenos"> 97</span></a>        <span class="n">api_version</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="AzureLlm-98"><a href="#AzureLlm-98"><span class="linenos"> 98</span></a>        <span class="n">deployment</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="AzureLlm-99"><a href="#AzureLlm-99"><span class="linenos"> 99</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="AzureLlm-100"><a href="#AzureLlm-100"><span class="linenos">100</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize the Azure Language Model client.</span>
</span><span id="AzureLlm-101"><a href="#AzureLlm-101"><span class="linenos">101</span></a>
</span><span id="AzureLlm-102"><a href="#AzureLlm-102"><span class="linenos">102</span></a><span class="sd">        Args:</span>
</span><span id="AzureLlm-103"><a href="#AzureLlm-103"><span class="linenos">103</span></a><span class="sd">            api_key: The Azure OpenAI API key.</span>
</span><span id="AzureLlm-104"><a href="#AzureLlm-104"><span class="linenos">104</span></a><span class="sd">            endpoint: The model&#39;s endpoint.</span>
</span><span id="AzureLlm-105"><a href="#AzureLlm-105"><span class="linenos">105</span></a><span class="sd">            api_version: The Azure OpenAI API version.</span>
</span><span id="AzureLlm-106"><a href="#AzureLlm-106"><span class="linenos">106</span></a><span class="sd">            deployment: The Azure OpenAI deployment.</span>
</span><span id="AzureLlm-107"><a href="#AzureLlm-107"><span class="linenos">107</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="AzureLlm-108"><a href="#AzureLlm-108"><span class="linenos">108</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">client</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">AsyncAzureOpenAI</span><span class="p">(</span>
</span><span id="AzureLlm-109"><a href="#AzureLlm-109"><span class="linenos">109</span></a>            <span class="n">api_key</span><span class="o">=</span><span class="n">api_key</span><span class="p">,</span>
</span><span id="AzureLlm-110"><a href="#AzureLlm-110"><span class="linenos">110</span></a>            <span class="n">azure_endpoint</span><span class="o">=</span><span class="n">endpoint</span><span class="p">,</span>
</span><span id="AzureLlm-111"><a href="#AzureLlm-111"><span class="linenos">111</span></a>            <span class="n">api_version</span><span class="o">=</span><span class="n">api_version</span><span class="p">,</span>
</span><span id="AzureLlm-112"><a href="#AzureLlm-112"><span class="linenos">112</span></a>        <span class="p">)</span>
</span><span id="AzureLlm-113"><a href="#AzureLlm-113"><span class="linenos">113</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">deployment</span>
</span><span id="AzureLlm-114"><a href="#AzureLlm-114"><span class="linenos">114</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_instructor</span> <span class="o">=</span> <span class="n">instructor</span><span class="o">.</span><span class="n">from_openai</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">client</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Azure OpenAI Large Language Models.</p>

<p>This class serves as an interface for Azure Large Language Models.
Both this class and OpenAiLlm inherit from the same base class as,
apart from initialization, the LLM clients behave the same.</p>
</div>


                            <div id="AzureLlm.__init__" class="classattr">
                                        <input id="AzureLlm.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">AzureLlm</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">api_key</span><span class="p">:</span> <span class="nb">str</span>, </span><span class="param"><span class="n">endpoint</span><span class="p">:</span> <span class="nb">str</span>, </span><span class="param"><span class="n">api_version</span><span class="p">:</span> <span class="nb">str</span>, </span><span class="param"><span class="n">deployment</span><span class="p">:</span> <span class="nb">str</span></span>)</span>

                <label class="view-source-button" for="AzureLlm.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#AzureLlm.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="AzureLlm.__init__-93"><a href="#AzureLlm.__init__-93"><span class="linenos"> 93</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="AzureLlm.__init__-94"><a href="#AzureLlm.__init__-94"><span class="linenos"> 94</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="AzureLlm.__init__-95"><a href="#AzureLlm.__init__-95"><span class="linenos"> 95</span></a>        <span class="n">api_key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="AzureLlm.__init__-96"><a href="#AzureLlm.__init__-96"><span class="linenos"> 96</span></a>        <span class="n">endpoint</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="AzureLlm.__init__-97"><a href="#AzureLlm.__init__-97"><span class="linenos"> 97</span></a>        <span class="n">api_version</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="AzureLlm.__init__-98"><a href="#AzureLlm.__init__-98"><span class="linenos"> 98</span></a>        <span class="n">deployment</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="AzureLlm.__init__-99"><a href="#AzureLlm.__init__-99"><span class="linenos"> 99</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="AzureLlm.__init__-100"><a href="#AzureLlm.__init__-100"><span class="linenos">100</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize the Azure Language Model client.</span>
</span><span id="AzureLlm.__init__-101"><a href="#AzureLlm.__init__-101"><span class="linenos">101</span></a>
</span><span id="AzureLlm.__init__-102"><a href="#AzureLlm.__init__-102"><span class="linenos">102</span></a><span class="sd">        Args:</span>
</span><span id="AzureLlm.__init__-103"><a href="#AzureLlm.__init__-103"><span class="linenos">103</span></a><span class="sd">            api_key: The Azure OpenAI API key.</span>
</span><span id="AzureLlm.__init__-104"><a href="#AzureLlm.__init__-104"><span class="linenos">104</span></a><span class="sd">            endpoint: The model&#39;s endpoint.</span>
</span><span id="AzureLlm.__init__-105"><a href="#AzureLlm.__init__-105"><span class="linenos">105</span></a><span class="sd">            api_version: The Azure OpenAI API version.</span>
</span><span id="AzureLlm.__init__-106"><a href="#AzureLlm.__init__-106"><span class="linenos">106</span></a><span class="sd">            deployment: The Azure OpenAI deployment.</span>
</span><span id="AzureLlm.__init__-107"><a href="#AzureLlm.__init__-107"><span class="linenos">107</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="AzureLlm.__init__-108"><a href="#AzureLlm.__init__-108"><span class="linenos">108</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">client</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">AsyncAzureOpenAI</span><span class="p">(</span>
</span><span id="AzureLlm.__init__-109"><a href="#AzureLlm.__init__-109"><span class="linenos">109</span></a>            <span class="n">api_key</span><span class="o">=</span><span class="n">api_key</span><span class="p">,</span>
</span><span id="AzureLlm.__init__-110"><a href="#AzureLlm.__init__-110"><span class="linenos">110</span></a>            <span class="n">azure_endpoint</span><span class="o">=</span><span class="n">endpoint</span><span class="p">,</span>
</span><span id="AzureLlm.__init__-111"><a href="#AzureLlm.__init__-111"><span class="linenos">111</span></a>            <span class="n">api_version</span><span class="o">=</span><span class="n">api_version</span><span class="p">,</span>
</span><span id="AzureLlm.__init__-112"><a href="#AzureLlm.__init__-112"><span class="linenos">112</span></a>        <span class="p">)</span>
</span><span id="AzureLlm.__init__-113"><a href="#AzureLlm.__init__-113"><span class="linenos">113</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">deployment</span>
</span><span id="AzureLlm.__init__-114"><a href="#AzureLlm.__init__-114"><span class="linenos">114</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_instructor</span> <span class="o">=</span> <span class="n">instructor</span><span class="o">.</span><span class="n">from_openai</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">client</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Initialize the Azure Language Model client.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>api_key:</strong>  The Azure OpenAI API key.</li>
<li><strong>endpoint:</strong>  The model's endpoint.</li>
<li><strong>api_version:</strong>  The Azure OpenAI API version.</li>
<li><strong>deployment:</strong>  The Azure OpenAI deployment.</li>
</ul>
</div>


                            </div>
                            <div id="AzureLlm.client" class="classattr">
                                <div class="attr variable">
            <span class="name">client</span>

        
    </div>
    <a class="headerlink" href="#AzureLlm.client"></a>
    
    

                            </div>
                            <div id="AzureLlm.model" class="classattr">
                                <div class="attr variable">
            <span class="name">model</span>

        
    </div>
    <a class="headerlink" href="#AzureLlm.model"></a>
    
    

                            </div>
                </section>
                <section id="LargeLanguageModel">
                            <input id="LargeLanguageModel-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">LargeLanguageModel</span><wbr>(<span class="base">pydantic.main.BaseModel</span>):

                <label class="view-source-button" for="LargeLanguageModel-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#LargeLanguageModel"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="LargeLanguageModel-65"><a href="#LargeLanguageModel-65"><span class="linenos"> 65</span></a><span class="k">class</span><span class="w"> </span><span class="nc">LargeLanguageModel</span><span class="p">(</span><span class="n">pydantic</span><span class="o">.</span><span class="n">BaseModel</span><span class="p">):</span>
</span><span id="LargeLanguageModel-66"><a href="#LargeLanguageModel-66"><span class="linenos"> 66</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Llm class that provides access to all available LLMs.</span>
</span><span id="LargeLanguageModel-67"><a href="#LargeLanguageModel-67"><span class="linenos"> 67</span></a>
</span><span id="LargeLanguageModel-68"><a href="#LargeLanguageModel-68"><span class="linenos"> 68</span></a><span class="sd">    Attributes:</span>
</span><span id="LargeLanguageModel-69"><a href="#LargeLanguageModel-69"><span class="linenos"> 69</span></a><span class="sd">        client: The client for the large language model.</span>
</span><span id="LargeLanguageModel-70"><a href="#LargeLanguageModel-70"><span class="linenos"> 70</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="LargeLanguageModel-71"><a href="#LargeLanguageModel-71"><span class="linenos"> 71</span></a>
</span><span id="LargeLanguageModel-72"><a href="#LargeLanguageModel-72"><span class="linenos"> 72</span></a>    <span class="n">model_config</span> <span class="o">=</span> <span class="n">pydantic</span><span class="o">.</span><span class="n">ConfigDict</span><span class="p">(</span><span class="n">arbitrary_types_allowed</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">frozen</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="LargeLanguageModel-73"><a href="#LargeLanguageModel-73"><span class="linenos"> 73</span></a>    <span class="n">client</span><span class="p">:</span> <span class="n">LlmBaseClass</span>
</span><span id="LargeLanguageModel-74"><a href="#LargeLanguageModel-74"><span class="linenos"> 74</span></a>
</span><span id="LargeLanguageModel-75"><a href="#LargeLanguageModel-75"><span class="linenos"> 75</span></a>    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">system_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">user_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
</span><span id="LargeLanguageModel-76"><a href="#LargeLanguageModel-76"><span class="linenos"> 76</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Runs the model with the given prompts.</span>
</span><span id="LargeLanguageModel-77"><a href="#LargeLanguageModel-77"><span class="linenos"> 77</span></a>
</span><span id="LargeLanguageModel-78"><a href="#LargeLanguageModel-78"><span class="linenos"> 78</span></a><span class="sd">        Args:</span>
</span><span id="LargeLanguageModel-79"><a href="#LargeLanguageModel-79"><span class="linenos"> 79</span></a><span class="sd">            system_prompt: The system prompt.</span>
</span><span id="LargeLanguageModel-80"><a href="#LargeLanguageModel-80"><span class="linenos"> 80</span></a><span class="sd">            user_prompt: The user prompt.</span>
</span><span id="LargeLanguageModel-81"><a href="#LargeLanguageModel-81"><span class="linenos"> 81</span></a>
</span><span id="LargeLanguageModel-82"><a href="#LargeLanguageModel-82"><span class="linenos"> 82</span></a><span class="sd">        Returns:</span>
</span><span id="LargeLanguageModel-83"><a href="#LargeLanguageModel-83"><span class="linenos"> 83</span></a><span class="sd">            The output text.</span>
</span><span id="LargeLanguageModel-84"><a href="#LargeLanguageModel-84"><span class="linenos"> 84</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="LargeLanguageModel-85"><a href="#LargeLanguageModel-85"><span class="linenos"> 85</span></a>        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
</span><span id="LargeLanguageModel-86"><a href="#LargeLanguageModel-86"><span class="linenos"> 86</span></a>            <span class="s2">&quot;Calling LLM run with: </span><span class="se">\n\n</span><span class="s2">System Prompt: </span><span class="si">%s</span><span class="se">\n</span><span class="s2">User Prompt: </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span>
</span><span id="LargeLanguageModel-87"><a href="#LargeLanguageModel-87"><span class="linenos"> 87</span></a>            <span class="n">system_prompt</span><span class="p">,</span>
</span><span id="LargeLanguageModel-88"><a href="#LargeLanguageModel-88"><span class="linenos"> 88</span></a>            <span class="n">user_prompt</span><span class="p">,</span>
</span><span id="LargeLanguageModel-89"><a href="#LargeLanguageModel-89"><span class="linenos"> 89</span></a>        <span class="p">)</span>
</span><span id="LargeLanguageModel-90"><a href="#LargeLanguageModel-90"><span class="linenos"> 90</span></a>        <span class="k">return</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">client</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">system_prompt</span><span class="p">,</span> <span class="n">user_prompt</span><span class="p">)</span>
</span><span id="LargeLanguageModel-91"><a href="#LargeLanguageModel-91"><span class="linenos"> 91</span></a>
</span><span id="LargeLanguageModel-92"><a href="#LargeLanguageModel-92"><span class="linenos"> 92</span></a>    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">call_instructor</span><span class="p">(</span>
</span><span id="LargeLanguageModel-93"><a href="#LargeLanguageModel-93"><span class="linenos"> 93</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="LargeLanguageModel-94"><a href="#LargeLanguageModel-94"><span class="linenos"> 94</span></a>        <span class="n">response_model</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="n">T</span><span class="p">],</span>
</span><span id="LargeLanguageModel-95"><a href="#LargeLanguageModel-95"><span class="linenos"> 95</span></a>        <span class="n">system_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="LargeLanguageModel-96"><a href="#LargeLanguageModel-96"><span class="linenos"> 96</span></a>        <span class="n">user_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="LargeLanguageModel-97"><a href="#LargeLanguageModel-97"><span class="linenos"> 97</span></a>        <span class="n">max_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4096</span><span class="p">,</span>
</span><span id="LargeLanguageModel-98"><a href="#LargeLanguageModel-98"><span class="linenos"> 98</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
</span><span id="LargeLanguageModel-99"><a href="#LargeLanguageModel-99"><span class="linenos"> 99</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Run a type-safe large language model query.</span>
</span><span id="LargeLanguageModel-100"><a href="#LargeLanguageModel-100"><span class="linenos">100</span></a>
</span><span id="LargeLanguageModel-101"><a href="#LargeLanguageModel-101"><span class="linenos">101</span></a><span class="sd">        Args:</span>
</span><span id="LargeLanguageModel-102"><a href="#LargeLanguageModel-102"><span class="linenos">102</span></a><span class="sd">            response_model: The Pydantic response model.</span>
</span><span id="LargeLanguageModel-103"><a href="#LargeLanguageModel-103"><span class="linenos">103</span></a><span class="sd">            system_prompt: The system prompt.</span>
</span><span id="LargeLanguageModel-104"><a href="#LargeLanguageModel-104"><span class="linenos">104</span></a><span class="sd">            user_prompt: The user prompt.</span>
</span><span id="LargeLanguageModel-105"><a href="#LargeLanguageModel-105"><span class="linenos">105</span></a><span class="sd">            max_tokens: The maximum number of tokens to allow.</span>
</span><span id="LargeLanguageModel-106"><a href="#LargeLanguageModel-106"><span class="linenos">106</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="LargeLanguageModel-107"><a href="#LargeLanguageModel-107"><span class="linenos">107</span></a>        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
</span><span id="LargeLanguageModel-108"><a href="#LargeLanguageModel-108"><span class="linenos">108</span></a>            <span class="s2">&quot;Calling instructor with: </span><span class="se">\n\n</span><span class="s2">System Prompt: </span><span class="si">%s</span><span class="se">\n\n</span><span class="s2">User Prompt: </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span>
</span><span id="LargeLanguageModel-109"><a href="#LargeLanguageModel-109"><span class="linenos">109</span></a>            <span class="n">system_prompt</span><span class="p">,</span>
</span><span id="LargeLanguageModel-110"><a href="#LargeLanguageModel-110"><span class="linenos">110</span></a>            <span class="n">user_prompt</span><span class="p">,</span>
</span><span id="LargeLanguageModel-111"><a href="#LargeLanguageModel-111"><span class="linenos">111</span></a>        <span class="p">)</span>
</span><span id="LargeLanguageModel-112"><a href="#LargeLanguageModel-112"><span class="linenos">112</span></a>        <span class="k">return</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">client</span><span class="o">.</span><span class="n">call_instructor</span><span class="p">(</span>
</span><span id="LargeLanguageModel-113"><a href="#LargeLanguageModel-113"><span class="linenos">113</span></a>            <span class="n">response_model</span><span class="p">,</span>
</span><span id="LargeLanguageModel-114"><a href="#LargeLanguageModel-114"><span class="linenos">114</span></a>            <span class="n">system_prompt</span><span class="p">,</span>
</span><span id="LargeLanguageModel-115"><a href="#LargeLanguageModel-115"><span class="linenos">115</span></a>            <span class="n">user_prompt</span><span class="p">,</span>
</span><span id="LargeLanguageModel-116"><a href="#LargeLanguageModel-116"><span class="linenos">116</span></a>            <span class="n">max_tokens</span><span class="p">,</span>
</span><span id="LargeLanguageModel-117"><a href="#LargeLanguageModel-117"><span class="linenos">117</span></a>        <span class="p">)</span>
</span><span id="LargeLanguageModel-118"><a href="#LargeLanguageModel-118"><span class="linenos">118</span></a>
</span><span id="LargeLanguageModel-119"><a href="#LargeLanguageModel-119"><span class="linenos">119</span></a>    <span class="nd">@overload</span>
</span><span id="LargeLanguageModel-120"><a href="#LargeLanguageModel-120"><span class="linenos">120</span></a>    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">chain_of_verification</span><span class="p">(</span>
</span><span id="LargeLanguageModel-121"><a href="#LargeLanguageModel-121"><span class="linenos">121</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="LargeLanguageModel-122"><a href="#LargeLanguageModel-122"><span class="linenos">122</span></a>        <span class="n">system_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="LargeLanguageModel-123"><a href="#LargeLanguageModel-123"><span class="linenos">123</span></a>        <span class="n">user_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="LargeLanguageModel-124"><a href="#LargeLanguageModel-124"><span class="linenos">124</span></a>        <span class="n">response_model</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="n">T</span><span class="p">],</span>
</span><span id="LargeLanguageModel-125"><a href="#LargeLanguageModel-125"><span class="linenos">125</span></a>        <span class="n">statements</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span>
</span><span id="LargeLanguageModel-126"><a href="#LargeLanguageModel-126"><span class="linenos">126</span></a>        <span class="o">*</span><span class="p">,</span>
</span><span id="LargeLanguageModel-127"><a href="#LargeLanguageModel-127"><span class="linenos">127</span></a>        <span class="n">max_verifications</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span>
</span><span id="LargeLanguageModel-128"><a href="#LargeLanguageModel-128"><span class="linenos">128</span></a>        <span class="n">create_new_statements</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
</span><span id="LargeLanguageModel-129"><a href="#LargeLanguageModel-129"><span class="linenos">129</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
</span><span id="LargeLanguageModel-130"><a href="#LargeLanguageModel-130"><span class="linenos">130</span></a>        <span class="k">pass</span>
</span><span id="LargeLanguageModel-131"><a href="#LargeLanguageModel-131"><span class="linenos">131</span></a>
</span><span id="LargeLanguageModel-132"><a href="#LargeLanguageModel-132"><span class="linenos">132</span></a>    <span class="nd">@overload</span>
</span><span id="LargeLanguageModel-133"><a href="#LargeLanguageModel-133"><span class="linenos">133</span></a>    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">chain_of_verification</span><span class="p">(</span>
</span><span id="LargeLanguageModel-134"><a href="#LargeLanguageModel-134"><span class="linenos">134</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="LargeLanguageModel-135"><a href="#LargeLanguageModel-135"><span class="linenos">135</span></a>        <span class="n">system_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="LargeLanguageModel-136"><a href="#LargeLanguageModel-136"><span class="linenos">136</span></a>        <span class="n">user_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="LargeLanguageModel-137"><a href="#LargeLanguageModel-137"><span class="linenos">137</span></a>        <span class="n">response_model</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="n">T</span><span class="p">],</span>
</span><span id="LargeLanguageModel-138"><a href="#LargeLanguageModel-138"><span class="linenos">138</span></a>        <span class="n">statements</span><span class="p">:</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="LargeLanguageModel-139"><a href="#LargeLanguageModel-139"><span class="linenos">139</span></a>        <span class="o">*</span><span class="p">,</span>
</span><span id="LargeLanguageModel-140"><a href="#LargeLanguageModel-140"><span class="linenos">140</span></a>        <span class="n">max_verifications</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">...</span><span class="p">,</span>
</span><span id="LargeLanguageModel-141"><a href="#LargeLanguageModel-141"><span class="linenos">141</span></a>        <span class="n">create_new_statements</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="kc">True</span><span class="p">],</span>
</span><span id="LargeLanguageModel-142"><a href="#LargeLanguageModel-142"><span class="linenos">142</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
</span><span id="LargeLanguageModel-143"><a href="#LargeLanguageModel-143"><span class="linenos">143</span></a>        <span class="k">pass</span>
</span><span id="LargeLanguageModel-144"><a href="#LargeLanguageModel-144"><span class="linenos">144</span></a>
</span><span id="LargeLanguageModel-145"><a href="#LargeLanguageModel-145"><span class="linenos">145</span></a>    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">chain_of_verification</span><span class="p">(</span>  <span class="c1"># noqa: PLR0913</span>
</span><span id="LargeLanguageModel-146"><a href="#LargeLanguageModel-146"><span class="linenos">146</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="LargeLanguageModel-147"><a href="#LargeLanguageModel-147"><span class="linenos">147</span></a>        <span class="n">system_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="LargeLanguageModel-148"><a href="#LargeLanguageModel-148"><span class="linenos">148</span></a>        <span class="n">user_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="LargeLanguageModel-149"><a href="#LargeLanguageModel-149"><span class="linenos">149</span></a>        <span class="n">response_model</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="n">T</span><span class="p">],</span>
</span><span id="LargeLanguageModel-150"><a href="#LargeLanguageModel-150"><span class="linenos">150</span></a>        <span class="n">statements</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="LargeLanguageModel-151"><a href="#LargeLanguageModel-151"><span class="linenos">151</span></a>        <span class="o">*</span><span class="p">,</span>
</span><span id="LargeLanguageModel-152"><a href="#LargeLanguageModel-152"><span class="linenos">152</span></a>        <span class="n">max_verifications</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
</span><span id="LargeLanguageModel-153"><a href="#LargeLanguageModel-153"><span class="linenos">153</span></a>        <span class="n">create_new_statements</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="LargeLanguageModel-154"><a href="#LargeLanguageModel-154"><span class="linenos">154</span></a>        <span class="n">error_on_iteration_limit</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="LargeLanguageModel-155"><a href="#LargeLanguageModel-155"><span class="linenos">155</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
</span><span id="LargeLanguageModel-156"><a href="#LargeLanguageModel-156"><span class="linenos">156</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Runs an LLM prompt that is self-assessed by the LLM.</span>
</span><span id="LargeLanguageModel-157"><a href="#LargeLanguageModel-157"><span class="linenos">157</span></a>
</span><span id="LargeLanguageModel-158"><a href="#LargeLanguageModel-158"><span class="linenos">158</span></a><span class="sd">        Args:</span>
</span><span id="LargeLanguageModel-159"><a href="#LargeLanguageModel-159"><span class="linenos">159</span></a><span class="sd">            system_prompt: The system prompt for the initial prompt.</span>
</span><span id="LargeLanguageModel-160"><a href="#LargeLanguageModel-160"><span class="linenos">160</span></a><span class="sd">            user_prompt: The user prompt for the initial prompt.</span>
</span><span id="LargeLanguageModel-161"><a href="#LargeLanguageModel-161"><span class="linenos">161</span></a><span class="sd">            response_model: The type of the response to return from Instructor.</span>
</span><span id="LargeLanguageModel-162"><a href="#LargeLanguageModel-162"><span class="linenos">162</span></a><span class="sd">            statements: Statements to verify the results.</span>
</span><span id="LargeLanguageModel-163"><a href="#LargeLanguageModel-163"><span class="linenos">163</span></a><span class="sd">            max_verifications: The maximum number of times to verify the results.</span>
</span><span id="LargeLanguageModel-164"><a href="#LargeLanguageModel-164"><span class="linenos">164</span></a><span class="sd">            create_new_statements: If True, generate new statements from the system</span>
</span><span id="LargeLanguageModel-165"><a href="#LargeLanguageModel-165"><span class="linenos">165</span></a><span class="sd">                prompt.</span>
</span><span id="LargeLanguageModel-166"><a href="#LargeLanguageModel-166"><span class="linenos">166</span></a><span class="sd">            error_on_iteration_limit: If True, raise an exception when the</span>
</span><span id="LargeLanguageModel-167"><a href="#LargeLanguageModel-167"><span class="linenos">167</span></a><span class="sd">                iteration limit is reached. Otherwise, returns the last result.</span>
</span><span id="LargeLanguageModel-168"><a href="#LargeLanguageModel-168"><span class="linenos">168</span></a>
</span><span id="LargeLanguageModel-169"><a href="#LargeLanguageModel-169"><span class="linenos">169</span></a><span class="sd">        Returns:</span>
</span><span id="LargeLanguageModel-170"><a href="#LargeLanguageModel-170"><span class="linenos">170</span></a><span class="sd">            The edited text result.</span>
</span><span id="LargeLanguageModel-171"><a href="#LargeLanguageModel-171"><span class="linenos">171</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="LargeLanguageModel-172"><a href="#LargeLanguageModel-172"><span class="linenos">172</span></a>        <span class="k">if</span> <span class="n">max_verifications</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="LargeLanguageModel-173"><a href="#LargeLanguageModel-173"><span class="linenos">173</span></a>            <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;max_verifications must be positive&quot;</span>
</span><span id="LargeLanguageModel-174"><a href="#LargeLanguageModel-174"><span class="linenos">174</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
</span><span id="LargeLanguageModel-175"><a href="#LargeLanguageModel-175"><span class="linenos">175</span></a>
</span><span id="LargeLanguageModel-176"><a href="#LargeLanguageModel-176"><span class="linenos">176</span></a>        <span class="k">if</span> <span class="n">statements</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">create_new_statements</span><span class="p">:</span>
</span><span id="LargeLanguageModel-177"><a href="#LargeLanguageModel-177"><span class="linenos">177</span></a>            <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;If no statements are provided, then they must be generated.&quot;</span>
</span><span id="LargeLanguageModel-178"><a href="#LargeLanguageModel-178"><span class="linenos">178</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
</span><span id="LargeLanguageModel-179"><a href="#LargeLanguageModel-179"><span class="linenos">179</span></a>        <span class="n">statements</span> <span class="o">=</span> <span class="n">statements</span> <span class="ow">or</span> <span class="p">[]</span>
</span><span id="LargeLanguageModel-180"><a href="#LargeLanguageModel-180"><span class="linenos">180</span></a>
</span><span id="LargeLanguageModel-181"><a href="#LargeLanguageModel-181"><span class="linenos">181</span></a>        <span class="k">if</span> <span class="n">create_new_statements</span><span class="p">:</span>
</span><span id="LargeLanguageModel-182"><a href="#LargeLanguageModel-182"><span class="linenos">182</span></a>            <span class="n">new_statements</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_statements</span><span class="p">(</span><span class="n">system_prompt</span><span class="p">)</span>
</span><span id="LargeLanguageModel-183"><a href="#LargeLanguageModel-183"><span class="linenos">183</span></a>            <span class="n">statements</span> <span class="o">+=</span> <span class="p">[</span><span class="n">statement</span><span class="o">.</span><span class="n">statement</span> <span class="k">for</span> <span class="n">statement</span> <span class="ow">in</span> <span class="n">new_statements</span><span class="p">]</span>
</span><span id="LargeLanguageModel-184"><a href="#LargeLanguageModel-184"><span class="linenos">184</span></a>        <span class="n">verification_prompt</span> <span class="o">=</span> <span class="n">prompts</span><span class="o">.</span><span class="n">chain_of_verification_verify</span><span class="p">(</span><span class="n">statements</span><span class="p">)</span>
</span><span id="LargeLanguageModel-185"><a href="#LargeLanguageModel-185"><span class="linenos">185</span></a>
</span><span id="LargeLanguageModel-186"><a href="#LargeLanguageModel-186"><span class="linenos">186</span></a>        <span class="n">rewrite_prompt</span> <span class="o">=</span> <span class="n">prompts</span><span class="o">.</span><span class="n">chain_of_verification_rewrite</span><span class="p">(</span>
</span><span id="LargeLanguageModel-187"><a href="#LargeLanguageModel-187"><span class="linenos">187</span></a>            <span class="n">statements</span><span class="o">=</span><span class="n">statements</span><span class="p">,</span>
</span><span id="LargeLanguageModel-188"><a href="#LargeLanguageModel-188"><span class="linenos">188</span></a>            <span class="n">instructions</span><span class="o">=</span><span class="n">system_prompt</span><span class="p">,</span>
</span><span id="LargeLanguageModel-189"><a href="#LargeLanguageModel-189"><span class="linenos">189</span></a>            <span class="n">source</span><span class="o">=</span><span class="n">user_prompt</span><span class="p">,</span>
</span><span id="LargeLanguageModel-190"><a href="#LargeLanguageModel-190"><span class="linenos">190</span></a>        <span class="p">)</span>
</span><span id="LargeLanguageModel-191"><a href="#LargeLanguageModel-191"><span class="linenos">191</span></a>
</span><span id="LargeLanguageModel-192"><a href="#LargeLanguageModel-192"><span class="linenos">192</span></a>        <span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="LargeLanguageModel-193"><a href="#LargeLanguageModel-193"><span class="linenos">193</span></a>        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_verifications</span><span class="p">):</span>
</span><span id="LargeLanguageModel-194"><a href="#LargeLanguageModel-194"><span class="linenos">194</span></a>            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Running verification iteration </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">idx</span><span class="p">)</span>
</span><span id="LargeLanguageModel-195"><a href="#LargeLanguageModel-195"><span class="linenos">195</span></a>            <span class="k">if</span> <span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="LargeLanguageModel-196"><a href="#LargeLanguageModel-196"><span class="linenos">196</span></a>                <span class="n">model</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">call_instructor</span><span class="p">(</span>
</span><span id="LargeLanguageModel-197"><a href="#LargeLanguageModel-197"><span class="linenos">197</span></a>                    <span class="n">response_model</span><span class="o">=</span><span class="n">response_model</span><span class="p">,</span>
</span><span id="LargeLanguageModel-198"><a href="#LargeLanguageModel-198"><span class="linenos">198</span></a>                    <span class="n">system_prompt</span><span class="o">=</span><span class="n">system_prompt</span><span class="p">,</span>
</span><span id="LargeLanguageModel-199"><a href="#LargeLanguageModel-199"><span class="linenos">199</span></a>                    <span class="n">user_prompt</span><span class="o">=</span><span class="n">user_prompt</span><span class="p">,</span>
</span><span id="LargeLanguageModel-200"><a href="#LargeLanguageModel-200"><span class="linenos">200</span></a>                <span class="p">)</span>
</span><span id="LargeLanguageModel-201"><a href="#LargeLanguageModel-201"><span class="linenos">201</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="LargeLanguageModel-202"><a href="#LargeLanguageModel-202"><span class="linenos">202</span></a>                <span class="n">model</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">call_instructor</span><span class="p">(</span>
</span><span id="LargeLanguageModel-203"><a href="#LargeLanguageModel-203"><span class="linenos">203</span></a>                    <span class="n">response_model</span><span class="o">=</span><span class="n">response_model</span><span class="p">,</span>
</span><span id="LargeLanguageModel-204"><a href="#LargeLanguageModel-204"><span class="linenos">204</span></a>                    <span class="n">system_prompt</span><span class="o">=</span><span class="n">rewrite_prompt</span><span class="p">,</span>
</span><span id="LargeLanguageModel-205"><a href="#LargeLanguageModel-205"><span class="linenos">205</span></a>                    <span class="n">user_prompt</span><span class="o">=</span><span class="n">_model_to_string</span><span class="p">(</span><span class="n">model</span><span class="p">),</span>
</span><span id="LargeLanguageModel-206"><a href="#LargeLanguageModel-206"><span class="linenos">206</span></a>                <span class="p">)</span>
</span><span id="LargeLanguageModel-207"><a href="#LargeLanguageModel-207"><span class="linenos">207</span></a>
</span><span id="LargeLanguageModel-208"><a href="#LargeLanguageModel-208"><span class="linenos">208</span></a>            <span class="n">text</span> <span class="o">=</span> <span class="n">_model_to_string</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</span><span id="LargeLanguageModel-209"><a href="#LargeLanguageModel-209"><span class="linenos">209</span></a>            <span class="n">verify</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">call_instructor</span><span class="p">(</span>
</span><span id="LargeLanguageModel-210"><a href="#LargeLanguageModel-210"><span class="linenos">210</span></a>                <span class="n">response_model</span><span class="o">=</span><span class="nb">list</span><span class="p">[</span><span class="n">_VerificationStatement</span><span class="p">],</span>
</span><span id="LargeLanguageModel-211"><a href="#LargeLanguageModel-211"><span class="linenos">211</span></a>                <span class="n">system_prompt</span><span class="o">=</span><span class="n">verification_prompt</span><span class="p">,</span>
</span><span id="LargeLanguageModel-212"><a href="#LargeLanguageModel-212"><span class="linenos">212</span></a>                <span class="n">user_prompt</span><span class="o">=</span><span class="n">text</span><span class="p">,</span>
</span><span id="LargeLanguageModel-213"><a href="#LargeLanguageModel-213"><span class="linenos">213</span></a>                <span class="n">max_tokens</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span>
</span><span id="LargeLanguageModel-214"><a href="#LargeLanguageModel-214"><span class="linenos">214</span></a>            <span class="p">)</span>
</span><span id="LargeLanguageModel-215"><a href="#LargeLanguageModel-215"><span class="linenos">215</span></a>
</span><span id="LargeLanguageModel-216"><a href="#LargeLanguageModel-216"><span class="linenos">216</span></a>            <span class="k">if</span> <span class="n">idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="LargeLanguageModel-217"><a href="#LargeLanguageModel-217"><span class="linenos">217</span></a>                <span class="k">continue</span>
</span><span id="LargeLanguageModel-218"><a href="#LargeLanguageModel-218"><span class="linenos">218</span></a>            <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="n">verification</span><span class="o">.</span><span class="n">correct</span> <span class="k">for</span> <span class="n">verification</span> <span class="ow">in</span> <span class="n">verify</span><span class="p">):</span>
</span><span id="LargeLanguageModel-219"><a href="#LargeLanguageModel-219"><span class="linenos">219</span></a>                <span class="k">break</span>
</span><span id="LargeLanguageModel-220"><a href="#LargeLanguageModel-220"><span class="linenos">220</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="LargeLanguageModel-221"><a href="#LargeLanguageModel-221"><span class="linenos">221</span></a>            <span class="k">if</span> <span class="n">error_on_iteration_limit</span><span class="p">:</span>
</span><span id="LargeLanguageModel-222"><a href="#LargeLanguageModel-222"><span class="linenos">222</span></a>                <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;Maximum number of iterations reached.&quot;</span>
</span><span id="LargeLanguageModel-223"><a href="#LargeLanguageModel-223"><span class="linenos">223</span></a>                <span class="k">raise</span> <span class="n">exceptions</span><span class="o">.</span><span class="n">IterationLimitError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
</span><span id="LargeLanguageModel-224"><a href="#LargeLanguageModel-224"><span class="linenos">224</span></a>
</span><span id="LargeLanguageModel-225"><a href="#LargeLanguageModel-225"><span class="linenos">225</span></a>        <span class="k">return</span> <span class="n">model</span>  <span class="c1"># type: ignore[return-value] # model will never be None as the for-loop is always entered.</span>
</span><span id="LargeLanguageModel-226"><a href="#LargeLanguageModel-226"><span class="linenos">226</span></a>
</span><span id="LargeLanguageModel-227"><a href="#LargeLanguageModel-227"><span class="linenos">227</span></a>    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">chain_of_density</span><span class="p">(</span>
</span><span id="LargeLanguageModel-228"><a href="#LargeLanguageModel-228"><span class="linenos">228</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="LargeLanguageModel-229"><a href="#LargeLanguageModel-229"><span class="linenos">229</span></a>        <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="LargeLanguageModel-230"><a href="#LargeLanguageModel-230"><span class="linenos">230</span></a>        <span class="n">repeats</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
</span><span id="LargeLanguageModel-231"><a href="#LargeLanguageModel-231"><span class="linenos">231</span></a>        <span class="o">*</span><span class="p">,</span>
</span><span id="LargeLanguageModel-232"><a href="#LargeLanguageModel-232"><span class="linenos">232</span></a>        <span class="n">max_informative_entities</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
</span><span id="LargeLanguageModel-233"><a href="#LargeLanguageModel-233"><span class="linenos">233</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
</span><span id="LargeLanguageModel-234"><a href="#LargeLanguageModel-234"><span class="linenos">234</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Iterative summarization of an input text.</span>
</span><span id="LargeLanguageModel-235"><a href="#LargeLanguageModel-235"><span class="linenos">235</span></a>
</span><span id="LargeLanguageModel-236"><a href="#LargeLanguageModel-236"><span class="linenos">236</span></a><span class="sd">        Chain of density performs an iterative summarization of an input text. It</span>
</span><span id="LargeLanguageModel-237"><a href="#LargeLanguageModel-237"><span class="linenos">237</span></a><span class="sd">        should,</span>
</span><span id="LargeLanguageModel-238"><a href="#LargeLanguageModel-238"><span class="linenos">238</span></a><span class="sd">        in theory, provide more robust summaries than single-shot approaches.</span>
</span><span id="LargeLanguageModel-239"><a href="#LargeLanguageModel-239"><span class="linenos">239</span></a>
</span><span id="LargeLanguageModel-240"><a href="#LargeLanguageModel-240"><span class="linenos">240</span></a><span class="sd">        Args:</span>
</span><span id="LargeLanguageModel-241"><a href="#LargeLanguageModel-241"><span class="linenos">241</span></a><span class="sd">            text: The input text to summarize</span>
</span><span id="LargeLanguageModel-242"><a href="#LargeLanguageModel-242"><span class="linenos">242</span></a><span class="sd">            repeats: The number of times to summarize.</span>
</span><span id="LargeLanguageModel-243"><a href="#LargeLanguageModel-243"><span class="linenos">243</span></a><span class="sd">            max_informative_entities: The maximum number of new entities to include in</span>
</span><span id="LargeLanguageModel-244"><a href="#LargeLanguageModel-244"><span class="linenos">244</span></a><span class="sd">                each summary.</span>
</span><span id="LargeLanguageModel-245"><a href="#LargeLanguageModel-245"><span class="linenos">245</span></a>
</span><span id="LargeLanguageModel-246"><a href="#LargeLanguageModel-246"><span class="linenos">246</span></a><span class="sd">        Returns:</span>
</span><span id="LargeLanguageModel-247"><a href="#LargeLanguageModel-247"><span class="linenos">247</span></a><span class="sd">            The summarized text.</span>
</span><span id="LargeLanguageModel-248"><a href="#LargeLanguageModel-248"><span class="linenos">248</span></a>
</span><span id="LargeLanguageModel-249"><a href="#LargeLanguageModel-249"><span class="linenos">249</span></a><span class="sd">        References:</span>
</span><span id="LargeLanguageModel-250"><a href="#LargeLanguageModel-250"><span class="linenos">250</span></a><span class="sd">            Adams, G., Fabbri, A. R., Ladhak, F., Lehman, E., &amp; Elhadad, N. (2023,</span>
</span><span id="LargeLanguageModel-251"><a href="#LargeLanguageModel-251"><span class="linenos">251</span></a><span class="sd">            December). From sparse to dense: GPT-4 summarization with chain of</span>
</span><span id="LargeLanguageModel-252"><a href="#LargeLanguageModel-252"><span class="linenos">252</span></a><span class="sd">            density prompting. In Proceedings of the Conference on Empirical Methods</span>
</span><span id="LargeLanguageModel-253"><a href="#LargeLanguageModel-253"><span class="linenos">253</span></a><span class="sd">            in Natural Language Processing. Conference on Empirical Methods in</span>
</span><span id="LargeLanguageModel-254"><a href="#LargeLanguageModel-254"><span class="linenos">254</span></a><span class="sd">            Natural Language Processing (Vol. 2023, No. 4th New Frontier</span>
</span><span id="LargeLanguageModel-255"><a href="#LargeLanguageModel-255"><span class="linenos">255</span></a><span class="sd">            Summarization Workshop, p. 68).</span>
</span><span id="LargeLanguageModel-256"><a href="#LargeLanguageModel-256"><span class="linenos">256</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="LargeLanguageModel-257"><a href="#LargeLanguageModel-257"><span class="linenos">257</span></a>        <span class="n">system_prompt</span> <span class="o">=</span> <span class="n">prompts</span><span class="o">.</span><span class="n">chain_of_density</span><span class="p">(</span><span class="n">article</span><span class="o">=</span><span class="n">text</span><span class="p">)</span>
</span><span id="LargeLanguageModel-258"><a href="#LargeLanguageModel-258"><span class="linenos">258</span></a>        <span class="k">if</span> <span class="n">repeats</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="LargeLanguageModel-259"><a href="#LargeLanguageModel-259"><span class="linenos">259</span></a>            <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;Repeat count must be positive&quot;</span>
</span><span id="LargeLanguageModel-260"><a href="#LargeLanguageModel-260"><span class="linenos">260</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
</span><span id="LargeLanguageModel-261"><a href="#LargeLanguageModel-261"><span class="linenos">261</span></a>
</span><span id="LargeLanguageModel-262"><a href="#LargeLanguageModel-262"><span class="linenos">262</span></a>        <span class="k">class</span><span class="w"> </span><span class="nc">Response</span><span class="p">(</span><span class="n">pydantic</span><span class="o">.</span><span class="n">BaseModel</span><span class="p">):</span>
</span><span id="LargeLanguageModel-263"><a href="#LargeLanguageModel-263"><span class="linenos">263</span></a>            <span class="n">missing_informative_entity</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">pydantic</span><span class="o">.</span><span class="n">Field</span><span class="p">(</span>
</span><span id="LargeLanguageModel-264"><a href="#LargeLanguageModel-264"><span class="linenos">264</span></a>                <span class="o">...</span><span class="p">,</span>
</span><span id="LargeLanguageModel-265"><a href="#LargeLanguageModel-265"><span class="linenos">265</span></a>                <span class="n">min_length</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="LargeLanguageModel-266"><a href="#LargeLanguageModel-266"><span class="linenos">266</span></a>                <span class="n">max_length</span><span class="o">=</span><span class="n">max_informative_entities</span><span class="p">,</span>
</span><span id="LargeLanguageModel-267"><a href="#LargeLanguageModel-267"><span class="linenos">267</span></a>            <span class="p">)</span>
</span><span id="LargeLanguageModel-268"><a href="#LargeLanguageModel-268"><span class="linenos">268</span></a>            <span class="n">summary</span><span class="p">:</span> <span class="nb">str</span>
</span><span id="LargeLanguageModel-269"><a href="#LargeLanguageModel-269"><span class="linenos">269</span></a>
</span><span id="LargeLanguageModel-270"><a href="#LargeLanguageModel-270"><span class="linenos">270</span></a>        <span class="n">summary</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
</span><span id="LargeLanguageModel-271"><a href="#LargeLanguageModel-271"><span class="linenos">271</span></a>        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">repeats</span><span class="p">):</span>
</span><span id="LargeLanguageModel-272"><a href="#LargeLanguageModel-272"><span class="linenos">272</span></a>            <span class="n">user_prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Current Summary: </span><span class="si">{</span><span class="n">summary</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="LargeLanguageModel-273"><a href="#LargeLanguageModel-273"><span class="linenos">273</span></a>            <span class="n">iteration</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">call_instructor</span><span class="p">(</span>
</span><span id="LargeLanguageModel-274"><a href="#LargeLanguageModel-274"><span class="linenos">274</span></a>                <span class="n">response_model</span><span class="o">=</span><span class="n">Response</span><span class="p">,</span>
</span><span id="LargeLanguageModel-275"><a href="#LargeLanguageModel-275"><span class="linenos">275</span></a>                <span class="n">system_prompt</span><span class="o">=</span><span class="n">system_prompt</span><span class="p">,</span>
</span><span id="LargeLanguageModel-276"><a href="#LargeLanguageModel-276"><span class="linenos">276</span></a>                <span class="n">user_prompt</span><span class="o">=</span><span class="n">user_prompt</span><span class="p">,</span>
</span><span id="LargeLanguageModel-277"><a href="#LargeLanguageModel-277"><span class="linenos">277</span></a>            <span class="p">)</span>
</span><span id="LargeLanguageModel-278"><a href="#LargeLanguageModel-278"><span class="linenos">278</span></a>            <span class="n">summary</span> <span class="o">=</span> <span class="n">iteration</span><span class="o">.</span><span class="n">summary</span>
</span><span id="LargeLanguageModel-279"><a href="#LargeLanguageModel-279"><span class="linenos">279</span></a>        <span class="k">return</span> <span class="n">summary</span>
</span><span id="LargeLanguageModel-280"><a href="#LargeLanguageModel-280"><span class="linenos">280</span></a>
</span><span id="LargeLanguageModel-281"><a href="#LargeLanguageModel-281"><span class="linenos">281</span></a>    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">_create_statements</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">instructions</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">_GeneratedStatement</span><span class="p">]:</span>
</span><span id="LargeLanguageModel-282"><a href="#LargeLanguageModel-282"><span class="linenos">282</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Creates statements for prompt result validation.</span>
</span><span id="LargeLanguageModel-283"><a href="#LargeLanguageModel-283"><span class="linenos">283</span></a>
</span><span id="LargeLanguageModel-284"><a href="#LargeLanguageModel-284"><span class="linenos">284</span></a><span class="sd">        Args:</span>
</span><span id="LargeLanguageModel-285"><a href="#LargeLanguageModel-285"><span class="linenos">285</span></a><span class="sd">            instructions: The instructions provided to the model, commonly</span>
</span><span id="LargeLanguageModel-286"><a href="#LargeLanguageModel-286"><span class="linenos">286</span></a><span class="sd">                the system prompt.</span>
</span><span id="LargeLanguageModel-287"><a href="#LargeLanguageModel-287"><span class="linenos">287</span></a>
</span><span id="LargeLanguageModel-288"><a href="#LargeLanguageModel-288"><span class="linenos">288</span></a><span class="sd">        Returns:</span>
</span><span id="LargeLanguageModel-289"><a href="#LargeLanguageModel-289"><span class="linenos">289</span></a><span class="sd">            List of verification statements as strings.</span>
</span><span id="LargeLanguageModel-290"><a href="#LargeLanguageModel-290"><span class="linenos">290</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="LargeLanguageModel-291"><a href="#LargeLanguageModel-291"><span class="linenos">291</span></a>        <span class="n">statements</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">call_instructor</span><span class="p">(</span>
</span><span id="LargeLanguageModel-292"><a href="#LargeLanguageModel-292"><span class="linenos">292</span></a>            <span class="nb">list</span><span class="p">[</span><span class="n">_GeneratedStatement</span><span class="p">],</span>
</span><span id="LargeLanguageModel-293"><a href="#LargeLanguageModel-293"><span class="linenos">293</span></a>            <span class="n">system_prompt</span><span class="o">=</span><span class="n">prompts</span><span class="o">.</span><span class="n">chain_of_verification_create_statements</span><span class="p">(),</span>
</span><span id="LargeLanguageModel-294"><a href="#LargeLanguageModel-294"><span class="linenos">294</span></a>            <span class="n">user_prompt</span><span class="o">=</span><span class="n">instructions</span><span class="p">,</span>
</span><span id="LargeLanguageModel-295"><a href="#LargeLanguageModel-295"><span class="linenos">295</span></a>            <span class="n">max_tokens</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span>
</span><span id="LargeLanguageModel-296"><a href="#LargeLanguageModel-296"><span class="linenos">296</span></a>        <span class="p">)</span>
</span><span id="LargeLanguageModel-297"><a href="#LargeLanguageModel-297"><span class="linenos">297</span></a>        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Created statements: </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">statements</span><span class="p">)</span>
</span><span id="LargeLanguageModel-298"><a href="#LargeLanguageModel-298"><span class="linenos">298</span></a>        <span class="k">return</span> <span class="n">statements</span>
</span></pre></div>


            <div class="docstring"><p>Llm class that provides access to all available LLMs.</p>

<h6 id="attributes">Attributes:</h6>

<ul>
<li><strong>client:</strong>  The client for the large language model.</li>
</ul>
</div>


                            <div id="LargeLanguageModel.model_config" class="classattr">
                                <div class="attr variable">
            <span class="name">model_config</span>        =
<span class="default_value">{&#39;arbitrary_types_allowed&#39;: True, &#39;frozen&#39;: True}</span>

        
    </div>
    <a class="headerlink" href="#LargeLanguageModel.model_config"></a>
    
            <div class="docstring"><p>Configuration for the model, should be a dictionary conforming to [<code>ConfigDict</code>][pydantic.config.ConfigDict].</p>
</div>


                            </div>
                            <div id="LargeLanguageModel.client" class="classattr">
                                <div class="attr variable">
            <span class="name">client</span><span class="annotation">: cloai.llm.utils.LlmBaseClass</span>

        
    </div>
    <a class="headerlink" href="#LargeLanguageModel.client"></a>
    
    

                            </div>
                            <div id="LargeLanguageModel.run" class="classattr">
                                        <input id="LargeLanguageModel.run-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">async def</span>
        <span class="name">run</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">system_prompt</span><span class="p">:</span> <span class="nb">str</span>, </span><span class="param"><span class="n">user_prompt</span><span class="p">:</span> <span class="nb">str</span></span><span class="return-annotation">) -> <span class="nb">str</span>:</span></span>

                <label class="view-source-button" for="LargeLanguageModel.run-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#LargeLanguageModel.run"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="LargeLanguageModel.run-75"><a href="#LargeLanguageModel.run-75"><span class="linenos">75</span></a>    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">system_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">user_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
</span><span id="LargeLanguageModel.run-76"><a href="#LargeLanguageModel.run-76"><span class="linenos">76</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Runs the model with the given prompts.</span>
</span><span id="LargeLanguageModel.run-77"><a href="#LargeLanguageModel.run-77"><span class="linenos">77</span></a>
</span><span id="LargeLanguageModel.run-78"><a href="#LargeLanguageModel.run-78"><span class="linenos">78</span></a><span class="sd">        Args:</span>
</span><span id="LargeLanguageModel.run-79"><a href="#LargeLanguageModel.run-79"><span class="linenos">79</span></a><span class="sd">            system_prompt: The system prompt.</span>
</span><span id="LargeLanguageModel.run-80"><a href="#LargeLanguageModel.run-80"><span class="linenos">80</span></a><span class="sd">            user_prompt: The user prompt.</span>
</span><span id="LargeLanguageModel.run-81"><a href="#LargeLanguageModel.run-81"><span class="linenos">81</span></a>
</span><span id="LargeLanguageModel.run-82"><a href="#LargeLanguageModel.run-82"><span class="linenos">82</span></a><span class="sd">        Returns:</span>
</span><span id="LargeLanguageModel.run-83"><a href="#LargeLanguageModel.run-83"><span class="linenos">83</span></a><span class="sd">            The output text.</span>
</span><span id="LargeLanguageModel.run-84"><a href="#LargeLanguageModel.run-84"><span class="linenos">84</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="LargeLanguageModel.run-85"><a href="#LargeLanguageModel.run-85"><span class="linenos">85</span></a>        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
</span><span id="LargeLanguageModel.run-86"><a href="#LargeLanguageModel.run-86"><span class="linenos">86</span></a>            <span class="s2">&quot;Calling LLM run with: </span><span class="se">\n\n</span><span class="s2">System Prompt: </span><span class="si">%s</span><span class="se">\n</span><span class="s2">User Prompt: </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span>
</span><span id="LargeLanguageModel.run-87"><a href="#LargeLanguageModel.run-87"><span class="linenos">87</span></a>            <span class="n">system_prompt</span><span class="p">,</span>
</span><span id="LargeLanguageModel.run-88"><a href="#LargeLanguageModel.run-88"><span class="linenos">88</span></a>            <span class="n">user_prompt</span><span class="p">,</span>
</span><span id="LargeLanguageModel.run-89"><a href="#LargeLanguageModel.run-89"><span class="linenos">89</span></a>        <span class="p">)</span>
</span><span id="LargeLanguageModel.run-90"><a href="#LargeLanguageModel.run-90"><span class="linenos">90</span></a>        <span class="k">return</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">client</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">system_prompt</span><span class="p">,</span> <span class="n">user_prompt</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Runs the model with the given prompts.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>system_prompt:</strong>  The system prompt.</li>
<li><strong>user_prompt:</strong>  The user prompt.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>The output text.</p>
</blockquote>
</div>


                            </div>
                            <div id="LargeLanguageModel.call_instructor" class="classattr">
                                        <input id="LargeLanguageModel.call_instructor-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">async def</span>
        <span class="name">call_instructor</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">response_model</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="o">~</span><span class="n">T</span><span class="p">]</span>,</span><span class="param">	<span class="n">system_prompt</span><span class="p">:</span> <span class="nb">str</span>,</span><span class="param">	<span class="n">user_prompt</span><span class="p">:</span> <span class="nb">str</span>,</span><span class="param">	<span class="n">max_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4096</span></span><span class="return-annotation">) -> <span class="o">~</span><span class="n">T</span>:</span></span>

                <label class="view-source-button" for="LargeLanguageModel.call_instructor-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#LargeLanguageModel.call_instructor"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="LargeLanguageModel.call_instructor-92"><a href="#LargeLanguageModel.call_instructor-92"><span class="linenos"> 92</span></a>    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">call_instructor</span><span class="p">(</span>
</span><span id="LargeLanguageModel.call_instructor-93"><a href="#LargeLanguageModel.call_instructor-93"><span class="linenos"> 93</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="LargeLanguageModel.call_instructor-94"><a href="#LargeLanguageModel.call_instructor-94"><span class="linenos"> 94</span></a>        <span class="n">response_model</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="n">T</span><span class="p">],</span>
</span><span id="LargeLanguageModel.call_instructor-95"><a href="#LargeLanguageModel.call_instructor-95"><span class="linenos"> 95</span></a>        <span class="n">system_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="LargeLanguageModel.call_instructor-96"><a href="#LargeLanguageModel.call_instructor-96"><span class="linenos"> 96</span></a>        <span class="n">user_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="LargeLanguageModel.call_instructor-97"><a href="#LargeLanguageModel.call_instructor-97"><span class="linenos"> 97</span></a>        <span class="n">max_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4096</span><span class="p">,</span>
</span><span id="LargeLanguageModel.call_instructor-98"><a href="#LargeLanguageModel.call_instructor-98"><span class="linenos"> 98</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
</span><span id="LargeLanguageModel.call_instructor-99"><a href="#LargeLanguageModel.call_instructor-99"><span class="linenos"> 99</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Run a type-safe large language model query.</span>
</span><span id="LargeLanguageModel.call_instructor-100"><a href="#LargeLanguageModel.call_instructor-100"><span class="linenos">100</span></a>
</span><span id="LargeLanguageModel.call_instructor-101"><a href="#LargeLanguageModel.call_instructor-101"><span class="linenos">101</span></a><span class="sd">        Args:</span>
</span><span id="LargeLanguageModel.call_instructor-102"><a href="#LargeLanguageModel.call_instructor-102"><span class="linenos">102</span></a><span class="sd">            response_model: The Pydantic response model.</span>
</span><span id="LargeLanguageModel.call_instructor-103"><a href="#LargeLanguageModel.call_instructor-103"><span class="linenos">103</span></a><span class="sd">            system_prompt: The system prompt.</span>
</span><span id="LargeLanguageModel.call_instructor-104"><a href="#LargeLanguageModel.call_instructor-104"><span class="linenos">104</span></a><span class="sd">            user_prompt: The user prompt.</span>
</span><span id="LargeLanguageModel.call_instructor-105"><a href="#LargeLanguageModel.call_instructor-105"><span class="linenos">105</span></a><span class="sd">            max_tokens: The maximum number of tokens to allow.</span>
</span><span id="LargeLanguageModel.call_instructor-106"><a href="#LargeLanguageModel.call_instructor-106"><span class="linenos">106</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="LargeLanguageModel.call_instructor-107"><a href="#LargeLanguageModel.call_instructor-107"><span class="linenos">107</span></a>        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
</span><span id="LargeLanguageModel.call_instructor-108"><a href="#LargeLanguageModel.call_instructor-108"><span class="linenos">108</span></a>            <span class="s2">&quot;Calling instructor with: </span><span class="se">\n\n</span><span class="s2">System Prompt: </span><span class="si">%s</span><span class="se">\n\n</span><span class="s2">User Prompt: </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span>
</span><span id="LargeLanguageModel.call_instructor-109"><a href="#LargeLanguageModel.call_instructor-109"><span class="linenos">109</span></a>            <span class="n">system_prompt</span><span class="p">,</span>
</span><span id="LargeLanguageModel.call_instructor-110"><a href="#LargeLanguageModel.call_instructor-110"><span class="linenos">110</span></a>            <span class="n">user_prompt</span><span class="p">,</span>
</span><span id="LargeLanguageModel.call_instructor-111"><a href="#LargeLanguageModel.call_instructor-111"><span class="linenos">111</span></a>        <span class="p">)</span>
</span><span id="LargeLanguageModel.call_instructor-112"><a href="#LargeLanguageModel.call_instructor-112"><span class="linenos">112</span></a>        <span class="k">return</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">client</span><span class="o">.</span><span class="n">call_instructor</span><span class="p">(</span>
</span><span id="LargeLanguageModel.call_instructor-113"><a href="#LargeLanguageModel.call_instructor-113"><span class="linenos">113</span></a>            <span class="n">response_model</span><span class="p">,</span>
</span><span id="LargeLanguageModel.call_instructor-114"><a href="#LargeLanguageModel.call_instructor-114"><span class="linenos">114</span></a>            <span class="n">system_prompt</span><span class="p">,</span>
</span><span id="LargeLanguageModel.call_instructor-115"><a href="#LargeLanguageModel.call_instructor-115"><span class="linenos">115</span></a>            <span class="n">user_prompt</span><span class="p">,</span>
</span><span id="LargeLanguageModel.call_instructor-116"><a href="#LargeLanguageModel.call_instructor-116"><span class="linenos">116</span></a>            <span class="n">max_tokens</span><span class="p">,</span>
</span><span id="LargeLanguageModel.call_instructor-117"><a href="#LargeLanguageModel.call_instructor-117"><span class="linenos">117</span></a>        <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Run a type-safe large language model query.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>response_model:</strong>  The Pydantic response model.</li>
<li><strong>system_prompt:</strong>  The system prompt.</li>
<li><strong>user_prompt:</strong>  The user prompt.</li>
<li><strong>max_tokens:</strong>  The maximum number of tokens to allow.</li>
</ul>
</div>


                            </div>
                            <div id="LargeLanguageModel.chain_of_verification" class="classattr">
                                        <input id="LargeLanguageModel.chain_of_verification-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">async def</span>
        <span class="name">chain_of_verification</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">system_prompt</span><span class="p">:</span> <span class="nb">str</span>,</span><span class="param">	<span class="n">user_prompt</span><span class="p">:</span> <span class="nb">str</span>,</span><span class="param">	<span class="n">response_model</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="o">~</span><span class="n">T</span><span class="p">]</span>,</span><span class="param">	<span class="n">statements</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="o">*</span>,</span><span class="param">	<span class="n">max_verifications</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span>,</span><span class="param">	<span class="n">create_new_statements</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>,</span><span class="param">	<span class="n">error_on_iteration_limit</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span></span><span class="return-annotation">) -> <span class="o">~</span><span class="n">T</span>:</span></span>

                <label class="view-source-button" for="LargeLanguageModel.chain_of_verification-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#LargeLanguageModel.chain_of_verification"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="LargeLanguageModel.chain_of_verification-145"><a href="#LargeLanguageModel.chain_of_verification-145"><span class="linenos">145</span></a>    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">chain_of_verification</span><span class="p">(</span>  <span class="c1"># noqa: PLR0913</span>
</span><span id="LargeLanguageModel.chain_of_verification-146"><a href="#LargeLanguageModel.chain_of_verification-146"><span class="linenos">146</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="LargeLanguageModel.chain_of_verification-147"><a href="#LargeLanguageModel.chain_of_verification-147"><span class="linenos">147</span></a>        <span class="n">system_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="LargeLanguageModel.chain_of_verification-148"><a href="#LargeLanguageModel.chain_of_verification-148"><span class="linenos">148</span></a>        <span class="n">user_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="LargeLanguageModel.chain_of_verification-149"><a href="#LargeLanguageModel.chain_of_verification-149"><span class="linenos">149</span></a>        <span class="n">response_model</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="n">T</span><span class="p">],</span>
</span><span id="LargeLanguageModel.chain_of_verification-150"><a href="#LargeLanguageModel.chain_of_verification-150"><span class="linenos">150</span></a>        <span class="n">statements</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="LargeLanguageModel.chain_of_verification-151"><a href="#LargeLanguageModel.chain_of_verification-151"><span class="linenos">151</span></a>        <span class="o">*</span><span class="p">,</span>
</span><span id="LargeLanguageModel.chain_of_verification-152"><a href="#LargeLanguageModel.chain_of_verification-152"><span class="linenos">152</span></a>        <span class="n">max_verifications</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
</span><span id="LargeLanguageModel.chain_of_verification-153"><a href="#LargeLanguageModel.chain_of_verification-153"><span class="linenos">153</span></a>        <span class="n">create_new_statements</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="LargeLanguageModel.chain_of_verification-154"><a href="#LargeLanguageModel.chain_of_verification-154"><span class="linenos">154</span></a>        <span class="n">error_on_iteration_limit</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="LargeLanguageModel.chain_of_verification-155"><a href="#LargeLanguageModel.chain_of_verification-155"><span class="linenos">155</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
</span><span id="LargeLanguageModel.chain_of_verification-156"><a href="#LargeLanguageModel.chain_of_verification-156"><span class="linenos">156</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Runs an LLM prompt that is self-assessed by the LLM.</span>
</span><span id="LargeLanguageModel.chain_of_verification-157"><a href="#LargeLanguageModel.chain_of_verification-157"><span class="linenos">157</span></a>
</span><span id="LargeLanguageModel.chain_of_verification-158"><a href="#LargeLanguageModel.chain_of_verification-158"><span class="linenos">158</span></a><span class="sd">        Args:</span>
</span><span id="LargeLanguageModel.chain_of_verification-159"><a href="#LargeLanguageModel.chain_of_verification-159"><span class="linenos">159</span></a><span class="sd">            system_prompt: The system prompt for the initial prompt.</span>
</span><span id="LargeLanguageModel.chain_of_verification-160"><a href="#LargeLanguageModel.chain_of_verification-160"><span class="linenos">160</span></a><span class="sd">            user_prompt: The user prompt for the initial prompt.</span>
</span><span id="LargeLanguageModel.chain_of_verification-161"><a href="#LargeLanguageModel.chain_of_verification-161"><span class="linenos">161</span></a><span class="sd">            response_model: The type of the response to return from Instructor.</span>
</span><span id="LargeLanguageModel.chain_of_verification-162"><a href="#LargeLanguageModel.chain_of_verification-162"><span class="linenos">162</span></a><span class="sd">            statements: Statements to verify the results.</span>
</span><span id="LargeLanguageModel.chain_of_verification-163"><a href="#LargeLanguageModel.chain_of_verification-163"><span class="linenos">163</span></a><span class="sd">            max_verifications: The maximum number of times to verify the results.</span>
</span><span id="LargeLanguageModel.chain_of_verification-164"><a href="#LargeLanguageModel.chain_of_verification-164"><span class="linenos">164</span></a><span class="sd">            create_new_statements: If True, generate new statements from the system</span>
</span><span id="LargeLanguageModel.chain_of_verification-165"><a href="#LargeLanguageModel.chain_of_verification-165"><span class="linenos">165</span></a><span class="sd">                prompt.</span>
</span><span id="LargeLanguageModel.chain_of_verification-166"><a href="#LargeLanguageModel.chain_of_verification-166"><span class="linenos">166</span></a><span class="sd">            error_on_iteration_limit: If True, raise an exception when the</span>
</span><span id="LargeLanguageModel.chain_of_verification-167"><a href="#LargeLanguageModel.chain_of_verification-167"><span class="linenos">167</span></a><span class="sd">                iteration limit is reached. Otherwise, returns the last result.</span>
</span><span id="LargeLanguageModel.chain_of_verification-168"><a href="#LargeLanguageModel.chain_of_verification-168"><span class="linenos">168</span></a>
</span><span id="LargeLanguageModel.chain_of_verification-169"><a href="#LargeLanguageModel.chain_of_verification-169"><span class="linenos">169</span></a><span class="sd">        Returns:</span>
</span><span id="LargeLanguageModel.chain_of_verification-170"><a href="#LargeLanguageModel.chain_of_verification-170"><span class="linenos">170</span></a><span class="sd">            The edited text result.</span>
</span><span id="LargeLanguageModel.chain_of_verification-171"><a href="#LargeLanguageModel.chain_of_verification-171"><span class="linenos">171</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="LargeLanguageModel.chain_of_verification-172"><a href="#LargeLanguageModel.chain_of_verification-172"><span class="linenos">172</span></a>        <span class="k">if</span> <span class="n">max_verifications</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="LargeLanguageModel.chain_of_verification-173"><a href="#LargeLanguageModel.chain_of_verification-173"><span class="linenos">173</span></a>            <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;max_verifications must be positive&quot;</span>
</span><span id="LargeLanguageModel.chain_of_verification-174"><a href="#LargeLanguageModel.chain_of_verification-174"><span class="linenos">174</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
</span><span id="LargeLanguageModel.chain_of_verification-175"><a href="#LargeLanguageModel.chain_of_verification-175"><span class="linenos">175</span></a>
</span><span id="LargeLanguageModel.chain_of_verification-176"><a href="#LargeLanguageModel.chain_of_verification-176"><span class="linenos">176</span></a>        <span class="k">if</span> <span class="n">statements</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">create_new_statements</span><span class="p">:</span>
</span><span id="LargeLanguageModel.chain_of_verification-177"><a href="#LargeLanguageModel.chain_of_verification-177"><span class="linenos">177</span></a>            <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;If no statements are provided, then they must be generated.&quot;</span>
</span><span id="LargeLanguageModel.chain_of_verification-178"><a href="#LargeLanguageModel.chain_of_verification-178"><span class="linenos">178</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
</span><span id="LargeLanguageModel.chain_of_verification-179"><a href="#LargeLanguageModel.chain_of_verification-179"><span class="linenos">179</span></a>        <span class="n">statements</span> <span class="o">=</span> <span class="n">statements</span> <span class="ow">or</span> <span class="p">[]</span>
</span><span id="LargeLanguageModel.chain_of_verification-180"><a href="#LargeLanguageModel.chain_of_verification-180"><span class="linenos">180</span></a>
</span><span id="LargeLanguageModel.chain_of_verification-181"><a href="#LargeLanguageModel.chain_of_verification-181"><span class="linenos">181</span></a>        <span class="k">if</span> <span class="n">create_new_statements</span><span class="p">:</span>
</span><span id="LargeLanguageModel.chain_of_verification-182"><a href="#LargeLanguageModel.chain_of_verification-182"><span class="linenos">182</span></a>            <span class="n">new_statements</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_statements</span><span class="p">(</span><span class="n">system_prompt</span><span class="p">)</span>
</span><span id="LargeLanguageModel.chain_of_verification-183"><a href="#LargeLanguageModel.chain_of_verification-183"><span class="linenos">183</span></a>            <span class="n">statements</span> <span class="o">+=</span> <span class="p">[</span><span class="n">statement</span><span class="o">.</span><span class="n">statement</span> <span class="k">for</span> <span class="n">statement</span> <span class="ow">in</span> <span class="n">new_statements</span><span class="p">]</span>
</span><span id="LargeLanguageModel.chain_of_verification-184"><a href="#LargeLanguageModel.chain_of_verification-184"><span class="linenos">184</span></a>        <span class="n">verification_prompt</span> <span class="o">=</span> <span class="n">prompts</span><span class="o">.</span><span class="n">chain_of_verification_verify</span><span class="p">(</span><span class="n">statements</span><span class="p">)</span>
</span><span id="LargeLanguageModel.chain_of_verification-185"><a href="#LargeLanguageModel.chain_of_verification-185"><span class="linenos">185</span></a>
</span><span id="LargeLanguageModel.chain_of_verification-186"><a href="#LargeLanguageModel.chain_of_verification-186"><span class="linenos">186</span></a>        <span class="n">rewrite_prompt</span> <span class="o">=</span> <span class="n">prompts</span><span class="o">.</span><span class="n">chain_of_verification_rewrite</span><span class="p">(</span>
</span><span id="LargeLanguageModel.chain_of_verification-187"><a href="#LargeLanguageModel.chain_of_verification-187"><span class="linenos">187</span></a>            <span class="n">statements</span><span class="o">=</span><span class="n">statements</span><span class="p">,</span>
</span><span id="LargeLanguageModel.chain_of_verification-188"><a href="#LargeLanguageModel.chain_of_verification-188"><span class="linenos">188</span></a>            <span class="n">instructions</span><span class="o">=</span><span class="n">system_prompt</span><span class="p">,</span>
</span><span id="LargeLanguageModel.chain_of_verification-189"><a href="#LargeLanguageModel.chain_of_verification-189"><span class="linenos">189</span></a>            <span class="n">source</span><span class="o">=</span><span class="n">user_prompt</span><span class="p">,</span>
</span><span id="LargeLanguageModel.chain_of_verification-190"><a href="#LargeLanguageModel.chain_of_verification-190"><span class="linenos">190</span></a>        <span class="p">)</span>
</span><span id="LargeLanguageModel.chain_of_verification-191"><a href="#LargeLanguageModel.chain_of_verification-191"><span class="linenos">191</span></a>
</span><span id="LargeLanguageModel.chain_of_verification-192"><a href="#LargeLanguageModel.chain_of_verification-192"><span class="linenos">192</span></a>        <span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="LargeLanguageModel.chain_of_verification-193"><a href="#LargeLanguageModel.chain_of_verification-193"><span class="linenos">193</span></a>        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_verifications</span><span class="p">):</span>
</span><span id="LargeLanguageModel.chain_of_verification-194"><a href="#LargeLanguageModel.chain_of_verification-194"><span class="linenos">194</span></a>            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Running verification iteration </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">idx</span><span class="p">)</span>
</span><span id="LargeLanguageModel.chain_of_verification-195"><a href="#LargeLanguageModel.chain_of_verification-195"><span class="linenos">195</span></a>            <span class="k">if</span> <span class="n">model</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="LargeLanguageModel.chain_of_verification-196"><a href="#LargeLanguageModel.chain_of_verification-196"><span class="linenos">196</span></a>                <span class="n">model</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">call_instructor</span><span class="p">(</span>
</span><span id="LargeLanguageModel.chain_of_verification-197"><a href="#LargeLanguageModel.chain_of_verification-197"><span class="linenos">197</span></a>                    <span class="n">response_model</span><span class="o">=</span><span class="n">response_model</span><span class="p">,</span>
</span><span id="LargeLanguageModel.chain_of_verification-198"><a href="#LargeLanguageModel.chain_of_verification-198"><span class="linenos">198</span></a>                    <span class="n">system_prompt</span><span class="o">=</span><span class="n">system_prompt</span><span class="p">,</span>
</span><span id="LargeLanguageModel.chain_of_verification-199"><a href="#LargeLanguageModel.chain_of_verification-199"><span class="linenos">199</span></a>                    <span class="n">user_prompt</span><span class="o">=</span><span class="n">user_prompt</span><span class="p">,</span>
</span><span id="LargeLanguageModel.chain_of_verification-200"><a href="#LargeLanguageModel.chain_of_verification-200"><span class="linenos">200</span></a>                <span class="p">)</span>
</span><span id="LargeLanguageModel.chain_of_verification-201"><a href="#LargeLanguageModel.chain_of_verification-201"><span class="linenos">201</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="LargeLanguageModel.chain_of_verification-202"><a href="#LargeLanguageModel.chain_of_verification-202"><span class="linenos">202</span></a>                <span class="n">model</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">call_instructor</span><span class="p">(</span>
</span><span id="LargeLanguageModel.chain_of_verification-203"><a href="#LargeLanguageModel.chain_of_verification-203"><span class="linenos">203</span></a>                    <span class="n">response_model</span><span class="o">=</span><span class="n">response_model</span><span class="p">,</span>
</span><span id="LargeLanguageModel.chain_of_verification-204"><a href="#LargeLanguageModel.chain_of_verification-204"><span class="linenos">204</span></a>                    <span class="n">system_prompt</span><span class="o">=</span><span class="n">rewrite_prompt</span><span class="p">,</span>
</span><span id="LargeLanguageModel.chain_of_verification-205"><a href="#LargeLanguageModel.chain_of_verification-205"><span class="linenos">205</span></a>                    <span class="n">user_prompt</span><span class="o">=</span><span class="n">_model_to_string</span><span class="p">(</span><span class="n">model</span><span class="p">),</span>
</span><span id="LargeLanguageModel.chain_of_verification-206"><a href="#LargeLanguageModel.chain_of_verification-206"><span class="linenos">206</span></a>                <span class="p">)</span>
</span><span id="LargeLanguageModel.chain_of_verification-207"><a href="#LargeLanguageModel.chain_of_verification-207"><span class="linenos">207</span></a>
</span><span id="LargeLanguageModel.chain_of_verification-208"><a href="#LargeLanguageModel.chain_of_verification-208"><span class="linenos">208</span></a>            <span class="n">text</span> <span class="o">=</span> <span class="n">_model_to_string</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</span><span id="LargeLanguageModel.chain_of_verification-209"><a href="#LargeLanguageModel.chain_of_verification-209"><span class="linenos">209</span></a>            <span class="n">verify</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">call_instructor</span><span class="p">(</span>
</span><span id="LargeLanguageModel.chain_of_verification-210"><a href="#LargeLanguageModel.chain_of_verification-210"><span class="linenos">210</span></a>                <span class="n">response_model</span><span class="o">=</span><span class="nb">list</span><span class="p">[</span><span class="n">_VerificationStatement</span><span class="p">],</span>
</span><span id="LargeLanguageModel.chain_of_verification-211"><a href="#LargeLanguageModel.chain_of_verification-211"><span class="linenos">211</span></a>                <span class="n">system_prompt</span><span class="o">=</span><span class="n">verification_prompt</span><span class="p">,</span>
</span><span id="LargeLanguageModel.chain_of_verification-212"><a href="#LargeLanguageModel.chain_of_verification-212"><span class="linenos">212</span></a>                <span class="n">user_prompt</span><span class="o">=</span><span class="n">text</span><span class="p">,</span>
</span><span id="LargeLanguageModel.chain_of_verification-213"><a href="#LargeLanguageModel.chain_of_verification-213"><span class="linenos">213</span></a>                <span class="n">max_tokens</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span>
</span><span id="LargeLanguageModel.chain_of_verification-214"><a href="#LargeLanguageModel.chain_of_verification-214"><span class="linenos">214</span></a>            <span class="p">)</span>
</span><span id="LargeLanguageModel.chain_of_verification-215"><a href="#LargeLanguageModel.chain_of_verification-215"><span class="linenos">215</span></a>
</span><span id="LargeLanguageModel.chain_of_verification-216"><a href="#LargeLanguageModel.chain_of_verification-216"><span class="linenos">216</span></a>            <span class="k">if</span> <span class="n">idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="LargeLanguageModel.chain_of_verification-217"><a href="#LargeLanguageModel.chain_of_verification-217"><span class="linenos">217</span></a>                <span class="k">continue</span>
</span><span id="LargeLanguageModel.chain_of_verification-218"><a href="#LargeLanguageModel.chain_of_verification-218"><span class="linenos">218</span></a>            <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="n">verification</span><span class="o">.</span><span class="n">correct</span> <span class="k">for</span> <span class="n">verification</span> <span class="ow">in</span> <span class="n">verify</span><span class="p">):</span>
</span><span id="LargeLanguageModel.chain_of_verification-219"><a href="#LargeLanguageModel.chain_of_verification-219"><span class="linenos">219</span></a>                <span class="k">break</span>
</span><span id="LargeLanguageModel.chain_of_verification-220"><a href="#LargeLanguageModel.chain_of_verification-220"><span class="linenos">220</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="LargeLanguageModel.chain_of_verification-221"><a href="#LargeLanguageModel.chain_of_verification-221"><span class="linenos">221</span></a>            <span class="k">if</span> <span class="n">error_on_iteration_limit</span><span class="p">:</span>
</span><span id="LargeLanguageModel.chain_of_verification-222"><a href="#LargeLanguageModel.chain_of_verification-222"><span class="linenos">222</span></a>                <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;Maximum number of iterations reached.&quot;</span>
</span><span id="LargeLanguageModel.chain_of_verification-223"><a href="#LargeLanguageModel.chain_of_verification-223"><span class="linenos">223</span></a>                <span class="k">raise</span> <span class="n">exceptions</span><span class="o">.</span><span class="n">IterationLimitError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
</span><span id="LargeLanguageModel.chain_of_verification-224"><a href="#LargeLanguageModel.chain_of_verification-224"><span class="linenos">224</span></a>
</span><span id="LargeLanguageModel.chain_of_verification-225"><a href="#LargeLanguageModel.chain_of_verification-225"><span class="linenos">225</span></a>        <span class="k">return</span> <span class="n">model</span>  <span class="c1"># type: ignore[return-value] # model will never be None as the for-loop is always entered.</span>
</span></pre></div>


            <div class="docstring"><p>Runs an LLM prompt that is self-assessed by the LLM.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>system_prompt:</strong>  The system prompt for the initial prompt.</li>
<li><strong>user_prompt:</strong>  The user prompt for the initial prompt.</li>
<li><strong>response_model:</strong>  The type of the response to return from Instructor.</li>
<li><strong>statements:</strong>  Statements to verify the results.</li>
<li><strong>max_verifications:</strong>  The maximum number of times to verify the results.</li>
<li><strong>create_new_statements:</strong>  If True, generate new statements from the system
prompt.</li>
<li><strong>error_on_iteration_limit:</strong>  If True, raise an exception when the
iteration limit is reached. Otherwise, returns the last result.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>The edited text result.</p>
</blockquote>
</div>


                            </div>
                            <div id="LargeLanguageModel.chain_of_density" class="classattr">
                                        <input id="LargeLanguageModel.chain_of_density-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">async def</span>
        <span class="name">chain_of_density</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">text</span><span class="p">:</span> <span class="nb">str</span>,</span><span class="param">	<span class="n">repeats</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span>,</span><span class="param">	<span class="o">*</span>,</span><span class="param">	<span class="n">max_informative_entities</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span></span><span class="return-annotation">) -> <span class="nb">str</span>:</span></span>

                <label class="view-source-button" for="LargeLanguageModel.chain_of_density-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#LargeLanguageModel.chain_of_density"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="LargeLanguageModel.chain_of_density-227"><a href="#LargeLanguageModel.chain_of_density-227"><span class="linenos">227</span></a>    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">chain_of_density</span><span class="p">(</span>
</span><span id="LargeLanguageModel.chain_of_density-228"><a href="#LargeLanguageModel.chain_of_density-228"><span class="linenos">228</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="LargeLanguageModel.chain_of_density-229"><a href="#LargeLanguageModel.chain_of_density-229"><span class="linenos">229</span></a>        <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="LargeLanguageModel.chain_of_density-230"><a href="#LargeLanguageModel.chain_of_density-230"><span class="linenos">230</span></a>        <span class="n">repeats</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
</span><span id="LargeLanguageModel.chain_of_density-231"><a href="#LargeLanguageModel.chain_of_density-231"><span class="linenos">231</span></a>        <span class="o">*</span><span class="p">,</span>
</span><span id="LargeLanguageModel.chain_of_density-232"><a href="#LargeLanguageModel.chain_of_density-232"><span class="linenos">232</span></a>        <span class="n">max_informative_entities</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
</span><span id="LargeLanguageModel.chain_of_density-233"><a href="#LargeLanguageModel.chain_of_density-233"><span class="linenos">233</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
</span><span id="LargeLanguageModel.chain_of_density-234"><a href="#LargeLanguageModel.chain_of_density-234"><span class="linenos">234</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Iterative summarization of an input text.</span>
</span><span id="LargeLanguageModel.chain_of_density-235"><a href="#LargeLanguageModel.chain_of_density-235"><span class="linenos">235</span></a>
</span><span id="LargeLanguageModel.chain_of_density-236"><a href="#LargeLanguageModel.chain_of_density-236"><span class="linenos">236</span></a><span class="sd">        Chain of density performs an iterative summarization of an input text. It</span>
</span><span id="LargeLanguageModel.chain_of_density-237"><a href="#LargeLanguageModel.chain_of_density-237"><span class="linenos">237</span></a><span class="sd">        should,</span>
</span><span id="LargeLanguageModel.chain_of_density-238"><a href="#LargeLanguageModel.chain_of_density-238"><span class="linenos">238</span></a><span class="sd">        in theory, provide more robust summaries than single-shot approaches.</span>
</span><span id="LargeLanguageModel.chain_of_density-239"><a href="#LargeLanguageModel.chain_of_density-239"><span class="linenos">239</span></a>
</span><span id="LargeLanguageModel.chain_of_density-240"><a href="#LargeLanguageModel.chain_of_density-240"><span class="linenos">240</span></a><span class="sd">        Args:</span>
</span><span id="LargeLanguageModel.chain_of_density-241"><a href="#LargeLanguageModel.chain_of_density-241"><span class="linenos">241</span></a><span class="sd">            text: The input text to summarize</span>
</span><span id="LargeLanguageModel.chain_of_density-242"><a href="#LargeLanguageModel.chain_of_density-242"><span class="linenos">242</span></a><span class="sd">            repeats: The number of times to summarize.</span>
</span><span id="LargeLanguageModel.chain_of_density-243"><a href="#LargeLanguageModel.chain_of_density-243"><span class="linenos">243</span></a><span class="sd">            max_informative_entities: The maximum number of new entities to include in</span>
</span><span id="LargeLanguageModel.chain_of_density-244"><a href="#LargeLanguageModel.chain_of_density-244"><span class="linenos">244</span></a><span class="sd">                each summary.</span>
</span><span id="LargeLanguageModel.chain_of_density-245"><a href="#LargeLanguageModel.chain_of_density-245"><span class="linenos">245</span></a>
</span><span id="LargeLanguageModel.chain_of_density-246"><a href="#LargeLanguageModel.chain_of_density-246"><span class="linenos">246</span></a><span class="sd">        Returns:</span>
</span><span id="LargeLanguageModel.chain_of_density-247"><a href="#LargeLanguageModel.chain_of_density-247"><span class="linenos">247</span></a><span class="sd">            The summarized text.</span>
</span><span id="LargeLanguageModel.chain_of_density-248"><a href="#LargeLanguageModel.chain_of_density-248"><span class="linenos">248</span></a>
</span><span id="LargeLanguageModel.chain_of_density-249"><a href="#LargeLanguageModel.chain_of_density-249"><span class="linenos">249</span></a><span class="sd">        References:</span>
</span><span id="LargeLanguageModel.chain_of_density-250"><a href="#LargeLanguageModel.chain_of_density-250"><span class="linenos">250</span></a><span class="sd">            Adams, G., Fabbri, A. R., Ladhak, F., Lehman, E., &amp; Elhadad, N. (2023,</span>
</span><span id="LargeLanguageModel.chain_of_density-251"><a href="#LargeLanguageModel.chain_of_density-251"><span class="linenos">251</span></a><span class="sd">            December). From sparse to dense: GPT-4 summarization with chain of</span>
</span><span id="LargeLanguageModel.chain_of_density-252"><a href="#LargeLanguageModel.chain_of_density-252"><span class="linenos">252</span></a><span class="sd">            density prompting. In Proceedings of the Conference on Empirical Methods</span>
</span><span id="LargeLanguageModel.chain_of_density-253"><a href="#LargeLanguageModel.chain_of_density-253"><span class="linenos">253</span></a><span class="sd">            in Natural Language Processing. Conference on Empirical Methods in</span>
</span><span id="LargeLanguageModel.chain_of_density-254"><a href="#LargeLanguageModel.chain_of_density-254"><span class="linenos">254</span></a><span class="sd">            Natural Language Processing (Vol. 2023, No. 4th New Frontier</span>
</span><span id="LargeLanguageModel.chain_of_density-255"><a href="#LargeLanguageModel.chain_of_density-255"><span class="linenos">255</span></a><span class="sd">            Summarization Workshop, p. 68).</span>
</span><span id="LargeLanguageModel.chain_of_density-256"><a href="#LargeLanguageModel.chain_of_density-256"><span class="linenos">256</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="LargeLanguageModel.chain_of_density-257"><a href="#LargeLanguageModel.chain_of_density-257"><span class="linenos">257</span></a>        <span class="n">system_prompt</span> <span class="o">=</span> <span class="n">prompts</span><span class="o">.</span><span class="n">chain_of_density</span><span class="p">(</span><span class="n">article</span><span class="o">=</span><span class="n">text</span><span class="p">)</span>
</span><span id="LargeLanguageModel.chain_of_density-258"><a href="#LargeLanguageModel.chain_of_density-258"><span class="linenos">258</span></a>        <span class="k">if</span> <span class="n">repeats</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="LargeLanguageModel.chain_of_density-259"><a href="#LargeLanguageModel.chain_of_density-259"><span class="linenos">259</span></a>            <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;Repeat count must be positive&quot;</span>
</span><span id="LargeLanguageModel.chain_of_density-260"><a href="#LargeLanguageModel.chain_of_density-260"><span class="linenos">260</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
</span><span id="LargeLanguageModel.chain_of_density-261"><a href="#LargeLanguageModel.chain_of_density-261"><span class="linenos">261</span></a>
</span><span id="LargeLanguageModel.chain_of_density-262"><a href="#LargeLanguageModel.chain_of_density-262"><span class="linenos">262</span></a>        <span class="k">class</span><span class="w"> </span><span class="nc">Response</span><span class="p">(</span><span class="n">pydantic</span><span class="o">.</span><span class="n">BaseModel</span><span class="p">):</span>
</span><span id="LargeLanguageModel.chain_of_density-263"><a href="#LargeLanguageModel.chain_of_density-263"><span class="linenos">263</span></a>            <span class="n">missing_informative_entity</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">pydantic</span><span class="o">.</span><span class="n">Field</span><span class="p">(</span>
</span><span id="LargeLanguageModel.chain_of_density-264"><a href="#LargeLanguageModel.chain_of_density-264"><span class="linenos">264</span></a>                <span class="o">...</span><span class="p">,</span>
</span><span id="LargeLanguageModel.chain_of_density-265"><a href="#LargeLanguageModel.chain_of_density-265"><span class="linenos">265</span></a>                <span class="n">min_length</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="LargeLanguageModel.chain_of_density-266"><a href="#LargeLanguageModel.chain_of_density-266"><span class="linenos">266</span></a>                <span class="n">max_length</span><span class="o">=</span><span class="n">max_informative_entities</span><span class="p">,</span>
</span><span id="LargeLanguageModel.chain_of_density-267"><a href="#LargeLanguageModel.chain_of_density-267"><span class="linenos">267</span></a>            <span class="p">)</span>
</span><span id="LargeLanguageModel.chain_of_density-268"><a href="#LargeLanguageModel.chain_of_density-268"><span class="linenos">268</span></a>            <span class="n">summary</span><span class="p">:</span> <span class="nb">str</span>
</span><span id="LargeLanguageModel.chain_of_density-269"><a href="#LargeLanguageModel.chain_of_density-269"><span class="linenos">269</span></a>
</span><span id="LargeLanguageModel.chain_of_density-270"><a href="#LargeLanguageModel.chain_of_density-270"><span class="linenos">270</span></a>        <span class="n">summary</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
</span><span id="LargeLanguageModel.chain_of_density-271"><a href="#LargeLanguageModel.chain_of_density-271"><span class="linenos">271</span></a>        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">repeats</span><span class="p">):</span>
</span><span id="LargeLanguageModel.chain_of_density-272"><a href="#LargeLanguageModel.chain_of_density-272"><span class="linenos">272</span></a>            <span class="n">user_prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Current Summary: </span><span class="si">{</span><span class="n">summary</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="LargeLanguageModel.chain_of_density-273"><a href="#LargeLanguageModel.chain_of_density-273"><span class="linenos">273</span></a>            <span class="n">iteration</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">call_instructor</span><span class="p">(</span>
</span><span id="LargeLanguageModel.chain_of_density-274"><a href="#LargeLanguageModel.chain_of_density-274"><span class="linenos">274</span></a>                <span class="n">response_model</span><span class="o">=</span><span class="n">Response</span><span class="p">,</span>
</span><span id="LargeLanguageModel.chain_of_density-275"><a href="#LargeLanguageModel.chain_of_density-275"><span class="linenos">275</span></a>                <span class="n">system_prompt</span><span class="o">=</span><span class="n">system_prompt</span><span class="p">,</span>
</span><span id="LargeLanguageModel.chain_of_density-276"><a href="#LargeLanguageModel.chain_of_density-276"><span class="linenos">276</span></a>                <span class="n">user_prompt</span><span class="o">=</span><span class="n">user_prompt</span><span class="p">,</span>
</span><span id="LargeLanguageModel.chain_of_density-277"><a href="#LargeLanguageModel.chain_of_density-277"><span class="linenos">277</span></a>            <span class="p">)</span>
</span><span id="LargeLanguageModel.chain_of_density-278"><a href="#LargeLanguageModel.chain_of_density-278"><span class="linenos">278</span></a>            <span class="n">summary</span> <span class="o">=</span> <span class="n">iteration</span><span class="o">.</span><span class="n">summary</span>
</span><span id="LargeLanguageModel.chain_of_density-279"><a href="#LargeLanguageModel.chain_of_density-279"><span class="linenos">279</span></a>        <span class="k">return</span> <span class="n">summary</span>
</span></pre></div>


            <div class="docstring"><p>Iterative summarization of an input text.</p>

<p>Chain of density performs an iterative summarization of an input text. It
should,
in theory, provide more robust summaries than single-shot approaches.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>text:</strong>  The input text to summarize</li>
<li><strong>repeats:</strong>  The number of times to summarize.</li>
<li><strong>max_informative_entities:</strong>  The maximum number of new entities to include in
each summary.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>The summarized text.</p>
</blockquote>

<h6 id="references">References:</h6>

<blockquote>
  <p>Adams, G., Fabbri, A. R., Ladhak, F., Lehman, E., &amp; Elhadad, N. (2023,
  December). From sparse to dense: GPT-4 summarization with chain of
  density prompting. In Proceedings of the Conference on Empirical Methods
  in Natural Language Processing. Conference on Empirical Methods in
  Natural Language Processing (Vol. 2023, No. 4th New Frontier
  Summarization Workshop, p. 68).</p>
</blockquote>
</div>


                            </div>
                </section>
                <section id="OllamaLlm">
                            <input id="OllamaLlm-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">OllamaLlm</span><wbr>(<span class="base">cloai.llm.utils.LlmBaseClass</span>):

                <label class="view-source-button" for="OllamaLlm-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#OllamaLlm"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="OllamaLlm-15"><a href="#OllamaLlm-15"><span class="linenos">15</span></a><span class="k">class</span><span class="w"> </span><span class="nc">OllamaLlm</span><span class="p">(</span><span class="n">LlmBaseClass</span><span class="p">):</span>
</span><span id="OllamaLlm-16"><a href="#OllamaLlm-16"><span class="linenos">16</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Client for Ollama API.&quot;&quot;&quot;</span>
</span><span id="OllamaLlm-17"><a href="#OllamaLlm-17"><span class="linenos">17</span></a>
</span><span id="OllamaLlm-18"><a href="#OllamaLlm-18"><span class="linenos">18</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="OllamaLlm-19"><a href="#OllamaLlm-19"><span class="linenos">19</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="OllamaLlm-20"><a href="#OllamaLlm-20"><span class="linenos">20</span></a>        <span class="n">model</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="OllamaLlm-21"><a href="#OllamaLlm-21"><span class="linenos">21</span></a>        <span class="n">base_url</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="OllamaLlm-22"><a href="#OllamaLlm-22"><span class="linenos">22</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="OllamaLlm-23"><a href="#OllamaLlm-23"><span class="linenos">23</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize Ollama client.</span>
</span><span id="OllamaLlm-24"><a href="#OllamaLlm-24"><span class="linenos">24</span></a>
</span><span id="OllamaLlm-25"><a href="#OllamaLlm-25"><span class="linenos">25</span></a><span class="sd">        Args:</span>
</span><span id="OllamaLlm-26"><a href="#OllamaLlm-26"><span class="linenos">26</span></a><span class="sd">            model: The model to run, must already be installed on the host via ollama.</span>
</span><span id="OllamaLlm-27"><a href="#OllamaLlm-27"><span class="linenos">27</span></a><span class="sd">            base_url: The URL of the Ollama API.</span>
</span><span id="OllamaLlm-28"><a href="#OllamaLlm-28"><span class="linenos">28</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="OllamaLlm-29"><a href="#OllamaLlm-29"><span class="linenos">29</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
</span><span id="OllamaLlm-30"><a href="#OllamaLlm-30"><span class="linenos">30</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">client</span> <span class="o">=</span> <span class="n">ollama</span><span class="o">.</span><span class="n">AsyncClient</span><span class="p">(</span><span class="n">host</span><span class="o">=</span><span class="n">base_url</span><span class="p">)</span>
</span><span id="OllamaLlm-31"><a href="#OllamaLlm-31"><span class="linenos">31</span></a>
</span><span id="OllamaLlm-32"><a href="#OllamaLlm-32"><span class="linenos">32</span></a>    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">system_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">user_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
</span><span id="OllamaLlm-33"><a href="#OllamaLlm-33"><span class="linenos">33</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Call Ollama model.&quot;&quot;&quot;</span>
</span><span id="OllamaLlm-34"><a href="#OllamaLlm-34"><span class="linenos">34</span></a>        <span class="n">response</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="p">(</span>
</span><span id="OllamaLlm-35"><a href="#OllamaLlm-35"><span class="linenos">35</span></a>            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
</span><span id="OllamaLlm-36"><a href="#OllamaLlm-36"><span class="linenos">36</span></a>            <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
</span><span id="OllamaLlm-37"><a href="#OllamaLlm-37"><span class="linenos">37</span></a>                <span class="p">{</span>
</span><span id="OllamaLlm-38"><a href="#OllamaLlm-38"><span class="linenos">38</span></a>                    <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span>
</span><span id="OllamaLlm-39"><a href="#OllamaLlm-39"><span class="linenos">39</span></a>                    <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">system_prompt</span><span class="p">,</span>
</span><span id="OllamaLlm-40"><a href="#OllamaLlm-40"><span class="linenos">40</span></a>                <span class="p">},</span>
</span><span id="OllamaLlm-41"><a href="#OllamaLlm-41"><span class="linenos">41</span></a>                <span class="p">{</span>
</span><span id="OllamaLlm-42"><a href="#OllamaLlm-42"><span class="linenos">42</span></a>                    <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span>
</span><span id="OllamaLlm-43"><a href="#OllamaLlm-43"><span class="linenos">43</span></a>                    <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">user_prompt</span><span class="p">,</span>
</span><span id="OllamaLlm-44"><a href="#OllamaLlm-44"><span class="linenos">44</span></a>                <span class="p">},</span>
</span><span id="OllamaLlm-45"><a href="#OllamaLlm-45"><span class="linenos">45</span></a>            <span class="p">],</span>
</span><span id="OllamaLlm-46"><a href="#OllamaLlm-46"><span class="linenos">46</span></a>        <span class="p">)</span>
</span><span id="OllamaLlm-47"><a href="#OllamaLlm-47"><span class="linenos">47</span></a>        <span class="k">return</span> <span class="n">response</span><span class="p">[</span><span class="s2">&quot;message&quot;</span><span class="p">][</span><span class="s2">&quot;content&quot;</span><span class="p">]</span>
</span><span id="OllamaLlm-48"><a href="#OllamaLlm-48"><span class="linenos">48</span></a>
</span><span id="OllamaLlm-49"><a href="#OllamaLlm-49"><span class="linenos">49</span></a>    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">call_instructor</span><span class="p">(</span>
</span><span id="OllamaLlm-50"><a href="#OllamaLlm-50"><span class="linenos">50</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="OllamaLlm-51"><a href="#OllamaLlm-51"><span class="linenos">51</span></a>        <span class="n">response_model</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="n">T</span><span class="p">],</span>
</span><span id="OllamaLlm-52"><a href="#OllamaLlm-52"><span class="linenos">52</span></a>        <span class="n">system_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="OllamaLlm-53"><a href="#OllamaLlm-53"><span class="linenos">53</span></a>        <span class="n">user_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="OllamaLlm-54"><a href="#OllamaLlm-54"><span class="linenos">54</span></a>        <span class="n">max_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4096</span><span class="p">,</span>
</span><span id="OllamaLlm-55"><a href="#OllamaLlm-55"><span class="linenos">55</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
</span><span id="OllamaLlm-56"><a href="#OllamaLlm-56"><span class="linenos">56</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Run a type-safe large language model query.</span>
</span><span id="OllamaLlm-57"><a href="#OllamaLlm-57"><span class="linenos">57</span></a>
</span><span id="OllamaLlm-58"><a href="#OllamaLlm-58"><span class="linenos">58</span></a><span class="sd">        This function uses Pydantic to convert any arbitrary class to JSON</span>
</span><span id="OllamaLlm-59"><a href="#OllamaLlm-59"><span class="linenos">59</span></a><span class="sd">        schema. This is unlikely to be fool-proof, but we can deal with issues</span>
</span><span id="OllamaLlm-60"><a href="#OllamaLlm-60"><span class="linenos">60</span></a><span class="sd">        as they arise.</span>
</span><span id="OllamaLlm-61"><a href="#OllamaLlm-61"><span class="linenos">61</span></a>
</span><span id="OllamaLlm-62"><a href="#OllamaLlm-62"><span class="linenos">62</span></a><span class="sd">        Args:</span>
</span><span id="OllamaLlm-63"><a href="#OllamaLlm-63"><span class="linenos">63</span></a><span class="sd">            response_model: The Pydantic response model.</span>
</span><span id="OllamaLlm-64"><a href="#OllamaLlm-64"><span class="linenos">64</span></a><span class="sd">            system_prompt: The system prompt.</span>
</span><span id="OllamaLlm-65"><a href="#OllamaLlm-65"><span class="linenos">65</span></a><span class="sd">            user_prompt: The user prompt.</span>
</span><span id="OllamaLlm-66"><a href="#OllamaLlm-66"><span class="linenos">66</span></a><span class="sd">            max_tokens: The maximum number of tokens to allow.</span>
</span><span id="OllamaLlm-67"><a href="#OllamaLlm-67"><span class="linenos">67</span></a>
</span><span id="OllamaLlm-68"><a href="#OllamaLlm-68"><span class="linenos">68</span></a><span class="sd">        Returns:</span>
</span><span id="OllamaLlm-69"><a href="#OllamaLlm-69"><span class="linenos">69</span></a><span class="sd">            The response as the requested object.</span>
</span><span id="OllamaLlm-70"><a href="#OllamaLlm-70"><span class="linenos">70</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="OllamaLlm-71"><a href="#OllamaLlm-71"><span class="linenos">71</span></a>        <span class="n">default_max_tokens</span> <span class="o">=</span> <span class="mi">4096</span>
</span><span id="OllamaLlm-72"><a href="#OllamaLlm-72"><span class="linenos">72</span></a>        <span class="k">if</span> <span class="n">max_tokens</span> <span class="o">!=</span> <span class="n">default_max_tokens</span><span class="p">:</span>
</span><span id="OllamaLlm-73"><a href="#OllamaLlm-73"><span class="linenos">73</span></a>            <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;max_tokens has not yet been implemented in Ollama.&quot;</span>
</span><span id="OllamaLlm-74"><a href="#OllamaLlm-74"><span class="linenos">74</span></a>            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
</span><span id="OllamaLlm-75"><a href="#OllamaLlm-75"><span class="linenos">75</span></a>
</span><span id="OllamaLlm-76"><a href="#OllamaLlm-76"><span class="linenos">76</span></a>        <span class="c1"># Use Pydantic for converting an arbitrary class to JSON schema.</span>
</span><span id="OllamaLlm-77"><a href="#OllamaLlm-77"><span class="linenos">77</span></a>        <span class="n">schema</span> <span class="o">=</span> <span class="n">pydantic</span><span class="o">.</span><span class="n">create_model</span><span class="p">(</span>
</span><span id="OllamaLlm-78"><a href="#OllamaLlm-78"><span class="linenos">78</span></a>            <span class="n">response_model</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
</span><span id="OllamaLlm-79"><a href="#OllamaLlm-79"><span class="linenos">79</span></a>            <span class="n">field</span><span class="o">=</span><span class="p">(</span><span class="n">response_model</span><span class="p">,</span> <span class="o">...</span><span class="p">),</span>
</span><span id="OllamaLlm-80"><a href="#OllamaLlm-80"><span class="linenos">80</span></a>        <span class="p">)</span><span class="o">.</span><span class="n">model_json_schema</span><span class="p">()</span>
</span><span id="OllamaLlm-81"><a href="#OllamaLlm-81"><span class="linenos">81</span></a>
</span><span id="OllamaLlm-82"><a href="#OllamaLlm-82"><span class="linenos">82</span></a>        <span class="n">response</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="p">(</span>
</span><span id="OllamaLlm-83"><a href="#OllamaLlm-83"><span class="linenos">83</span></a>            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
</span><span id="OllamaLlm-84"><a href="#OllamaLlm-84"><span class="linenos">84</span></a>            <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
</span><span id="OllamaLlm-85"><a href="#OllamaLlm-85"><span class="linenos">85</span></a>                <span class="p">{</span>
</span><span id="OllamaLlm-86"><a href="#OllamaLlm-86"><span class="linenos">86</span></a>                    <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span>
</span><span id="OllamaLlm-87"><a href="#OllamaLlm-87"><span class="linenos">87</span></a>                    <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">system_prompt</span><span class="p">,</span>
</span><span id="OllamaLlm-88"><a href="#OllamaLlm-88"><span class="linenos">88</span></a>                <span class="p">},</span>
</span><span id="OllamaLlm-89"><a href="#OllamaLlm-89"><span class="linenos">89</span></a>                <span class="p">{</span>
</span><span id="OllamaLlm-90"><a href="#OllamaLlm-90"><span class="linenos">90</span></a>                    <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span>
</span><span id="OllamaLlm-91"><a href="#OllamaLlm-91"><span class="linenos">91</span></a>                    <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">user_prompt</span><span class="p">,</span>
</span><span id="OllamaLlm-92"><a href="#OllamaLlm-92"><span class="linenos">92</span></a>                <span class="p">},</span>
</span><span id="OllamaLlm-93"><a href="#OllamaLlm-93"><span class="linenos">93</span></a>            <span class="p">],</span>
</span><span id="OllamaLlm-94"><a href="#OllamaLlm-94"><span class="linenos">94</span></a>            <span class="nb">format</span><span class="o">=</span><span class="n">schema</span><span class="p">,</span>
</span><span id="OllamaLlm-95"><a href="#OllamaLlm-95"><span class="linenos">95</span></a>        <span class="p">)</span>
</span><span id="OllamaLlm-96"><a href="#OllamaLlm-96"><span class="linenos">96</span></a>
</span><span id="OllamaLlm-97"><a href="#OllamaLlm-97"><span class="linenos">97</span></a>        <span class="n">data</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="p">)[</span><span class="s2">&quot;field&quot;</span><span class="p">]</span>  <span class="c1"># type: ignore[arg-type]</span>
</span><span id="OllamaLlm-98"><a href="#OllamaLlm-98"><span class="linenos">98</span></a>        <span class="k">return</span> <span class="n">_model_and_data_to_object</span><span class="p">(</span><span class="n">response_model</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Client for Ollama API.</p>
</div>


                            <div id="OllamaLlm.__init__" class="classattr">
                                        <input id="OllamaLlm.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">OllamaLlm</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">model</span><span class="p">:</span> <span class="nb">str</span>, </span><span class="param"><span class="n">base_url</span><span class="p">:</span> <span class="nb">str</span></span>)</span>

                <label class="view-source-button" for="OllamaLlm.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#OllamaLlm.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="OllamaLlm.__init__-18"><a href="#OllamaLlm.__init__-18"><span class="linenos">18</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="OllamaLlm.__init__-19"><a href="#OllamaLlm.__init__-19"><span class="linenos">19</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="OllamaLlm.__init__-20"><a href="#OllamaLlm.__init__-20"><span class="linenos">20</span></a>        <span class="n">model</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="OllamaLlm.__init__-21"><a href="#OllamaLlm.__init__-21"><span class="linenos">21</span></a>        <span class="n">base_url</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="OllamaLlm.__init__-22"><a href="#OllamaLlm.__init__-22"><span class="linenos">22</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="OllamaLlm.__init__-23"><a href="#OllamaLlm.__init__-23"><span class="linenos">23</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize Ollama client.</span>
</span><span id="OllamaLlm.__init__-24"><a href="#OllamaLlm.__init__-24"><span class="linenos">24</span></a>
</span><span id="OllamaLlm.__init__-25"><a href="#OllamaLlm.__init__-25"><span class="linenos">25</span></a><span class="sd">        Args:</span>
</span><span id="OllamaLlm.__init__-26"><a href="#OllamaLlm.__init__-26"><span class="linenos">26</span></a><span class="sd">            model: The model to run, must already be installed on the host via ollama.</span>
</span><span id="OllamaLlm.__init__-27"><a href="#OllamaLlm.__init__-27"><span class="linenos">27</span></a><span class="sd">            base_url: The URL of the Ollama API.</span>
</span><span id="OllamaLlm.__init__-28"><a href="#OllamaLlm.__init__-28"><span class="linenos">28</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="OllamaLlm.__init__-29"><a href="#OllamaLlm.__init__-29"><span class="linenos">29</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
</span><span id="OllamaLlm.__init__-30"><a href="#OllamaLlm.__init__-30"><span class="linenos">30</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">client</span> <span class="o">=</span> <span class="n">ollama</span><span class="o">.</span><span class="n">AsyncClient</span><span class="p">(</span><span class="n">host</span><span class="o">=</span><span class="n">base_url</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Initialize Ollama client.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>model:</strong>  The model to run, must already be installed on the host via ollama.</li>
<li><strong>base_url:</strong>  The URL of the Ollama API.</li>
</ul>
</div>


                            </div>
                            <div id="OllamaLlm.model" class="classattr">
                                <div class="attr variable">
            <span class="name">model</span>

        
    </div>
    <a class="headerlink" href="#OllamaLlm.model"></a>
    
    

                            </div>
                            <div id="OllamaLlm.client" class="classattr">
                                <div class="attr variable">
            <span class="name">client</span>

        
    </div>
    <a class="headerlink" href="#OllamaLlm.client"></a>
    
    

                            </div>
                            <div id="OllamaLlm.run" class="classattr">
                                        <input id="OllamaLlm.run-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">async def</span>
        <span class="name">run</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">system_prompt</span><span class="p">:</span> <span class="nb">str</span>, </span><span class="param"><span class="n">user_prompt</span><span class="p">:</span> <span class="nb">str</span></span><span class="return-annotation">) -> <span class="nb">str</span>:</span></span>

                <label class="view-source-button" for="OllamaLlm.run-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#OllamaLlm.run"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="OllamaLlm.run-32"><a href="#OllamaLlm.run-32"><span class="linenos">32</span></a>    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">system_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">user_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
</span><span id="OllamaLlm.run-33"><a href="#OllamaLlm.run-33"><span class="linenos">33</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Call Ollama model.&quot;&quot;&quot;</span>
</span><span id="OllamaLlm.run-34"><a href="#OllamaLlm.run-34"><span class="linenos">34</span></a>        <span class="n">response</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="p">(</span>
</span><span id="OllamaLlm.run-35"><a href="#OllamaLlm.run-35"><span class="linenos">35</span></a>            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
</span><span id="OllamaLlm.run-36"><a href="#OllamaLlm.run-36"><span class="linenos">36</span></a>            <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
</span><span id="OllamaLlm.run-37"><a href="#OllamaLlm.run-37"><span class="linenos">37</span></a>                <span class="p">{</span>
</span><span id="OllamaLlm.run-38"><a href="#OllamaLlm.run-38"><span class="linenos">38</span></a>                    <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span>
</span><span id="OllamaLlm.run-39"><a href="#OllamaLlm.run-39"><span class="linenos">39</span></a>                    <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">system_prompt</span><span class="p">,</span>
</span><span id="OllamaLlm.run-40"><a href="#OllamaLlm.run-40"><span class="linenos">40</span></a>                <span class="p">},</span>
</span><span id="OllamaLlm.run-41"><a href="#OllamaLlm.run-41"><span class="linenos">41</span></a>                <span class="p">{</span>
</span><span id="OllamaLlm.run-42"><a href="#OllamaLlm.run-42"><span class="linenos">42</span></a>                    <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span>
</span><span id="OllamaLlm.run-43"><a href="#OllamaLlm.run-43"><span class="linenos">43</span></a>                    <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">user_prompt</span><span class="p">,</span>
</span><span id="OllamaLlm.run-44"><a href="#OllamaLlm.run-44"><span class="linenos">44</span></a>                <span class="p">},</span>
</span><span id="OllamaLlm.run-45"><a href="#OllamaLlm.run-45"><span class="linenos">45</span></a>            <span class="p">],</span>
</span><span id="OllamaLlm.run-46"><a href="#OllamaLlm.run-46"><span class="linenos">46</span></a>        <span class="p">)</span>
</span><span id="OllamaLlm.run-47"><a href="#OllamaLlm.run-47"><span class="linenos">47</span></a>        <span class="k">return</span> <span class="n">response</span><span class="p">[</span><span class="s2">&quot;message&quot;</span><span class="p">][</span><span class="s2">&quot;content&quot;</span><span class="p">]</span>
</span></pre></div>


            <div class="docstring"><p>Call Ollama model.</p>
</div>


                            </div>
                            <div id="OllamaLlm.call_instructor" class="classattr">
                                        <input id="OllamaLlm.call_instructor-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">async def</span>
        <span class="name">call_instructor</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">response_model</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="o">~</span><span class="n">T</span><span class="p">]</span>,</span><span class="param">	<span class="n">system_prompt</span><span class="p">:</span> <span class="nb">str</span>,</span><span class="param">	<span class="n">user_prompt</span><span class="p">:</span> <span class="nb">str</span>,</span><span class="param">	<span class="n">max_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4096</span></span><span class="return-annotation">) -> <span class="o">~</span><span class="n">T</span>:</span></span>

                <label class="view-source-button" for="OllamaLlm.call_instructor-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#OllamaLlm.call_instructor"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="OllamaLlm.call_instructor-49"><a href="#OllamaLlm.call_instructor-49"><span class="linenos">49</span></a>    <span class="k">async</span> <span class="k">def</span><span class="w"> </span><span class="nf">call_instructor</span><span class="p">(</span>
</span><span id="OllamaLlm.call_instructor-50"><a href="#OllamaLlm.call_instructor-50"><span class="linenos">50</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="OllamaLlm.call_instructor-51"><a href="#OllamaLlm.call_instructor-51"><span class="linenos">51</span></a>        <span class="n">response_model</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="n">T</span><span class="p">],</span>
</span><span id="OllamaLlm.call_instructor-52"><a href="#OllamaLlm.call_instructor-52"><span class="linenos">52</span></a>        <span class="n">system_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="OllamaLlm.call_instructor-53"><a href="#OllamaLlm.call_instructor-53"><span class="linenos">53</span></a>        <span class="n">user_prompt</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="OllamaLlm.call_instructor-54"><a href="#OllamaLlm.call_instructor-54"><span class="linenos">54</span></a>        <span class="n">max_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4096</span><span class="p">,</span>
</span><span id="OllamaLlm.call_instructor-55"><a href="#OllamaLlm.call_instructor-55"><span class="linenos">55</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
</span><span id="OllamaLlm.call_instructor-56"><a href="#OllamaLlm.call_instructor-56"><span class="linenos">56</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Run a type-safe large language model query.</span>
</span><span id="OllamaLlm.call_instructor-57"><a href="#OllamaLlm.call_instructor-57"><span class="linenos">57</span></a>
</span><span id="OllamaLlm.call_instructor-58"><a href="#OllamaLlm.call_instructor-58"><span class="linenos">58</span></a><span class="sd">        This function uses Pydantic to convert any arbitrary class to JSON</span>
</span><span id="OllamaLlm.call_instructor-59"><a href="#OllamaLlm.call_instructor-59"><span class="linenos">59</span></a><span class="sd">        schema. This is unlikely to be fool-proof, but we can deal with issues</span>
</span><span id="OllamaLlm.call_instructor-60"><a href="#OllamaLlm.call_instructor-60"><span class="linenos">60</span></a><span class="sd">        as they arise.</span>
</span><span id="OllamaLlm.call_instructor-61"><a href="#OllamaLlm.call_instructor-61"><span class="linenos">61</span></a>
</span><span id="OllamaLlm.call_instructor-62"><a href="#OllamaLlm.call_instructor-62"><span class="linenos">62</span></a><span class="sd">        Args:</span>
</span><span id="OllamaLlm.call_instructor-63"><a href="#OllamaLlm.call_instructor-63"><span class="linenos">63</span></a><span class="sd">            response_model: The Pydantic response model.</span>
</span><span id="OllamaLlm.call_instructor-64"><a href="#OllamaLlm.call_instructor-64"><span class="linenos">64</span></a><span class="sd">            system_prompt: The system prompt.</span>
</span><span id="OllamaLlm.call_instructor-65"><a href="#OllamaLlm.call_instructor-65"><span class="linenos">65</span></a><span class="sd">            user_prompt: The user prompt.</span>
</span><span id="OllamaLlm.call_instructor-66"><a href="#OllamaLlm.call_instructor-66"><span class="linenos">66</span></a><span class="sd">            max_tokens: The maximum number of tokens to allow.</span>
</span><span id="OllamaLlm.call_instructor-67"><a href="#OllamaLlm.call_instructor-67"><span class="linenos">67</span></a>
</span><span id="OllamaLlm.call_instructor-68"><a href="#OllamaLlm.call_instructor-68"><span class="linenos">68</span></a><span class="sd">        Returns:</span>
</span><span id="OllamaLlm.call_instructor-69"><a href="#OllamaLlm.call_instructor-69"><span class="linenos">69</span></a><span class="sd">            The response as the requested object.</span>
</span><span id="OllamaLlm.call_instructor-70"><a href="#OllamaLlm.call_instructor-70"><span class="linenos">70</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="OllamaLlm.call_instructor-71"><a href="#OllamaLlm.call_instructor-71"><span class="linenos">71</span></a>        <span class="n">default_max_tokens</span> <span class="o">=</span> <span class="mi">4096</span>
</span><span id="OllamaLlm.call_instructor-72"><a href="#OllamaLlm.call_instructor-72"><span class="linenos">72</span></a>        <span class="k">if</span> <span class="n">max_tokens</span> <span class="o">!=</span> <span class="n">default_max_tokens</span><span class="p">:</span>
</span><span id="OllamaLlm.call_instructor-73"><a href="#OllamaLlm.call_instructor-73"><span class="linenos">73</span></a>            <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;max_tokens has not yet been implemented in Ollama.&quot;</span>
</span><span id="OllamaLlm.call_instructor-74"><a href="#OllamaLlm.call_instructor-74"><span class="linenos">74</span></a>            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
</span><span id="OllamaLlm.call_instructor-75"><a href="#OllamaLlm.call_instructor-75"><span class="linenos">75</span></a>
</span><span id="OllamaLlm.call_instructor-76"><a href="#OllamaLlm.call_instructor-76"><span class="linenos">76</span></a>        <span class="c1"># Use Pydantic for converting an arbitrary class to JSON schema.</span>
</span><span id="OllamaLlm.call_instructor-77"><a href="#OllamaLlm.call_instructor-77"><span class="linenos">77</span></a>        <span class="n">schema</span> <span class="o">=</span> <span class="n">pydantic</span><span class="o">.</span><span class="n">create_model</span><span class="p">(</span>
</span><span id="OllamaLlm.call_instructor-78"><a href="#OllamaLlm.call_instructor-78"><span class="linenos">78</span></a>            <span class="n">response_model</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
</span><span id="OllamaLlm.call_instructor-79"><a href="#OllamaLlm.call_instructor-79"><span class="linenos">79</span></a>            <span class="n">field</span><span class="o">=</span><span class="p">(</span><span class="n">response_model</span><span class="p">,</span> <span class="o">...</span><span class="p">),</span>
</span><span id="OllamaLlm.call_instructor-80"><a href="#OllamaLlm.call_instructor-80"><span class="linenos">80</span></a>        <span class="p">)</span><span class="o">.</span><span class="n">model_json_schema</span><span class="p">()</span>
</span><span id="OllamaLlm.call_instructor-81"><a href="#OllamaLlm.call_instructor-81"><span class="linenos">81</span></a>
</span><span id="OllamaLlm.call_instructor-82"><a href="#OllamaLlm.call_instructor-82"><span class="linenos">82</span></a>        <span class="n">response</span> <span class="o">=</span> <span class="k">await</span> <span class="bp">self</span><span class="o">.</span><span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="p">(</span>
</span><span id="OllamaLlm.call_instructor-83"><a href="#OllamaLlm.call_instructor-83"><span class="linenos">83</span></a>            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
</span><span id="OllamaLlm.call_instructor-84"><a href="#OllamaLlm.call_instructor-84"><span class="linenos">84</span></a>            <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
</span><span id="OllamaLlm.call_instructor-85"><a href="#OllamaLlm.call_instructor-85"><span class="linenos">85</span></a>                <span class="p">{</span>
</span><span id="OllamaLlm.call_instructor-86"><a href="#OllamaLlm.call_instructor-86"><span class="linenos">86</span></a>                    <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span>
</span><span id="OllamaLlm.call_instructor-87"><a href="#OllamaLlm.call_instructor-87"><span class="linenos">87</span></a>                    <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">system_prompt</span><span class="p">,</span>
</span><span id="OllamaLlm.call_instructor-88"><a href="#OllamaLlm.call_instructor-88"><span class="linenos">88</span></a>                <span class="p">},</span>
</span><span id="OllamaLlm.call_instructor-89"><a href="#OllamaLlm.call_instructor-89"><span class="linenos">89</span></a>                <span class="p">{</span>
</span><span id="OllamaLlm.call_instructor-90"><a href="#OllamaLlm.call_instructor-90"><span class="linenos">90</span></a>                    <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span>
</span><span id="OllamaLlm.call_instructor-91"><a href="#OllamaLlm.call_instructor-91"><span class="linenos">91</span></a>                    <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">user_prompt</span><span class="p">,</span>
</span><span id="OllamaLlm.call_instructor-92"><a href="#OllamaLlm.call_instructor-92"><span class="linenos">92</span></a>                <span class="p">},</span>
</span><span id="OllamaLlm.call_instructor-93"><a href="#OllamaLlm.call_instructor-93"><span class="linenos">93</span></a>            <span class="p">],</span>
</span><span id="OllamaLlm.call_instructor-94"><a href="#OllamaLlm.call_instructor-94"><span class="linenos">94</span></a>            <span class="nb">format</span><span class="o">=</span><span class="n">schema</span><span class="p">,</span>
</span><span id="OllamaLlm.call_instructor-95"><a href="#OllamaLlm.call_instructor-95"><span class="linenos">95</span></a>        <span class="p">)</span>
</span><span id="OllamaLlm.call_instructor-96"><a href="#OllamaLlm.call_instructor-96"><span class="linenos">96</span></a>
</span><span id="OllamaLlm.call_instructor-97"><a href="#OllamaLlm.call_instructor-97"><span class="linenos">97</span></a>        <span class="n">data</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span><span class="p">)[</span><span class="s2">&quot;field&quot;</span><span class="p">]</span>  <span class="c1"># type: ignore[arg-type]</span>
</span><span id="OllamaLlm.call_instructor-98"><a href="#OllamaLlm.call_instructor-98"><span class="linenos">98</span></a>        <span class="k">return</span> <span class="n">_model_and_data_to_object</span><span class="p">(</span><span class="n">response_model</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Run a type-safe large language model query.</p>

<p>This function uses Pydantic to convert any arbitrary class to JSON
schema. This is unlikely to be fool-proof, but we can deal with issues
as they arise.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>response_model:</strong>  The Pydantic response model.</li>
<li><strong>system_prompt:</strong>  The system prompt.</li>
<li><strong>user_prompt:</strong>  The user prompt.</li>
<li><strong>max_tokens:</strong>  The maximum number of tokens to allow.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>The response as the requested object.</p>
</blockquote>
</div>


                            </div>
                </section>
                <section id="OpenAiLlm">
                            <input id="OpenAiLlm-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">OpenAiLlm</span><wbr>(<span class="base">cloai.llm.openai._OpenAiBase</span>):

                <label class="view-source-button" for="OpenAiLlm-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#OpenAiLlm"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="OpenAiLlm-117"><a href="#OpenAiLlm-117"><span class="linenos">117</span></a><span class="k">class</span><span class="w"> </span><span class="nc">OpenAiLlm</span><span class="p">(</span><span class="n">_OpenAiBase</span><span class="p">):</span>
</span><span id="OpenAiLlm-118"><a href="#OpenAiLlm-118"><span class="linenos">118</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;OpenAI Large Language Models.</span>
</span><span id="OpenAiLlm-119"><a href="#OpenAiLlm-119"><span class="linenos">119</span></a>
</span><span id="OpenAiLlm-120"><a href="#OpenAiLlm-120"><span class="linenos">120</span></a><span class="sd">    This class serves as a generic interface to any model that uses OpenAIs</span>
</span><span id="OpenAiLlm-121"><a href="#OpenAiLlm-121"><span class="linenos">121</span></a><span class="sd">    interface such as OpenAI&#39;s models, Ollama, and LiteLLM.</span>
</span><span id="OpenAiLlm-122"><a href="#OpenAiLlm-122"><span class="linenos">122</span></a>
</span><span id="OpenAiLlm-123"><a href="#OpenAiLlm-123"><span class="linenos">123</span></a><span class="sd">    Both this class and AzureLlm inherit from the same base class as,</span>
</span><span id="OpenAiLlm-124"><a href="#OpenAiLlm-124"><span class="linenos">124</span></a><span class="sd">    apart from initialization, the LLM clients behave the same.</span>
</span><span id="OpenAiLlm-125"><a href="#OpenAiLlm-125"><span class="linenos">125</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="OpenAiLlm-126"><a href="#OpenAiLlm-126"><span class="linenos">126</span></a>
</span><span id="OpenAiLlm-127"><a href="#OpenAiLlm-127"><span class="linenos">127</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="OpenAiLlm-128"><a href="#OpenAiLlm-128"><span class="linenos">128</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="OpenAiLlm-129"><a href="#OpenAiLlm-129"><span class="linenos">129</span></a>        <span class="n">model</span><span class="p">:</span> <span class="n">chat_model</span><span class="o">.</span><span class="n">ChatModel</span> <span class="o">|</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="OpenAiLlm-130"><a href="#OpenAiLlm-130"><span class="linenos">130</span></a>        <span class="n">api_key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="OpenAiLlm-131"><a href="#OpenAiLlm-131"><span class="linenos">131</span></a>        <span class="n">base_url</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="OpenAiLlm-132"><a href="#OpenAiLlm-132"><span class="linenos">132</span></a>        <span class="n">instructor_mode</span><span class="p">:</span> <span class="n">instructor</span><span class="o">.</span><span class="n">Mode</span> <span class="o">=</span> <span class="n">instructor</span><span class="o">.</span><span class="n">Mode</span><span class="o">.</span><span class="n">TOOLS</span><span class="p">,</span>
</span><span id="OpenAiLlm-133"><a href="#OpenAiLlm-133"><span class="linenos">133</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="OpenAiLlm-134"><a href="#OpenAiLlm-134"><span class="linenos">134</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize the OpenAI Language Model client.</span>
</span><span id="OpenAiLlm-135"><a href="#OpenAiLlm-135"><span class="linenos">135</span></a>
</span><span id="OpenAiLlm-136"><a href="#OpenAiLlm-136"><span class="linenos">136</span></a><span class="sd">        Args:</span>
</span><span id="OpenAiLlm-137"><a href="#OpenAiLlm-137"><span class="linenos">137</span></a><span class="sd">            model: The model to use for the language model.</span>
</span><span id="OpenAiLlm-138"><a href="#OpenAiLlm-138"><span class="linenos">138</span></a><span class="sd">            api_key: The OpenAI API key.</span>
</span><span id="OpenAiLlm-139"><a href="#OpenAiLlm-139"><span class="linenos">139</span></a><span class="sd">            base_url: The URL for the endpoint, defaults to OpenAI&#39;s endpoint.</span>
</span><span id="OpenAiLlm-140"><a href="#OpenAiLlm-140"><span class="linenos">140</span></a><span class="sd">            instructor_mode: The instructor mode to use.</span>
</span><span id="OpenAiLlm-141"><a href="#OpenAiLlm-141"><span class="linenos">141</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="OpenAiLlm-142"><a href="#OpenAiLlm-142"><span class="linenos">142</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">client</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">AsyncOpenAI</span><span class="p">(</span><span class="n">api_key</span><span class="o">=</span><span class="n">api_key</span><span class="p">,</span> <span class="n">base_url</span><span class="o">=</span><span class="n">base_url</span><span class="p">)</span>
</span><span id="OpenAiLlm-143"><a href="#OpenAiLlm-143"><span class="linenos">143</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
</span><span id="OpenAiLlm-144"><a href="#OpenAiLlm-144"><span class="linenos">144</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_instructor</span> <span class="o">=</span> <span class="n">instructor</span><span class="o">.</span><span class="n">from_openai</span><span class="p">(</span>
</span><span id="OpenAiLlm-145"><a href="#OpenAiLlm-145"><span class="linenos">145</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">client</span><span class="p">,</span>
</span><span id="OpenAiLlm-146"><a href="#OpenAiLlm-146"><span class="linenos">146</span></a>            <span class="n">mode</span><span class="o">=</span><span class="n">instructor_mode</span><span class="p">,</span>
</span><span id="OpenAiLlm-147"><a href="#OpenAiLlm-147"><span class="linenos">147</span></a>        <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>OpenAI Large Language Models.</p>

<p>This class serves as a generic interface to any model that uses OpenAIs
interface such as OpenAI's models, Ollama, and LiteLLM.</p>

<p>Both this class and AzureLlm inherit from the same base class as,
apart from initialization, the LLM clients behave the same.</p>
</div>


                            <div id="OpenAiLlm.__init__" class="classattr">
                                        <input id="OpenAiLlm.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">OpenAiLlm</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">model</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Literal</span><span class="p">[</span><span class="s1">&#39;gpt-4.1&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt-4.1-mini&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt-4.1-nano&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt-4.1-2025-04-14&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt-4.1-mini-2025-04-14&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt-4.1-nano-2025-04-14&#39;</span><span class="p">,</span> <span class="s1">&#39;o4-mini&#39;</span><span class="p">,</span> <span class="s1">&#39;o4-mini-2025-04-16&#39;</span><span class="p">,</span> <span class="s1">&#39;o3&#39;</span><span class="p">,</span> <span class="s1">&#39;o3-2025-04-16&#39;</span><span class="p">,</span> <span class="s1">&#39;o3-mini&#39;</span><span class="p">,</span> <span class="s1">&#39;o3-mini-2025-01-31&#39;</span><span class="p">,</span> <span class="s1">&#39;o1&#39;</span><span class="p">,</span> <span class="s1">&#39;o1-2024-12-17&#39;</span><span class="p">,</span> <span class="s1">&#39;o1-preview&#39;</span><span class="p">,</span> <span class="s1">&#39;o1-preview-2024-09-12&#39;</span><span class="p">,</span> <span class="s1">&#39;o1-mini&#39;</span><span class="p">,</span> <span class="s1">&#39;o1-mini-2024-09-12&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt-4o&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt-4o-2024-11-20&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt-4o-2024-08-06&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt-4o-2024-05-13&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt-4o-audio-preview&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt-4o-audio-preview-2024-10-01&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt-4o-audio-preview-2024-12-17&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt-4o-mini-audio-preview&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt-4o-mini-audio-preview-2024-12-17&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt-4o-search-preview&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt-4o-mini-search-preview&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt-4o-search-preview-2025-03-11&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt-4o-mini-search-preview-2025-03-11&#39;</span><span class="p">,</span> <span class="s1">&#39;chatgpt-4o-latest&#39;</span><span class="p">,</span> <span class="s1">&#39;codex-mini-latest&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt-4o-mini&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt-4o-mini-2024-07-18&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt-4-turbo&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt-4-turbo-2024-04-09&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt-4-0125-preview&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt-4-turbo-preview&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt-4-1106-preview&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt-4-vision-preview&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt-4&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt-4-0314&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt-4-0613&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt-4-32k&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt-4-32k-0314&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt-4-32k-0613&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt-3.5-turbo&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt-3.5-turbo-16k&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt-3.5-turbo-0301&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt-3.5-turbo-0613&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt-3.5-turbo-1106&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt-3.5-turbo-0125&#39;</span><span class="p">,</span> <span class="s1">&#39;gpt-3.5-turbo-16k-0613&#39;</span><span class="p">],</span> <span class="nb">str</span><span class="p">]</span>,</span><span class="param">	<span class="n">api_key</span><span class="p">:</span> <span class="nb">str</span>,</span><span class="param">	<span class="n">base_url</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">instructor_mode</span><span class="p">:</span> <span class="n">instructor</span><span class="o">.</span><span class="n">mode</span><span class="o">.</span><span class="n">Mode</span> <span class="o">=</span> <span class="o">&lt;</span><span class="n">Mode</span><span class="o">.</span><span class="n">TOOLS</span><span class="p">:</span> <span class="s1">&#39;tool_call&#39;</span><span class="o">&gt;</span></span>)</span>

                <label class="view-source-button" for="OpenAiLlm.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#OpenAiLlm.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="OpenAiLlm.__init__-127"><a href="#OpenAiLlm.__init__-127"><span class="linenos">127</span></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
</span><span id="OpenAiLlm.__init__-128"><a href="#OpenAiLlm.__init__-128"><span class="linenos">128</span></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="OpenAiLlm.__init__-129"><a href="#OpenAiLlm.__init__-129"><span class="linenos">129</span></a>        <span class="n">model</span><span class="p">:</span> <span class="n">chat_model</span><span class="o">.</span><span class="n">ChatModel</span> <span class="o">|</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="OpenAiLlm.__init__-130"><a href="#OpenAiLlm.__init__-130"><span class="linenos">130</span></a>        <span class="n">api_key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
</span><span id="OpenAiLlm.__init__-131"><a href="#OpenAiLlm.__init__-131"><span class="linenos">131</span></a>        <span class="n">base_url</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="OpenAiLlm.__init__-132"><a href="#OpenAiLlm.__init__-132"><span class="linenos">132</span></a>        <span class="n">instructor_mode</span><span class="p">:</span> <span class="n">instructor</span><span class="o">.</span><span class="n">Mode</span> <span class="o">=</span> <span class="n">instructor</span><span class="o">.</span><span class="n">Mode</span><span class="o">.</span><span class="n">TOOLS</span><span class="p">,</span>
</span><span id="OpenAiLlm.__init__-133"><a href="#OpenAiLlm.__init__-133"><span class="linenos">133</span></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="OpenAiLlm.__init__-134"><a href="#OpenAiLlm.__init__-134"><span class="linenos">134</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize the OpenAI Language Model client.</span>
</span><span id="OpenAiLlm.__init__-135"><a href="#OpenAiLlm.__init__-135"><span class="linenos">135</span></a>
</span><span id="OpenAiLlm.__init__-136"><a href="#OpenAiLlm.__init__-136"><span class="linenos">136</span></a><span class="sd">        Args:</span>
</span><span id="OpenAiLlm.__init__-137"><a href="#OpenAiLlm.__init__-137"><span class="linenos">137</span></a><span class="sd">            model: The model to use for the language model.</span>
</span><span id="OpenAiLlm.__init__-138"><a href="#OpenAiLlm.__init__-138"><span class="linenos">138</span></a><span class="sd">            api_key: The OpenAI API key.</span>
</span><span id="OpenAiLlm.__init__-139"><a href="#OpenAiLlm.__init__-139"><span class="linenos">139</span></a><span class="sd">            base_url: The URL for the endpoint, defaults to OpenAI&#39;s endpoint.</span>
</span><span id="OpenAiLlm.__init__-140"><a href="#OpenAiLlm.__init__-140"><span class="linenos">140</span></a><span class="sd">            instructor_mode: The instructor mode to use.</span>
</span><span id="OpenAiLlm.__init__-141"><a href="#OpenAiLlm.__init__-141"><span class="linenos">141</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="OpenAiLlm.__init__-142"><a href="#OpenAiLlm.__init__-142"><span class="linenos">142</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">client</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">AsyncOpenAI</span><span class="p">(</span><span class="n">api_key</span><span class="o">=</span><span class="n">api_key</span><span class="p">,</span> <span class="n">base_url</span><span class="o">=</span><span class="n">base_url</span><span class="p">)</span>
</span><span id="OpenAiLlm.__init__-143"><a href="#OpenAiLlm.__init__-143"><span class="linenos">143</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
</span><span id="OpenAiLlm.__init__-144"><a href="#OpenAiLlm.__init__-144"><span class="linenos">144</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_instructor</span> <span class="o">=</span> <span class="n">instructor</span><span class="o">.</span><span class="n">from_openai</span><span class="p">(</span>
</span><span id="OpenAiLlm.__init__-145"><a href="#OpenAiLlm.__init__-145"><span class="linenos">145</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">client</span><span class="p">,</span>
</span><span id="OpenAiLlm.__init__-146"><a href="#OpenAiLlm.__init__-146"><span class="linenos">146</span></a>            <span class="n">mode</span><span class="o">=</span><span class="n">instructor_mode</span><span class="p">,</span>
</span><span id="OpenAiLlm.__init__-147"><a href="#OpenAiLlm.__init__-147"><span class="linenos">147</span></a>        <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Initialize the OpenAI Language Model client.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>model:</strong>  The model to use for the language model.</li>
<li><strong>api_key:</strong>  The OpenAI API key.</li>
<li><strong>base_url:</strong>  The URL for the endpoint, defaults to OpenAI's endpoint.</li>
<li><strong>instructor_mode:</strong>  The instructor mode to use.</li>
</ul>
</div>


                            </div>
                            <div id="OpenAiLlm.client" class="classattr">
                                <div class="attr variable">
            <span class="name">client</span>

        
    </div>
    <a class="headerlink" href="#OpenAiLlm.client"></a>
    
    

                            </div>
                            <div id="OpenAiLlm.model" class="classattr">
                                <div class="attr variable">
            <span class="name">model</span>

        
    </div>
    <a class="headerlink" href="#OpenAiLlm.model"></a>
    
    

                            </div>
                </section>
    </main>
</body>
</html>